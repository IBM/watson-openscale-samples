{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ec6e02f-b8a7-4e9b-8b70-4cc770a00815"
   },
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62b87ee0-6470-4fee-ad93-b752cfb20fd2"
   },
   "source": [
    "# IBM Watson OpenScale and Batch Processing:<br>Apache Spark on Cloud Pak for Data with IBM Analytics Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6a40839-4693-4954-977c-a06be10f1654"
   },
   "source": [
    "This notebook must be run in the Python 3.10 runtime environment. It requires Watson OpenScale service credentials.\n",
    "\n",
    "The notebook configures Watson OpenScale to monitor any WML online deployment as a self managed subscription on Openscale. For self managed subscriptions, all the monitors are run as jobs on user provided spark engine. Use the notebook to enable quality, drift, fairness and explainability monitoring and run on-demand evaluations. Before you can run the notebook, you must have the following resources:\n",
    "\n",
    "1. Configuration Archive generated using common configuration notebook [common configuration notebook](https://github.com/IBM/watson-openscale-samples/blob/main/Cloud%20Pak%20for%20Data/Batch%20Support/Configuration%20generation%20for%20OpenScale%20batch%20subscription.ipynb) and pre created WML deployment.\n",
    "2. Payload, feedback, drifted transactions, explanations queue and result tables to be created or validated in an Apache Hive datawarehouse. Please note, some of these maybe optional depending on your use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c379979-c5ad-4474-a0d6-a3e47ba52875"
   },
   "source": [
    "## Contents\n",
    "\n",
    "* [1. Setup](#setup)\n",
    "* [2. Configure Watson OpenScale](#openscale)\n",
    "* [3. Set up Subscription](#subscription)\n",
    "* [4. Quality monitoring](#quality)\n",
    "* [5. Drift monitoring](#drift)\n",
    "* [6. Fairness monitoring](#fairness)\n",
    "* [7. Explainability monitoring](#explainability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53c27c83-e746-43e4-96ba-62bb75548e79"
   },
   "source": [
    "# 1. Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a5d6f70-033b-456b-b78b-2c60b681858b"
   },
   "source": [
    "### Installing Required Libraries\n",
    "\n",
    "First import some of the packages you need to use. After you finish installing the following software packages, restart the kernel.\n",
    "\n",
    "### Import configuration archive/package\n",
    "\n",
    "Configuration archive/package created using configuration notebook will be required to onboard model for monitoring in IBM Watson OpenScale. Provide path location of archive here.\n",
    "\n",
    "Please note if you are executing this notebook in IBM Watson Studio, first upload the configuration archive/package to project and use provided code snippet to download it to local directory of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83d173c5-052c-4665-a835-cf4fb9f3c736"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import tarfile\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%env PIP_DISABLE_PIP_VERSION_CHECK=1\n",
    "\n",
    "# Note: Restart kernel after the dependencies are installed\n",
    "!pip install --upgrade ibm-watson-openscale\n",
    "!pip install \"ibm_wos_utils==5.0.1.16\"\n",
    "\n",
    "# # Download \"configuration_archive.tar.gz\" from project to local directory and \n",
    "# extract the artifacts\n",
    "# from ibm_watson_studio_lib import access_project_or_space\n",
    "# wslib = access_project_or_space()\n",
    "# wslib.download_file(\"configuration_archive.tar.gz\")\n",
    "archive_file_path = \"configuration_archive.tar.gz\"\n",
    "with tarfile.open('configuration_archive.tar.gz', \"r:gz\") as tar:\n",
    "    tar.extractall('.')\n",
    "# On unpacking the configuration archive, the files [common_configuration.json, drift_archive.tar.gz, \n",
    "# explainability.tar.gz, fairness_statistics.json] will be extracted to the current directory. \n",
    "# Output may differ depending on which monitors were enabled while running the \n",
    "# common configuration notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f5c59b7-046b-4118-8595-c23b272e6ed2"
   },
   "outputs": [],
   "source": [
    "!pip show ibm-watson-openscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f88fd4ce-007c-4e7d-89a6-74ac585c0ad4"
   },
   "source": [
    "## Configure credentials\n",
    "\n",
    "Provide your IBM Watson OpenScale and WML credentials in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f30968d7-16d6-4239-80fa-4782845115dc"
   },
   "outputs": [],
   "source": [
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"<cluster-url>\",\n",
    "    \"username\": \"<username>\",\n",
    "    \"password\": \"<password>\",\n",
    "    \"instance_id\": \"<openscale instance id>\"\n",
    "}\n",
    "\n",
    "WML_CREDENTIALS = {\n",
    "    \"url\": \"<wml_url>\",\n",
    "    \"username\": \"<username\",\n",
    "    \"password\": \"<password>\",\n",
    "    \"instance_id\": \"<instance id>\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "751fb159-b95f-4791-93f3-6c29c21d99d2"
   },
   "source": [
    "## Specify model details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ee265c7-7f58-4ad5-afae-a1d1839ba573"
   },
   "source": [
    "### Service provider and subscription metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a43dcbc2-39e5-4a68-8d84-a81611e8fbeb"
   },
   "outputs": [],
   "source": [
    "# Service Provider\n",
    "\n",
    "SERVICE_PROVIDER_NAME = \"<service-provider-name>\"\n",
    "SERVICE_PROVIDER_DESCRIPTION = \"<service-provider-description>\"\n",
    "\n",
    "# Subscription\n",
    "\n",
    "SUBSCRIPTION_NAME = \"<subscription-name>\"\n",
    "SUBSCRIPTION_DESCRIPTION = \"<subscription-description>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a252c34-7876-43b2-b6c0-f2db22856b25"
   },
   "source": [
    "### IBM Analytics Engine - Spark\n",
    "\n",
    "Make sure that the Apache Spark manager on IBM Analytics Engine is running, and then provide the following details:\n",
    "\n",
    "- IAE_SPARK_DISPLAY_NAME: _Display Name of the Spark instance in IBM Analytics Engine_\n",
    "- IAE_SPARK_JOBS_ENDPOINT: _Spark Jobs Endpoint for IBM Analytics Engine_\n",
    "- IBM_CPD_VOLUME: _IBM Cloud Pak for Data storage volume name_\n",
    "- IBM_CPD_USERNAME: _IBM Cloud Pak for Data username_\n",
    "- IBM_CPD_APIKEY: _IBM Cloud Pak for Data API key_\n",
    "- IAE_SPARK_DESCRIPTION: _Custom description for the Spark instance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eddf9d71-8df4-4e5b-a3b2-da22c042805a"
   },
   "outputs": [],
   "source": [
    "IAE_SPARK_DISPLAY_NAME = \"<spark-engine-name>\"\n",
    "IAE_SPARK_JOBS_ENDPOINT = \"<spark-job-endpoint-for-ibm-analytics-engine>\"\n",
    "IBM_CPD_VOLUME = \"<ibm-cpd-volume>\"\n",
    "IBM_CPD_USERNAME = \"<ibm-cloud-pak-for-data-username>\"\n",
    "IBM_CPD_APIKEY = \"<ibm-cloud-pak-for-data-apikey>\"\n",
    "IAE_SPARK_NAME = \"<iae-spark-name>\"\n",
    "IAE_SPARK_DESCRIPTION = \"<iae-spark-description>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aff6731b-48d9-4290-af29-6e8fb29e2d9f"
   },
   "source": [
    "#### Provide Spark Resource Settings\n",
    "\n",
    "To configure how much of your Spark Cluster resources this job can consume, edit the following values:\n",
    "\n",
    "- max_num_executors: _Maximum Number of executors to launch for this session_\n",
    "- min_executors: _Minimum Number of executors to launch for this session_\n",
    "- executor_cores: _Number of cores to use for each executor_   \n",
    "- executor_memory: _Amount of memory (in GBs) to use per executor process_\n",
    "- driver_cores: _Number of cores to use for the driver process_\n",
    "- driver_memory: _Amount of memory (in GBs) to use for the driver process_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ef23a21-39b2-43ea-86a1-6fee3b909ed7"
   },
   "outputs": [],
   "source": [
    "spark_parameters = {\n",
    "    \"max_num_executors\": 1,\n",
    "    \"min_num_executors\": 1,\n",
    "    \"executor_cores\": 1,\n",
    "    \"executor_memory\": 1,\n",
    "    \"driver_cores\": 1,\n",
    "    \"driver_memory\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e110fc8-0346-41cc-9700-440585806bdd"
   },
   "source": [
    "### Apache Hive\n",
    "\n",
    "To connect to Apache Hive, you must provide the following details:\n",
    "\n",
    "- HIVE_CONNECTION_NAME: _Custom display name for the Hive Connection_\n",
    "- HIVE_CONNECTION_DESCRIPTION: _Custom description for the Hive connection_\n",
    "- HIVE_METASTORE_URI: _Thrift URI for Hive Metastore to connect to_\n",
    "\n",
    "In case of a kerberos-enabled hive, provide additional details required to obtain the Hadoop delegation token:\n",
    "- HIVE_KERBEROS_PRINCIPAL: The kerberos principal used to generate the delegation token\n",
    "- DELEGATION_TOKEN_SECRET_URN: The secret_urn of the CP4D vault where the token is stored *OR*\n",
    "- DELEGATION_TOKEN_ENDPOINT: The REST endpoint which generates and returns the delegation token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b46e1745-1037-4c9b-8e91-991f792c6706"
   },
   "outputs": [],
   "source": [
    "HIVE_CONNECTION_NAME = \"<hive-connection-name>\"\n",
    "HIVE_CONNECTION_DESCRIPTION = \"<hive-connection-description>\"\n",
    "HIVE_METASTORE_URI = \"<hive-metastore-uri>\"\n",
    "\n",
    "# Flag to indicate if the Hive is secured with kerberos\n",
    "KERBEROS_ENABLED = False\n",
    "# Provide Hadoop delegation token details if KERBEROS_ENABLED is True\n",
    "# Provide either secret_urn of the CP4D vault OR the delegation token endpoint. One of the two fields is mandatory to fetch the delegation token.\n",
    "HIVE_KERBEROS_PRINCIPAL = \"<The kerberos principal used to generate the delegation token>\"\n",
    "DELEGATION_TOKEN_SECRET_URN = \"<The secret_urn of the CP4D vault where the token is stored>\"\n",
    "DELEGATION_TOKEN_ENDPOINT = \"<The REST endpoint which generates and returns the delegation token>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ce020c5-8eac-4d57-b2f2-39da4e769c6a"
   },
   "source": [
    "### Feedback table metadata\n",
    "\n",
    "The quality monitor stores metadata in the feedback table. To configure the quality monitor, you must provide the following details. To skip quality monitoring, run the following cell to initialize variables with the value of `None`.\n",
    "\n",
    "- FEEDBACK_DATABASE_NAME: _Database name where feedback table is present_\n",
    "- FEEDBACK_SCHEMA_NAME: _Schema name where feedback table is present_\n",
    "- FEEDBACK_TABLE_NAME: _Name of the feedback table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46276902-eeb5-49ac-9410-f4add43e3adb"
   },
   "outputs": [],
   "source": [
    "#feedback\n",
    "\n",
    "FEEDBACK_DATABASE_NAME = None\n",
    "FEEDBACK_TABLE_NAME = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d915a273-5512-46f2-b7d5-b1af4d65689a"
   },
   "source": [
    "### Payload and drift table metadata\n",
    "\n",
    "The drift monitor stores metadata in the payload and drift tables. To configure the drift monitor, you must provide the following details. To skip drift monitoring, run the following cell to initialize variables with the value of `None`.\n",
    "\n",
    "- PAYLOAD_DATABASE_NAME: _Database name where payload logging table is present_\n",
    "- PAYLOAD_SCHEMA_NAME: _Schema name where payload logging table is present_\n",
    "- PAYLOAD_TABLE_NAME: _Name of the payload logging table_\n",
    "- DRIFT_DATABASE_NAME: _Database name where drifted transactions table is present_\n",
    "- DRIFT_SCHEMA_NAME: _Schema name where drifted transactions table is present_\n",
    "- DRIFT_TABLE_NAME: _Name of the drifted transactions table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5918d2f-cd4b-4ee6-9821-40317485f8a1"
   },
   "outputs": [],
   "source": [
    "#payload logging\n",
    "\n",
    "PAYLOAD_DATABASE_NAME = None\n",
    "PAYLOAD_TABLE_NAME = None\n",
    "\n",
    "#drift\n",
    "\n",
    "DRIFT_DATABASE_NAME = None\n",
    "DRIFT_TABLE_NAME = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2640b5f2-be68-435a-92ca-12ce384a95d9"
   },
   "source": [
    "### Explainability table metadata\n",
    "\n",
    "The explainability monitor requires the queue and result tables. The payload table can also be used as the queue table. To configure the explainability monitor, you must provide the following details. To skip explainability monitoring, run the following cell to initialize variables with the value of `None`.\n",
    "\n",
    "- EXPLAINABILITY_DATABASE_NAME: _Database name where explanations queue, result tables are present_\n",
    "- EXPLAINABILITY_QUEUE_TABLE_NAME: _Name of the explanations queue table_\n",
    "- EXPLAINABILITY_RESULT_TABLE_NAME: _Name of the explanations result table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c10c17a-f553-439c-bb3c-54a2a10fd78c"
   },
   "outputs": [],
   "source": [
    "#explainability\n",
    "\n",
    "EXPLAINABILITY_DATABASE_NAME = None\n",
    "EXPLAINABILITY_QUEUE_TABLE_NAME = None\n",
    "EXPLAINABILITY_RESULT_TABLE_NAME = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c169c94-2492-4738-948d-6693dc38d43c"
   },
   "source": [
    "# 2. Configure Watson OpenScale <a name=\"openscale\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f90a66c0-3ce0-4233-a91c-b379bffd9f30"
   },
   "source": [
    "### Import the required libraries and set up the Watson OpenScale client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16fabc24-b7d0-4859-b500-9351f8833fdb"
   },
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import *\n",
    "\n",
    "authenticator = CloudPakForDataAuthenticator(\n",
    "        url=WOS_CREDENTIALS[\"url\"],\n",
    "        username=WOS_CREDENTIALS[\"username\"],\n",
    "        password=WOS_CREDENTIALS[\"password\"],\n",
    "        disable_ssl_verification=True\n",
    "    )\n",
    "\n",
    "wos_client = APIClient(authenticator=authenticator, service_url=WOS_CREDENTIALS[\"url\"], service_instance_id=WOS_CREDENTIALS[\"instance_id\"])\n",
    "data_mart_id=WOS_CREDENTIALS[\"instance_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e0fa3d4-2207-4699-bb38-f10e6e4c3a55"
   },
   "source": [
    "### Display Watson OpenScale datamart details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30fb3f08-4b30-4547-9c63-a66528472e01"
   },
   "outputs": [],
   "source": [
    "wos_client.data_marts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e444780-ecbd-4848-affd-6bc8d35efd3e"
   },
   "source": [
    "### Create a service provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "903193f5-14f3-451e-8abc-1cc814bbb4a6"
   },
   "outputs": [],
   "source": [
    "# Delete existing service provider with the same name as provided\n",
    "\n",
    "service_providers = wos_client.service_providers.list().result.service_providers\n",
    "for provider in service_providers:\n",
    "    if provider.entity.name == SERVICE_PROVIDER_NAME:\n",
    "        wos_client.service_providers.delete(service_provider_id=provider.metadata.id)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a90da5cb-c3b7-4ce6-9723-8becd72d31f0"
   },
   "outputs": [],
   "source": [
    "# Add Service Provider\n",
    "\n",
    "added_service_provider_result = wos_client.service_providers.add(\n",
    "        name=SERVICE_PROVIDER_NAME,\n",
    "        description=SERVICE_PROVIDER_DESCRIPTION,\n",
    "        service_type=ServiceTypes.WATSON_MACHINE_LEARNING,\n",
    "        credentials=WML_CREDENTIALS,\n",
    "        operational_space_id=\"production\",\n",
    "        background_mode=False\n",
    "    ).result\n",
    "\n",
    "service_provider_id = added_service_provider_result.metadata.id\n",
    "\n",
    "wos_client.service_providers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efd1520a-f87a-46d1-8229-c7615345fb55"
   },
   "outputs": [],
   "source": [
    "service_provide_details = wos_client.service_providers.get(service_provider_id=service_provider_id).result\n",
    "print(service_provide_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97374835-1ba6-4bd2-820d-169311758590"
   },
   "source": [
    "### Create integrated systems for Spark Engine and Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5253227f-1962-40d3-b085-df8e69a3be21"
   },
   "outputs": [],
   "source": [
    "# Delete existing spark and hive integrated systems if present\n",
    "\n",
    "integrated_systems = IntegratedSystems(wos_client).list().result.integrated_systems\n",
    "\n",
    "for system in integrated_systems:\n",
    "    if system.entity.name in (IAE_SPARK_NAME, HIVE_CONNECTION_NAME):\n",
    "        print(\"Deleting integrated system {}\".format(system.entity.name))\n",
    "        IntegratedSystems(wos_client).delete(integrated_system_id=system.metadata.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af21e5ae-725b-467c-ada9-ac26cefff3e3"
   },
   "source": [
    "#### Spark Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9def9c18-3034-49ba-89f9-c4d7ee8a668b"
   },
   "outputs": [],
   "source": [
    "spark_integrated_system = IntegratedSystems(wos_client).add(\n",
    "    name=IAE_SPARK_NAME,\n",
    "    description=IAE_SPARK_DESCRIPTION,\n",
    "    type=\"spark\",\n",
    "    credentials={\n",
    "        \"username\": IBM_CPD_USERNAME,\n",
    "        \"apikey\": IBM_CPD_APIKEY\n",
    "    },\n",
    "    connection={\n",
    "        \"display_name\": IAE_SPARK_DISPLAY_NAME,\n",
    "        \"endpoint\": IAE_SPARK_JOBS_ENDPOINT,\n",
    "        \"volume\": IBM_CPD_VOLUME,\n",
    "        \"location_type\": \"cpd_iae\"\n",
    "    }\n",
    ").result\n",
    "\n",
    "spark_integrated_system_id = spark_integrated_system.metadata.id\n",
    "print(spark_integrated_system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cc72495-baa9-4a82-9739-55f42955c473"
   },
   "source": [
    "#### Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27ac5450-513e-4bd9-a231-249625c4a6df"
   },
   "outputs": [],
   "source": [
    "hive_connection = {}\n",
    "hive_credentials = {}\n",
    "if HIVE_METASTORE_URI is not None:\n",
    "    hive_connection[\"metastore_url\"] = HIVE_METASTORE_URI\n",
    "    hive_connection[\"location_type\"] = \"metastore\"\n",
    "\n",
    "if KERBEROS_ENABLED is True:\n",
    "    hive_connection[\"kerberos_enabled\"] = True\n",
    "    hive_credentials[\"kerberos_principal\"] = HIVE_KERBEROS_PRINCIPAL\n",
    "    if DELEGATION_TOKEN_SECRET_URN:\n",
    "        hive_credentials[\"delegation_token_urn\"] = DELEGATION_TOKEN_SECRET_URN\n",
    "    if DELEGATION_TOKEN_ENDPOINT:\n",
    "        hive_credentials[\"delegation_token_endpoint\"] = DELEGATION_TOKEN_ENDPOINT\n",
    "\n",
    "hive_integrated_system = IntegratedSystems(wos_client).add(\n",
    "    name=HIVE_CONNECTION_NAME,\n",
    "    description=HIVE_CONNECTION_DESCRIPTION,\n",
    "    type=\"hive\",\n",
    "    credentials=hive_credentials,\n",
    "    connection=hive_connection\n",
    ").result\n",
    "\n",
    "hive_integrated_system_id=hive_integrated_system.metadata.id\n",
    "print(hive_integrated_system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b78f96ac-7662-41b5-883e-6da3f011c5da"
   },
   "source": [
    "# 3. Set up a subscription<a name=\"subscription\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6cbe79a-a8fb-4cae-8524-0fe940c71a17"
   },
   "outputs": [],
   "source": [
    "# Delete an existing subscription with the provided name\n",
    "\n",
    "subscriptions = wos_client.subscriptions.list().result.subscriptions\n",
    "for sub in subscriptions:\n",
    "    if sub.entity.deployment.name == SUBSCRIPTION_NAME:\n",
    "        wos_client.subscriptions.delete(subscription_id=sub.metadata.id)\n",
    "        break\n",
    "\n",
    "# Display all subscriptions\n",
    "wos_client.subscriptions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d19e502-5e53-4ee1-b60f-4b0912b49998"
   },
   "source": [
    "### Set subscription metadata\n",
    "\n",
    "In the following cell, we expect you extracted Configuration Archive to current directory and it contains common_configuration.json. If not true, please update path to correct location. After you edit the path information, run the cell to set the asset details and properties, the deployment details, the analytics engine details, and to add the required tables as data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "431e4689-cb82-4009-a1e8-631573e092c5"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Provide the WML deployment io and space d\n",
    "deployment_uid = \"<wml_deployment_id>\"\n",
    "space_id = \"<wml_space_id>\"\n",
    "common_configuration = None\n",
    "\n",
    "with open(\"common_configuration.json\", \"r\") as fp:\n",
    "    configuration_json = json.load(fp)\n",
    "    common_configuration = configuration_json.get(\"common_configuration\")\n",
    "    if common_configuration is None:\n",
    "        raise Exception(\"Please provide the correct path to the common configuration JSON\")\n",
    "        \n",
    "asset_deployment_details = wos_client.service_providers.list_assets(\n",
    "    data_mart_id=data_mart_id, service_provider_id=service_provider_id, \n",
    "    deployment_id = deployment_uid, deployment_space_id = space_id).result['resources'][0]\n",
    "\n",
    "model_asset_details_from_deployment = wos_client.service_providers.get_deployment_asset(\n",
    "    data_mart_id=data_mart_id,service_provider_id=service_provider_id,deployment_id=deployment_uid,\n",
    "    deployment_space_id=space_id)\n",
    "\n",
    "scoring_endpoint = ScoringEndpointRequest(\n",
    "    url=model_asset_details_from_deployment['entity']['scoring_endpoint']['url'] )\n",
    "    \n",
    "# Set asset details\n",
    "asset = Asset(\n",
    "    asset_id=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"asset_id\"],\n",
    "    url=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"url\"],\n",
    "    name=SUBSCRIPTION_NAME,\n",
    "    asset_type=AssetTypes.MODEL,\n",
    "    input_data_type=InputDataType.STRUCTURED,\n",
    "    problem_type=common_configuration.get(\"problem_type\") if common_configuration.get(\"problem_type\") else common_configuration.get(\"model_type\")\n",
    ")\n",
    "\n",
    "# Set deployment details\n",
    "asset_deployment = AssetDeploymentRequest(\n",
    "    deployment_id=asset_deployment_details['metadata']['guid'],\n",
    "    name=SUBSCRIPTION_NAME,\n",
    "    description=SUBSCRIPTION_DESCRIPTION,\n",
    "    deployment_type=DeploymentTypes.ONLINE,\n",
    "    scoring_endpoint=scoring_endpoint\n",
    ")\n",
    "\n",
    "probability_fields = common_configuration.get(\"probability_fields\") if common_configuration.get(\"probability_fields\") else [common_configuration.get(\"probability\")]\n",
    "\n",
    "\n",
    "# Set asset properties \n",
    "asset_properties_request = AssetPropertiesRequest(\n",
    "    label_column=common_configuration[\"label_column\"],\n",
    "    probability_fields=probability_fields, # comment out this line for regression models as probability_fields is not applicable\n",
    "    prediction_field=common_configuration[\"prediction\"],\n",
    "    feature_fields=common_configuration[\"feature_columns\"],\n",
    "    categorical_fields=common_configuration[\"categorical_columns\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd54e0181ffa4670acbbe1eb432d9369"
   },
   "outputs": [],
   "source": [
    "# Set analytics engine details\n",
    "analytics_engine = AnalyticsEngine(\n",
    "    type=\"spark\",\n",
    "    integrated_system_id=spark_integrated_system_id,\n",
    "    parameters = spark_parameters\n",
    ")\n",
    "\n",
    "# Add selected tables as data sources\n",
    "data_sources = []\n",
    "if FEEDBACK_DATABASE_NAME is not None and FEEDBACK_TABLE_NAME is not None:\n",
    "    feedback_data_source = DataSource(\n",
    "        type=\"feedback\", \n",
    "        database_name=FEEDBACK_DATABASE_NAME,\n",
    "        schema_name=FEEDBACK_DATABASE_NAME,\n",
    "        table_name=FEEDBACK_TABLE_NAME,\n",
    "        connection=DataSourceConnection(\n",
    "            type=\"hive\", \n",
    "            integrated_system_id=hive_integrated_system_id\n",
    "        ),\n",
    "        parameters={\n",
    "            \"hive_storage_format\": \"<to_be_edited>\" #supported values are \"csv\", \"parquet\", \"orc\"\n",
    "        },\n",
    "        auto_create=True, #set it to False if table already exists\n",
    "        status=DataSourceStatus(state=\"new\")\n",
    "    )\n",
    "    data_sources.append(feedback_data_source)\n",
    "    \n",
    "if PAYLOAD_DATABASE_NAME is not None and PAYLOAD_TABLE_NAME is not None \\\n",
    "    and DRIFT_DATABASE_NAME is not None and DRIFT_TABLE_NAME is not None:\n",
    "    payload_logging_data_source = DataSource(\n",
    "        type=\"payload\", \n",
    "        database_name=PAYLOAD_DATABASE_NAME,\n",
    "        schema_name=PAYLOAD_DATABASE_NAME,\n",
    "        table_name=PAYLOAD_TABLE_NAME,\n",
    "        connection=DataSourceConnection(\n",
    "            type=\"hive\", \n",
    "            integrated_system_id=hive_integrated_system_id\n",
    "        ),\n",
    "        parameters={\n",
    "            \"hive_storage_format\": \"<to_be_edited>\" #supported values are \"csv\", \"parquet\", \"orc\"\n",
    "        },\n",
    "        auto_create=True, #set it to False if table already exists\n",
    "        status=DataSourceStatus(state=\"new\")\n",
    "    )\n",
    "    \n",
    "    drifted_transactions_table_data_source = DataSource(\n",
    "        type=\"drift\", \n",
    "        database_name=DRIFT_DATABASE_NAME,\n",
    "        schema_name=DRIFT_DATABASE_NAME,\n",
    "        table_name=DRIFT_TABLE_NAME,\n",
    "        connection=DataSourceConnection(\n",
    "            type=\"hive\", \n",
    "            integrated_system_id=hive_integrated_system_id\n",
    "        ),\n",
    "        auto_create=True, #set it to False if table already exists\n",
    "        status=DataSourceStatus(state=\"new\")\n",
    "    )\n",
    "    \n",
    "    data_sources.append(payload_logging_data_source)\n",
    "    data_sources.append(drifted_transactions_table_data_source)\n",
    "\n",
    "if EXPLAINABILITY_DATABASE_NAME is not None and \\\n",
    "    EXPLAINABILITY_QUEUE_TABLE_NAME is not None and \\\n",
    "        EXPLAINABILITY_RESULT_TABLE_NAME is not None:\n",
    "\n",
    "    explainability_queue_data_source = DataSource(\n",
    "        type=\"explain_queue\", \n",
    "        database_name=EXPLAINABILITY_DATABASE_NAME,\n",
    "        schema_name=EXPLAINABILITY_DATABASE_NAME,\n",
    "        table_name=EXPLAINABILITY_QUEUE_TABLE_NAME,\n",
    "        connection=DataSourceConnection(\n",
    "            type=\"hive\", \n",
    "            integrated_system_id=hive_integrated_system_id\n",
    "        ),\n",
    "        parameters={\n",
    "            \"hive_storage_format\": \"<to_be_edited>\" #supported values are \"csv\", \"parquet\", \"orc\"\n",
    "        },\n",
    "        auto_create=True, #set it to False if table already exists\n",
    "        status=DataSourceStatus(state=\"new\")\n",
    "    )\n",
    "    \n",
    "    data_sources.append(explainability_queue_data_source)\n",
    "\n",
    "    explainability_result_data_source = DataSource(\n",
    "        type=\"explain_result\", \n",
    "        database_name=EXPLAINABILITY_DATABASE_NAME,\n",
    "        schema_name=EXPLAINABILITY_DATABASE_NAME,\n",
    "        table_name=EXPLAINABILITY_RESULT_TABLE_NAME,\n",
    "        connection=DataSourceConnection(\n",
    "            type=\"hive\", \n",
    "            integrated_system_id=hive_integrated_system_id\n",
    "        ),\n",
    "        parameters={},\n",
    "        auto_create=True, #set it to False if table already exists\n",
    "        status=DataSourceStatus(state=\"new\")\n",
    "    )\n",
    "    \n",
    "    data_sources.append(explainability_result_data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08d58a6d-0cc4-45be-beed-7dc48a1ec8bf"
   },
   "outputs": [],
   "source": [
    "# Adding the subscription\n",
    "\n",
    "subscription_details = Subscriptions(wos_client).add(\n",
    "    data_mart_id=data_mart_id,\n",
    "    service_provider_id=service_provider_id,\n",
    "    asset=asset,\n",
    "    deployment=asset_deployment,\n",
    "    asset_properties=asset_properties_request,\n",
    "    analytics_engine=analytics_engine,\n",
    "    scoring_endpoint=scoring_endpoint).result\n",
    "\n",
    "subscription_id = subscription_details.metadata.id\n",
    "print(subscription_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cca8df3-78fa-4f5d-8142-4033db8c65a8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# Checking subscription status\n",
    "\n",
    "state = wos_client.subscriptions.get(subscription_id).result.entity.status.state\n",
    "\n",
    "while state not in [\"active\", \"error\"]:\n",
    "    state = wos_client.subscriptions.get(subscription_id).result.entity.status.state\n",
    "    print(state)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5dbd284-f928-4775-8c1d-84a0f58f215d"
   },
   "outputs": [],
   "source": [
    "# Add training, output, and input data schemas to the subscription\n",
    "schemas_patch_document = [\n",
    "    JsonPatchOperation(op=OperationTypes.REPLACE, path='/asset_properties/training_data_schema', value=common_configuration[\"training_data_schema\"]),\n",
    "    JsonPatchOperation(op=OperationTypes.REPLACE, path='/asset_properties/input_data_schema', value=common_configuration[\"input_data_schema\"]),\n",
    "    JsonPatchOperation(op=OperationTypes.REPLACE, path='/asset_properties/output_data_schema', value=common_configuration[\"output_data_schema\"])\n",
    "]\n",
    "\n",
    "wos_client.subscriptions.update(subscription_id=subscription_id, patch_document=schemas_patch_document)\n",
    "\n",
    "# Add data_sources to the subscription\n",
    "data_sources_patch_document=[\n",
    "    JsonPatchOperation(op=OperationTypes.ADD, path='/data_sources', value=[data_source.to_dict() for data_source in data_sources])\n",
    "]\n",
    "\n",
    "wos_client.subscriptions.update(subscription_id=subscription_id, patch_document=data_sources_patch_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "761b87722b6a44838193693f0b132be8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Checking subscription status after the patch operation\n",
    "\n",
    "state = wos_client.subscriptions.get(subscription_id).result.entity.status.state\n",
    "\n",
    "while state not in [\"active\", \"error\"]:\n",
    "    state = wos_client.subscriptions.get(subscription_id).result.entity.status.state\n",
    "    print(state)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cd038b4-4588-41fd-8eec-9bc7ca2f08ed"
   },
   "source": [
    "# 4. Quality monitoring <a name=\"quality\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d90abe2-ceaa-4e53-964f-9a9006a5c0bf"
   },
   "source": [
    "### Enable the quality monitor\n",
    "\n",
    "In the following code cell, default values are set for the quality monitor. You can change the default values by updating the optional `min_feedback_data_size` attribute in the `parameters` dict and set the quality threshold in the `thresholds` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8e3f9579-5f1f-47cf-9953-272c2cf541fa"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    \"min_feedback_data_size\": 200\n",
    "}\n",
    "\n",
    "thresholds = [{\n",
    "        \"metric_id\": \"area_under_roc\",\n",
    "        \"type\": \"lower_limit\",\n",
    "        \"value\": 0.8\n",
    "}]\n",
    "\n",
    "quality_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.QUALITY.ID,\n",
    "    target=target,\n",
    "    parameters=parameters,\n",
    "    thresholds=thresholds\n",
    ").result\n",
    "\n",
    "quality_monitor_instance_id = quality_monitor_details.metadata.id\n",
    "print(quality_monitor_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3a7e576-c875-4ddc-b7cb-0ebc2bb9d4a2"
   },
   "source": [
    "### Check monitor instance status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c136a34b-e0bf-4d0b-bac9-94ad19e46fc6"
   },
   "outputs": [],
   "source": [
    "quality_status = None\n",
    "\n",
    "while quality_status not in (\"active\", \"error\"):\n",
    "    monitor_instance_details = wos_client.monitor_instances.get(monitor_instance_id=quality_monitor_instance_id).result\n",
    "    quality_status = monitor_instance_details.entity.status.state\n",
    "    if quality_status not in (\"active\", \"error\"):\n",
    "        print(datetime.utcnow().strftime('%H:%M:%S'), quality_status)\n",
    "        time.sleep(30)\n",
    "        \n",
    "print(datetime.utcnow().strftime('%H:%M:%S'), quality_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "591d8bfe-e676-4f02-bfba-8845736d3b5e"
   },
   "outputs": [],
   "source": [
    "monitor_instance_details = wos_client.monitor_instances.get(monitor_instance_id=quality_monitor_instance_id).result\n",
    "print(monitor_instance_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff98f5d8-0014-48b1-8e33-b9d72012a909"
   },
   "source": [
    "### Run an on-demand evaluation\n",
    "\n",
    "Please make sure you have data in feedback table in hive. Quality evaluation will use this data for its metrics computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5933f4ea-95e5-4902-9887-52bbfc6cc76e"
   },
   "outputs": [],
   "source": [
    "# Trigger on-demand run\n",
    "\n",
    "monitoring_run_details = wos_client.monitor_instances.run(monitor_instance_id=quality_monitor_instance_id).result\n",
    "monitoring_run_id=monitoring_run_details.metadata.id\n",
    "\n",
    "print(monitoring_run_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e3f2916-c01a-484d-9450-7a105ccf98a2"
   },
   "outputs": [],
   "source": [
    "# Check run status\n",
    "\n",
    "quality_run_status = None\n",
    "while quality_run_status not in (\"finished\", \"error\"):\n",
    "    monitoring_run_details = wos_client.monitor_instances.get_run_details(monitor_instance_id=quality_monitor_instance_id, monitoring_run_id=monitoring_run_id).result\n",
    "    quality_run_status = monitoring_run_details.entity.status.state\n",
    "    if quality_run_status not in (\"finished\", \"error\"):\n",
    "        print(datetime.utcnow().strftime(\"%H:%M:%S\"), quality_run_status)\n",
    "        time.sleep(30)\n",
    "        \n",
    "print(datetime.utcnow().strftime(\"%H:%M:%S\"), quality_run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd3c2a31-d52e-4dfe-868a-e6cd9f953642"
   },
   "source": [
    "### Display quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13ec2812-3c8b-44f0-9bfe-66f80837e04b"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=quality_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5090f31b-9f4d-452d-9ef6-64c42f8f571e"
   },
   "source": [
    "# 5. Drift monitoring <a name=\"drift\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc719938-796f-48d9-9cb3-32e278223a75"
   },
   "source": [
    "### Enable the drift monitor\n",
    "\n",
    "In the following code cell, type a path to the drift configuration tar ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54a4a63e-7cbc-4e0c-862b-d485105e1cfa"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.upload_drift_model(\n",
    "    model_path=\"drift_archive.tar.gz\",\n",
    "    data_mart_id=data_mart_id,\n",
    "    subscription_id=subscription_id\n",
    ").result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd397c89-d2d2-45d7-b1f7-6a09cf94dab3"
   },
   "source": [
    "In the following code cell, default values are set for the drift monitor. You can change the default values by updating the values in the `parameters` section. The `min_samples` parameter controls the number of minimum records required in an evaluation time window for drift analysis to be completed. The `drift_threshold` parameter sets the threshold in decimal format for the drift percentage to trigger an alert. The `train_drift_model` parameter controls whether to learn drift artefacts (drift model training and data constraints learning) by IBM Watson OpenScale via Spark job accessing training data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad99a513-6486-4920-8993-23eb1ddade27"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    \"min_samples\": 100,\n",
    "    \"drift_threshold\": 0.05,\n",
    "    \"train_drift_model\": False\n",
    "}\n",
    "\n",
    "drift_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.DRIFT.ID,\n",
    "    target=target,\n",
    "    parameters=parameters\n",
    ").result\n",
    "\n",
    "drift_monitor_instance_id = drift_monitor_details.metadata.id\n",
    "print(drift_monitor_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b99f35c-ffbb-4232-9176-eff8d35df6c5"
   },
   "source": [
    "### Check monitor instance status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "572aa9f5-afba-4b85-8f91-175802a1f1a8"
   },
   "outputs": [],
   "source": [
    "drift_status = None\n",
    "\n",
    "while drift_status not in (\"active\", \"error\"):\n",
    "    monitor_instance_details = wos_client.monitor_instances.get(monitor_instance_id=drift_monitor_instance_id).result\n",
    "    drift_status = monitor_instance_details.entity.status.state\n",
    "    if drift_status not in (\"active\", \"error\"):\n",
    "        print(datetime.utcnow().strftime('%H:%M:%S'), drift_status)\n",
    "        time.sleep(30)\n",
    "\n",
    "print(datetime.utcnow().strftime('%H:%M:%S'), drift_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58a025e1-1a06-48d6-8eab-c8fcfd6f9809"
   },
   "source": [
    "### Run an on-demand evaluation\n",
    "Please make sure you have data in payload table in hive. Drift evaluation will use this data for its metrics computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5fb4af2-c40f-46f1-9b08-91b3b890571a"
   },
   "outputs": [],
   "source": [
    "# Check Drift monitor instance details\n",
    "\n",
    "monitor_instance_details = wos_client.monitor_instances.get(monitor_instance_id=drift_monitor_instance_id).result\n",
    "print(monitor_instance_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b88a5a85-8725-4434-8812-a64e13e56f00"
   },
   "outputs": [],
   "source": [
    "# Trigger on-demand run\n",
    "\n",
    "monitoring_run_details = wos_client.monitor_instances.run(monitor_instance_id=drift_monitor_instance_id).result\n",
    "monitoring_run_id=monitoring_run_details.metadata.id\n",
    "\n",
    "print(monitoring_run_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d85f7f8d-928d-4f13-804f-59a71c2b4fd0"
   },
   "outputs": [],
   "source": [
    "# Check run status\n",
    "\n",
    "drift_run_status = None\n",
    "while drift_run_status not in (\"finished\", \"error\"):\n",
    "    monitoring_run_details = wos_client.monitor_instances.get_run_details(monitor_instance_id=drift_monitor_instance_id, monitoring_run_id=monitoring_run_id).result\n",
    "    drift_run_status = monitoring_run_details.entity.status.state\n",
    "    if drift_run_status not in (\"finished\", \"error\"):\n",
    "        print(datetime.utcnow().strftime(\"%H:%M:%S\"), drift_run_status)\n",
    "        time.sleep(30)\n",
    "        \n",
    "print(datetime.utcnow().strftime(\"%H:%M:%S\"), drift_run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d00636a4-93b5-4703-97f9-499236ddd027"
   },
   "source": [
    "### Display drift metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60df059b-c066-47be-a814-f6ef50f36db9"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=drift_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f65f4d6-3eed-4f57-86aa-c70ba53c2a6d"
   },
   "source": [
    "# 6. Fairness monitoring <a name=\"fairness\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beb1a400-2083-4fd4-815c-7678cbccdc82"
   },
   "source": [
    "### Enable the fairness monitor\n",
    "\n",
    "The following code cell, will enable the fairness monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adf2ab5c-ff27-4cbc-9e5e-da3d6049a48a"
   },
   "outputs": [],
   "source": [
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "\n",
    "fairness_statistics_json = None\n",
    "with open(\"fairness_statistics.json\", \"r\") as fp:\n",
    "    fairness_statistics_json = json.load(fp)\n",
    "    \n",
    "parameters = fairness_statistics_json[\"parameters\"]\n",
    "thresholds = fairness_statistics_json[\"thresholds\"]\n",
    "\n",
    "fairness_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.FAIRNESS.ID,\n",
    "    target=target,\n",
    "    parameters=parameters,\n",
    "    thresholds=thresholds\n",
    ").result\n",
    "\n",
    "fairness_monitor_instance_id = fairness_monitor_details.metadata.id\n",
    "print(fairness_monitor_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0785fe3e-ffff-40ec-88db-395793cd1fc0"
   },
   "source": [
    "### Check monitor instance status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcc4b37d-4505-42c9-a218-870f2bebd826"
   },
   "outputs": [],
   "source": [
    "fairness_state = fairness_monitor_details.entity.status.state\n",
    "\n",
    "while fairness_state not in (\"active\", \"error\"):\n",
    "    print(datetime.utcnow().strftime('%H:%M:%S'), fairness_state)\n",
    "    monitor_instance_details = wos_client.monitor_instances.get(monitor_instance_id=fairness_monitor_instance_id).result\n",
    "    fairness_state = monitor_instance_details.entity.status.state\n",
    "    time.sleep(30)\n",
    "\n",
    "print(datetime.utcnow().strftime('%H:%M:%S'), fairness_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80c1e0ac-faa9-4779-9942-d4adc7ec0252"
   },
   "source": [
    "### Run an on-demand evaluation\n",
    "Please make sure you have data in payload table in hive. Fairness evaluation will use this data for its metrics computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d16e9269-ca4b-4ce3-9b41-03c88174f01b"
   },
   "outputs": [],
   "source": [
    "# Trigger on-demand run\n",
    "\n",
    "monitoring_run_details = wos_client.monitor_instances.run(monitor_instance_id=fairness_monitor_instance_id).result\n",
    "monitoring_run_id=monitoring_run_details.metadata.id\n",
    "\n",
    "print(monitoring_run_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1ac6adb-1163-471b-b78d-cfc4b8a170f9"
   },
   "outputs": [],
   "source": [
    "# Check run status\n",
    "\n",
    "fairness_run_status = monitoring_run_details.entity.status.state\n",
    "while fairness_run_status not in (\"finished\", \"error\"):\n",
    "    print(datetime.utcnow().strftime(\"%H:%M:%S\"), fairness_run_status)\n",
    "    monitoring_run_details = wos_client.monitor_instances.get_run_details(monitor_instance_id=fairness_monitor_instance_id, monitoring_run_id=monitoring_run_id).result\n",
    "    fairness_run_status = monitoring_run_details.entity.status.state\n",
    "    time.sleep(30)\n",
    "        \n",
    "print(datetime.utcnow().strftime(\"%H:%M:%S\"), fairness_run_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a57fbb9-246e-4264-b5d6-d64a03884469"
   },
   "source": [
    "### Display fairness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3675e747-e098-412e-9c42-f3031c828b48"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=fairness_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94ee1c52-989a-4b2c-8a6c-d61e307a5d87"
   },
   "source": [
    "# 7. Explainability monitoring <a name=\"explainability\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37a1a652-6ca7-4a84-9838-3bb107788d80"
   },
   "source": [
    "### Enable the explainability monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d86ef9b4-395d-45ac-aee8-517ccff2f56d"
   },
   "source": [
    "#### Upload explainability configuration archive\n",
    "In the following code cell, type the path to the explainability configuration archive tar ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb7fc31c-9321-460a-bb07-6a6fbfe3d18f"
   },
   "outputs": [],
   "source": [
    "with open(\"explainability.tar.gz\", mode=\"rb\") as explainability_tar:\n",
    "    wos_client.monitor_instances.upload_explainability_archive(subscription_id=subscription_id, archive=explainability_tar)\n",
    "\n",
    "print(\"Uploaded explainability archive successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a05a2faa-8a2f-4e8f-b4ac-d688d826f559"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "# Uncomment the below lines to enable lime global explanation. Available from Cloud Pak for Data version 4.6.4 onwards.\n",
    "#    \"global_explanation\": {\n",
    "#        \"enabled\": True,  # Flag to enable global explanation \n",
    "#        \"explanation_method\": \"lime\",\n",
    "#        \"sample_size\": 1000, # [Optional] The sample size of records to be used for generating payload data global explanation. If not specified entire data in the payload window is used.\n",
    "#    }\n",
    "}\n",
    "\n",
    "explainability_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.EXPLAINABILITY.ID,\n",
    "    target=target,\n",
    "    parameters=parameters\n",
    ").result\n",
    "\n",
    "explainability_monitor_instance_id = explainability_monitor_details.metadata.id\n",
    "print(explainability_monitor_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c739d08f-ffd1-44be-a8a2-374935211c4b",
    "tags": []
   },
   "source": [
    "### Check monitor instance status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04f83904-1c33-4f0f-a2c1-ae74b4a4f382"
   },
   "outputs": [],
   "source": [
    "explainability_status = None\n",
    "\n",
    "while explainability_status not in (\"active\", \"error\"):\n",
    "    monitor_instance_details = wos_client.monitor_instances.get(monitor_instance_id=explainability_monitor_instance_id).result\n",
    "    explainability_status = monitor_instance_details.entity.status.state\n",
    "    if explainability_status not in (\"active\", \"error\"):\n",
    "        print(datetime.utcnow().strftime('%H:%M:%S'), explainability_status)\n",
    "        time.sleep(30)\n",
    "\n",
    "print(datetime.utcnow().strftime('%H:%M:%S'), explainability_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5444b917-1c8e-469c-83a1-b6575a83c616"
   },
   "source": [
    "### Run an on-demand evaluation\n",
    "Please make sure you have data in Explain queue table in hive. Explainability will use this data for computing explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee2a075c-4a44-4612-88a7-1d6783cbb382"
   },
   "outputs": [],
   "source": [
    "# Check Explainbility monitor instance details\n",
    "\n",
    "monitor_instance_details = wos_client.monitor_instances.get(monitor_instance_id=explainability_monitor_instance_id).result\n",
    "print(monitor_instance_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1c6c25d-64af-4afa-a8d2-a2988747f0c6"
   },
   "outputs": [],
   "source": [
    "# Trigger on-demand run\n",
    "\n",
    "monitoring_run_details = wos_client.monitor_instances.run(monitor_instance_id=explainability_monitor_instance_id).result\n",
    "monitoring_run_id=monitoring_run_details.metadata.id\n",
    "\n",
    "print(monitoring_run_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f827a07-a570-4c46-a5f0-5f71bade9454"
   },
   "outputs": [],
   "source": [
    "# Check run status\n",
    "\n",
    "explainability_run_status = None\n",
    "while explainability_run_status not in (\"finished\", \"error\"):\n",
    "    monitoring_run_details = wos_client.monitor_instances.get_run_details(monitor_instance_id=explainability_monitor_instance_id, monitoring_run_id=monitoring_run_id).result\n",
    "    explainability_run_status = monitoring_run_details.entity.status.state\n",
    "    if explainability_run_status not in (\"finished\", \"error\"):\n",
    "        print(datetime.utcnow().strftime(\"%H:%M:%S\"), explainability_run_status)\n",
    "        time.sleep(60)\n",
    "        \n",
    "print(datetime.utcnow().strftime(\"%H:%M:%S\"), explainability_run_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the global explanation stability metric. When lime global explanation is enabled, the monitor run computes global explanation and publishes global_explanation_stability metric.\n",
    "# wos_client.monitor_instances.show_metrics(monitor_instance_id=explainability_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26ac04ed-e76f-412e-b30e-2a96b5d5b81c"
   },
   "source": [
    "### Display sample explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ae76e5a-b98f-4988-9007-ec8c92a97a91"
   },
   "outputs": [],
   "source": [
    "explanations = wos_client.monitor_instances.get_all_explaination_tasks(subscription_id=subscription_id).result.to_dict()\n",
    "print(explanations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7879530640b049a18f45751445a9379b"
   },
   "source": [
    "### Generate on demand Contrastive explanation\n",
    "\n",
    "Choose any record from payload logging table or Explain Queue table and generate Lime, Contrastive explanations for the record. Please note that contrastive explanations are only supported for structured classification models. So specify the explanation_types accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46cc56218e9a4da987789c9a7cc3580f"
   },
   "outputs": [],
   "source": [
    "import time\n",
    " # Please enter scoring id(from payload table or Explain Queue table), for which you want to generate an explanation\n",
    " # scoring_ids = [\"<scoring_id_from_pl_or_explain_queue_table>\"]\n",
    "\n",
    "# As an example, we will generate a contrastive explanation for the first scoring id from the list of explanations generated above\n",
    "# as part of the Explainability monitor run\n",
    "scoring_ids = [explanations[\"explanation_values\"][0][1]]\n",
    "print(\"Running explanations on scoring IDs: {}\".format(scoring_ids))\n",
    "\n",
    "explanation_types = [\"lime\", \"contrastive\"]\n",
    "explanation_task_ids = wos_client.monitor_instances.explanation_tasks(scoring_ids=scoring_ids, subscription_id=subscription_id, explanation_types=explanation_types).result.metadata.explanation_task_ids\n",
    "explanation_task_id = explanation_task_ids[0]\n",
    "\n",
    "print(\"Getting explanation for explanation task id: {}\".format(explanation_task_id))\n",
    "explanation = wos_client.monitor_instances.get_explanation_tasks(explanation_task_id, subscription_id=subscription_id).result\n",
    "while explanation.entity.status.state not in (\"finished\", \"error\"):\n",
    "        explanation = wos_client.monitor_instances.get_explanation_tasks(explanation_task_id, subscription_id=subscription_id).result\n",
    "        explanation_run_status = explanation.entity.status.state\n",
    "        if explanation_run_status not in (\"finished\", \"error\"):\n",
    "            print(datetime.utcnow().strftime(\"%H:%M:%S\"), explanation_run_status)\n",
    "            time.sleep(60)\n",
    "            \n",
    "            \n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "694efb3641b44f25a5bd97bbada224e4"
   },
   "source": [
    "### Cleanup the untarred files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "843b2e53c5764050960445dbb8bc82ea"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "files = [\"common_configuration.json\", \"explainability.tar.gz\", \"drift_archive.tar.gz\", \"fairness_statistics.json\"]\n",
    "for file in files:\n",
    "    if os.path.isfile(file):\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1133c179-35b3-4cc5-9894-200eee7455ac"
   },
   "source": [
    "## Congratulations!\n",
    "\n",
    "You have finished the Batch demo for IBM Watson OpenScale by using Apache Spark on Cloud Pak for Data IBM Analytics Engine. You can now view the [Watson OpenScale Dashboard](https://url-to-your-cp4d-cluster/aiopenscale). Click the tile for the **German Credit model** to see the quality, drift and fairness monitors. Click the timeseries graph to get detailed information on transactions during a specific time window."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "37b82c9850f337b3f8e26ef3a35bf87c9f2cfa1e4ad2c96ec00819afd6ebf7e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
