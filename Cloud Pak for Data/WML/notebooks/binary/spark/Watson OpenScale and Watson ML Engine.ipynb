{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "130546d4-d72c-46f1-a506-246ace42ad56"
   },
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6d32920-c6f8-4df6-91a7-925640a9920a"
   },
   "source": [
    "# Working with Watson Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab7073b7-baf8-48ba-b9fb-e39e497596aa"
   },
   "source": [
    "This notebook should be run using with **Default Spark 3.2.x & Python 3.9** or **Python 3.10** runtime environment. **If you are viewing this in Watson Studio and do not see Python 3.9.x in the upper right corner of your screen, please update the runtime now.** It requires service credentials for the following services:\n",
    "  * Watson OpenScale\n",
    "  * Watson Machine Learning \n",
    "  * DB2\n",
    "\n",
    "  \n",
    "The notebook will train, create and deploy a German Credit Risk model, configure OpenScale to monitor that deployment, and inject seven days' worth of historical records and measurements for viewing in the OpenScale Insights dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75d4d5c7-59e0-47b6-8073-d5fe7b60a28a"
   },
   "source": [
    "### Contents\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Model building and deployment](#model)\n",
    "- [OpenScale configuration](#openscale)\n",
    "- [Quality monitor and feedback logging](#quality)\n",
    "- [Fairness, drift monitoring and explanations](#fairness)\n",
    "- [Custom monitors and metrics](#custom)\n",
    "- [Historical data](#historical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c3c7fcc-8701-45f3-ab34-af1b093b590c"
   },
   "source": [
    "# Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b4212ee-4116-4a47-a586-f0997df1ec53"
   },
   "source": [
    "## Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57a4e88e-7792-4ef9-b8c2-c96cd25e7da8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eb75b61-93b5-4139-96d5-fae98c8c9173",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pyspark==3.3.0 --no-cache | tail -n 1\n",
    "\n",
    "# If you are running this notebook in non IBM Watson Studio env then uncomment the below pip statements and run it.\n",
    "#!pip install --upgrade pandas==1.2.3 --no-cache | tail -n 1  \n",
    "#!pip install --upgrade requests==2.23 --no-cache | tail -n 1\n",
    "#!pip install numpy==1.20.1 --no-cache | tail -n 1\n",
    "#!pip install SciPy --no-cache | tail -n 1\n",
    "#!pip install lime --no-cache | tail -n 1\n",
    "\n",
    "!pip install --upgrade ibm-watson-machine-learning --user | tail -n 1\n",
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd55a125-14e4-440c-a2ee-c58813d75f9e"
   },
   "source": [
    "### Action: restart the kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39964944-8353-41ab-bf19-72dec9dd3eae"
   },
   "source": [
    "## Configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2abe81f0-cd47-4fe0-9b5c-505712c17752"
   },
   "source": [
    "- WOS_CREDENTIALS (CP4D)\n",
    "- WML_CREDENTIALS (CP4D)\n",
    "- DATABASE_CREDENTIALS (DB2 on CP4D or Cloud Object Storage (COS))\n",
    "- SCHEMA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f499be0-0ed7-46c9-9bf4-753c2529525f"
   },
   "outputs": [],
   "source": [
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"***\",\n",
    "    \"username\": \"***\",\n",
    "    \"password\": \"***\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4515adc7fa8b46ac8e6e9ac59d396b7f"
   },
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {\n",
    "                   \"url\": \"***\",\n",
    "                   \"username\": \"***\",\n",
    "                   \"password\" : \"***\",\n",
    "                   \"instance_id\": \"wml_local\",\n",
    "                   \"version\" : \"4.5\" #If your env is CP4D 4.x.x then specify \"4.x.x\" instead of \"4.5\"\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feafb75f-4fb1-4dcf-85c3-07d4b5d888a4"
   },
   "outputs": [],
   "source": [
    "#IBM DB2 database connection format example\n",
    "DATABASE_CREDENTIALS = {\n",
    "    \"hostname\":\"***\",\n",
    "    \"username\":\"***\",\n",
    "    \"password\":\"***\",\n",
    "    \"database\":\"***\",\n",
    "    \"port\":50000, #provide your actual DB2 port number (as integer value)\n",
    "    \"ssl\":\"***\",\n",
    "    \"sslmode\":\"***\",\n",
    "    \"certificate_base64\":\"***\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3161161a-242a-4938-abc5-25ff8095748b"
   },
   "source": [
    "### Action: put created schema name below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "973fda16-bc37-46d7-b193-2d775de597d6"
   },
   "outputs": [],
   "source": [
    "SCHEMA_NAME = 'AIOSFASTPATHICP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "749014a4-f65f-4e78-94d0-ee2738519721"
   },
   "source": [
    "## Run the notebook\n",
    "\n",
    "At this point, the notebook is ready to run. You can either run the cells one at a time, or click the **Kernel** option above and select **Restart and Run All** to run all the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4fe0e5c-dead-4c2a-a5fc-de179245bdf0"
   },
   "source": [
    "# Model building and deployment <a name=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9c44abc-9abb-4e6c-86bc-cb02dd7e8bb8"
   },
   "source": [
    "In this section you will learn how to train Spark MLLib model and next deploy it as web-service using Watson Machine Learning service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b69186c1-b491-40a7-a657-4ca112e82209"
   },
   "source": [
    "## Load the training data from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1a634fc-4524-494c-842f-3f9a0d4cba9c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm german_credit_data_biased_training.csv\n",
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/Cloud%20Pak%20for%20Data/WML/assets/data/credit_risk/german_credit_data_biased_training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a7b9f92-0fdb-4eb9-9c56-3f56653e08c5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "pd_data = pd.read_csv(\"german_credit_data_biased_training.csv\", sep=\",\", header=0)\n",
    "df_data = spark.read.csv(path=\"german_credit_data_biased_training.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84a9f61c-d459-4063-8b42-8c74d6fed26e"
   },
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08482041-a3cb-4649-9faa-ba434680a545",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f82e8b88-d2f7-47a8-910c-86ee276db604",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of records: \" + str(df_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7b30f4e-0fc5-4b8f-85cd-e8a1097f0c9f"
   },
   "source": [
    "## Visualize data with pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f95f404d-b4e8-4cbc-aecd-a6711fff985f"
   },
   "outputs": [],
   "source": [
    "#import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "353ac205-d447-46b1-bfeb-39457db0536f",
    "pixiedust": {
     "displayParams": {
      "aggregation": "COUNT",
      "chartsize": "51",
      "handlerId": "pieChart",
      "keyFields": "Risk",
      "mpld3": "false",
      "rendererId": "bokeh"
     },
     "pixieapp": {
      "name": "Spark German Risk Model - Final",
      "runtime": "spark-mllib_2.3",
      "type": "mllib_2.3"
     }
    }
   },
   "outputs": [],
   "source": [
    "display(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7478be73-75c1-4f83-9a13-3b807a7b3925"
   },
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c210dca2-86ee-4a2d-bb00-907359668466",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark_df = df_data\n",
    "(train_data, test_data) = spark_df.randomSplit([0.8, 0.2], 24)\n",
    "\n",
    "MODEL_NAME = \"Spark German Risk Model - Final\"\n",
    "DEPLOYMENT_NAME = \"Spark German Risk Deployment - Final\"\n",
    "\n",
    "print(\"Number of records for training: \" + str(train_data.count()))\n",
    "print(\"Number of records for evaluation: \" + str(test_data.count()))\n",
    "\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "001138a9-3891-4b23-a4f6-716bfc09a7cb"
   },
   "source": [
    "The code below creates a Random Forest Classifier with Spark, setting up string indexers for the categorical features and the label column. Finally, this notebook creates a pipeline including the indexers and the model, and does an initial Area Under ROC evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3e9dfabb-15fc-4ea0-aaeb-b58c1cc5ec51",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "features = [x for x in spark_df.columns if x != 'Risk']\n",
    "categorical_features = ['CheckingStatus', 'CreditHistory', 'LoanPurpose', 'ExistingSavings', 'EmploymentDuration', 'Sex', 'OthersOnLoan', 'OwnsProperty', 'InstallmentPlans', 'Housing', 'Job', 'Telephone', 'ForeignWorker']\n",
    "categorical_num_features = [x + '_IX' for x in categorical_features]\n",
    "si_list = [StringIndexer(inputCol=x, outputCol=y) for x, y in zip(categorical_features, categorical_num_features)]\n",
    "va_features = VectorAssembler(inputCols=categorical_num_features + [x for x in features if x not in categorical_features], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a42978de-e7a6-4c3c-a075-98f555ddc8c8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "si_label = StringIndexer(inputCol=\"Risk\", outputCol=\"label\").fit(spark_df)\n",
    "label_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=si_label.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99a07071-6748-4927-955e-86a463c55167",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages= si_list + [si_label, va_features, classifier, label_converter])\n",
    "\n",
    "model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50b6dcdc-e0da-473f-8633-914b94b5f715"
   },
   "source": [
    "**Note**: If you want filter features from model output please replace `*` with feature names to be retained in `SQLTransformer` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8a29125b-03b6-4565-8993-056acf9ff0a6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)\n",
    "evaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",  metricName='areaUnderROC')\n",
    "area_under_curve = evaluatorDT.evaluate(predictions)\n",
    "\n",
    "evaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",  metricName='areaUnderPR')\n",
    "area_under_PR = evaluatorDT.evaluate(predictions)\n",
    "#default evaluation is areaUnderROC\n",
    "print(\"areaUnderROC = %g\" % area_under_curve, \"areaUnderPR = %g\" % area_under_PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8800524-71b7-4193-9f3a-24e92d23a17f"
   },
   "outputs": [],
   "source": [
    "# extra code: evaluate more metrics by exporting them into pandas and numpy\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = predictions.toPandas()['prediction']\n",
    "y_pred = ['Risk' if pred == 1.0 else 'No Risk' for pred in y_pred]\n",
    "y_test = test_data.toPandas()['Risk']\n",
    "print(classification_report(y_test, y_pred, target_names=['Risk', 'No Risk']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60195a0348f64265a6bc2722e89db376"
   },
   "source": [
    "## Save training data to Cloud Object Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8842f7f8d5644ae697bf756ff3cc8cec"
   },
   "source": [
    "## Cloud object storage details\n",
    "In next cells, you will need to paste some credentials to Cloud Object Storage. If you haven't worked with COS yet please visit getting started with COS tutorial. You can find COS_API_KEY_ID and COS_RESOURCE_CRN variables in Service Credentials in menu of your COS instance. Used COS Service Credentials must be created with Role parameter set as Writer. Later training data file will be loaded to the bucket of your instance and used as training refecence in subsription.\n",
    "COS_ENDPOINT variable can be found in Endpoint field of the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "490ee79fecb94755a1e0fba50f62ab2b"
   },
   "outputs": [],
   "source": [
    "IAM_URL=\"https://iam.ng.bluemix.net/oidc/token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dffd7c56da1745368ac1a5dc3016f1fa"
   },
   "outputs": [],
   "source": [
    "COS_API_KEY_ID = \"***\"\n",
    "COS_RESOURCE_CRN = \"***\" # eg \"crn:v1:bluemix:public:cloud-object-storage:global:a/3bf0d9003abfb5d29761c3e97696b71c:d6f04d83-6c4f-4a62-a165-696756d63903::\"\n",
    "COS_ENDPOINT = \"***\" # Current list avaiable at https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d0b0f4dbd584cf98fdae398087a023f"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"***\" #example: \"credit-risk-training-data\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da2ce7a982104d0e87e8c42d58722779"
   },
   "outputs": [],
   "source": [
    "training_data_file_name=\"german_credit_data_biased_training.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6effe3cf584040cd80f3c95567547ef8"
   },
   "outputs": [],
   "source": [
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config, ClientError\n",
    "\n",
    "cos_client = ibm_boto3.resource(\"s3\",\n",
    "    ibm_api_key_id=COS_API_KEY_ID,\n",
    "    ibm_service_instance_id=COS_RESOURCE_CRN,\n",
    "    ibm_auth_endpoint=\"https://iam.bluemix.net/oidc/token\",\n",
    "    config=Config(signature_version=\"oauth\"),\n",
    "    endpoint_url=COS_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5102d0a46bb6496e9f2e819920c90d82"
   },
   "outputs": [],
   "source": [
    "with open(training_data_file_name, \"rb\") as file_data:\n",
    "    cos_client.Object(BUCKET_NAME, training_data_file_name).upload_fileobj(\n",
    "        Fileobj=file_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e27918b3-79da-4acf-b56d-7d7141b42b0c"
   },
   "source": [
    "## Publish the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c744359c-5462-4c4d-a83b-c9bc7b340299"
   },
   "source": [
    "In this section, the notebook uses Watson Machine Learning to save the model (including the pipeline) to the WML instance. Previous versions of the model are removed so that the notebook can be run again, resetting all data for another demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "678d87c3-5537-4c5a-be6b-5ef1d0ce24e4"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "wml_client = APIClient(WML_CREDENTIALS)\n",
    "wml_client.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "735b2e1f-5561-4068-97b0-cfbca2dc3e29"
   },
   "outputs": [],
   "source": [
    "space_name = \"tutorial-space\"\n",
    "# create the space and set it as default\n",
    "space_meta_data = {\n",
    "        wml_client.spaces.ConfigurationMetaNames.NAME : space_name,\n",
    "        wml_client.spaces.ConfigurationMetaNames.DESCRIPTION : 'tutorial_space'\n",
    "}\n",
    "spaces = wml_client.spaces.get_details()['resources']\n",
    "space_id = None\n",
    "for space in spaces:\n",
    "    if space['entity']['name'] == space_name:\n",
    "        space_id = space[\"metadata\"][\"id\"]\n",
    "if space_id is None:\n",
    "    space_id = wml_client.spaces.store(meta_props=space_meta_data)[\"metadata\"][\"id\"]\n",
    "\n",
    "print(space_id)\n",
    "wml_client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcc57977-7a37-4626-91d2-3853ef427bed"
   },
   "source": [
    "### Remove existing model and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfa0cc14-cead-4d07-bd0e-60584e5d996d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deployments_list = wml_client.deployments.get_details()\n",
    "for deployment in deployments_list[\"resources\"]:\n",
    "    model_id = deployment[\"entity\"][\"asset\"][\"id\"]\n",
    "    deployment_id = deployment[\"metadata\"][\"id\"]\n",
    "    if deployment[\"metadata\"][\"name\"] == DEPLOYMENT_NAME:\n",
    "        print(\"Deleting deployment id\", deployment_id)\n",
    "        wml_client.deployments.delete(deployment_id)\n",
    "        print(\"Deleting model id\", model_id)\n",
    "        wml_client.repository.delete(model_id)\n",
    "wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed0e969b-814b-4e80-bc2e-d34aa4988371"
   },
   "source": [
    "#### Add training data reference either from DB2 on CP4D or Cloud Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bd73ba77-a991-4b2f-82e4-17b5ea603e2d"
   },
   "outputs": [],
   "source": [
    "# COS training data reference example format\n",
    "\n",
    "datasource_type = wml_client.connections.get_datasource_type_uid_by_name('bluemixcloudobjectstorage')\n",
    "conn_meta_props= {\n",
    "    wml_client.connections.ConfigurationMetaNames.NAME: \"Connection My COS \",\n",
    "    wml_client.connections.ConfigurationMetaNames.DATASOURCE_TYPE: datasource_type,\n",
    "    wml_client.connections.ConfigurationMetaNames.DESCRIPTION: \"Connection to my COS\",\n",
    "    wml_client.connections.ConfigurationMetaNames.PROPERTIES: {\n",
    "        'bucket': BUCKET_NAME,\n",
    "        'api_key': COS_API_KEY_ID,\n",
    "        'resource_instance_id': COS_RESOURCE_CRN,\n",
    "        'iam_url': \"https://iam.ng.bluemix.net/oidc/token\",\n",
    "        'url': COS_ENDPOINT\n",
    "    }\n",
    "}\n",
    "\n",
    "conn_details = wml_client.connections.create(meta_props=conn_meta_props)\n",
    "connection_id = wml_client.connections.get_uid(conn_details)\n",
    "\n",
    "training_data_references = [\n",
    "    {\n",
    "        \"id\": \"German Credit Risk\", \n",
    "        \"type\": \"connection_asset\",\n",
    "        \"connection\": {\n",
    "            \"id\": connection_id,\n",
    "            \"href\": \"/v2/connections/\" + connection_id + \"?space_id=\" + space_id\n",
    "\n",
    "        },\n",
    "        \"location\": {\n",
    "            \"bucket\": BUCKET_NAME,\n",
    "            \"file_name\": training_data_file_name\n",
    "        }\n",
    "    }    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45893978c72045868efa13ccf94da8d1"
   },
   "outputs": [],
   "source": [
    "software_spec_uid = wml_client.software_specifications.get_id_by_name(\"spark-mllib_3.2\")\n",
    "print(\"Software Specification ID: {}\".format(software_spec_uid))\n",
    "model_props = {\n",
    "        wml_client._models.ConfigurationMetaNames.NAME:\"{}\".format(MODEL_NAME),\n",
    "        wml_client._models.ConfigurationMetaNames.TYPE: \"mllib_3.2\",\n",
    "        wml_client._models.ConfigurationMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n",
    "        wml_client._models.ConfigurationMetaNames.LABEL_FIELD: \"Risk\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f211368d-f5c2-4918-8a7b-de0a0998cfd1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Storing model ...\")\n",
    "published_model_details = wml_client.repository.store_model(\n",
    "    model=model, \n",
    "    meta_props=model_props, \n",
    "    training_data=train_data, \n",
    "    pipeline=pipeline)\n",
    "\n",
    "model_uid = wml_client.repository.get_model_id(published_model_details)\n",
    "print(\"Done\")\n",
    "print(\"Model ID: {}\".format(model_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3d03a8fa-7776-46ae-891c-df2c8a0f92cb"
   },
   "outputs": [],
   "source": [
    "wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e7736e1-60b7-4c28-a307-3bea649ec3d3"
   },
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bfdd696-cd67-4a9f-b4e8-d17bcbad9a3f"
   },
   "source": [
    "The next section of the notebook deploys the model as a RESTful web service in Watson Machine Learning. The deployed model will have a scoring URL you can use to send data to the model for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e0e6279-2acb-4d98-996f-eeb140536f8d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deployment_details = wml_client.deployments.create(\n",
    "    model_uid, \n",
    "    meta_props={\n",
    "        wml_client.deployments.ConfigurationMetaNames.NAME: \"{}\".format(DEPLOYMENT_NAME),\n",
    "        wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    ")\n",
    "scoring_url = wml_client.deployments.get_scoring_href(deployment_details)\n",
    "deployment_uid=wml_client.deployments.get_id(deployment_details)\n",
    "\n",
    "print(\"Scoring URL:\" + scoring_url)\n",
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f4a190b19bf47f48fd1fc5057f73066"
   },
   "source": [
    "## Sample scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "603cde429f9c43c98b8986d413f0366d"
   },
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\",\n",
    "                  \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\",\n",
    "                  \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n",
    "                  \"Telephone\", \"ForeignWorker\"]\n",
    "values = [\n",
    "            [\"no_checking\", 13, \"credits_paid_to_date\", \"car_new\", 1343, \"100_to_500\", \"1_to_4\", 2, \"female\", \"none\", 3,\n",
    "             \"savings_insurance\", 46, \"none\", \"own\", 2, \"skilled\", 1, \"none\", \"yes\"],\n",
    "            [\"no_checking\", 24, \"prior_payments_delayed\", \"furniture\", 4567, \"500_to_1000\", \"1_to_4\", 4, \"male\", \"none\",\n",
    "             4, \"savings_insurance\", 36, \"none\", \"free\", 2, \"management_self-employed\", 1, \"none\", \"yes\"],\n",
    "        ]\n",
    "\n",
    "scoring_payload = {\"input_data\": [{\"fields\": fields, \"values\": values}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43fbce986afd41898d3f59de4e7fffd8"
   },
   "outputs": [],
   "source": [
    "scoring_response = wml_client.deployments.score(deployment_uid, scoring_payload)\n",
    "scoring_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f351f89e-94f8-4efa-bc4a-f26ef517fc7c"
   },
   "source": [
    "# Configure OpenScale <a name=\"openscale\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7603056-701e-430e-809c-3df57c70e2e0"
   },
   "source": [
    "The notebook will now import the necessary libraries and set up a Python OpenScale client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a36f3b0f-4705-4f3d-9f05-e6f0a455bd95",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "from ibm_watson_openscale import APIClient\n",
    "\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0bf5aaa-e68e-4a36-84ae-7689949c4c1f"
   },
   "outputs": [],
   "source": [
    "authenticator = CloudPakForDataAuthenticator(\n",
    "        url=WOS_CREDENTIALS['url'],\n",
    "        username=WOS_CREDENTIALS['username'],\n",
    "        password=WOS_CREDENTIALS['password'],\n",
    "        disable_ssl_verification=True\n",
    "    )\n",
    "\n",
    "wos_client = APIClient(service_url=WOS_CREDENTIALS['url'],authenticator=authenticator)\n",
    "wos_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b26d6223-924a-42b9-b251-1e1933ac7b97"
   },
   "source": [
    "## Create datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2069a88d-61fb-436a-a17c-f0032999ecd7"
   },
   "source": [
    "### Set up datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49e8170b-c2da-4785-8d35-6c34b003ad88"
   },
   "source": [
    "Watson OpenScale uses a database to store payload logs and calculated metrics. If database credentials were supplied, the datamart will be created there unless there is an existing datamart and the KEEP_MY_INTERNAL_POSTGRES variable is set to True. If an OpenScale datamart exists in Db2 or PostgreSQL, the existing datamart will be used and no data will be overwritten.\n",
    "\n",
    "Prior instances of the German Credit model will be removed from OpenScale monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "304bc653696e4d90a521a279d3551135"
   },
   "outputs": [],
   "source": [
    "wos_client.data_marts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c81b009f-5a03-4aa8-ac8f-619f39de8aad"
   },
   "outputs": [],
   "source": [
    "data_marts = wos_client.data_marts.list().result.data_marts\n",
    "if len(data_marts) == 0:\n",
    "    if DB_CREDENTIALS is not None:\n",
    "        if SCHEMA_NAME is None: \n",
    "            print(\"Please specify the SCHEMA_NAME and rerun the cell\")\n",
    "\n",
    "        print('Setting up external datamart')\n",
    "        added_data_mart_result = wos_client.data_marts.add(\n",
    "                background_mode=False,\n",
    "                name=\"WOS Data Mart\",\n",
    "                description=\"Data Mart created by WOS tutorial notebook\",\n",
    "                database_configuration=DatabaseConfigurationRequest(\n",
    "                  database_type=DatabaseType.DB2,\n",
    "                    credentials=PrimaryStorageCredentialsLong(\n",
    "                        hostname=DATABASE_CREDENTIALS['hostname'],\n",
    "                        username=DATABASE_CREDENTIALS['username'],\n",
    "                        password=DATABASE_CREDENTIALS['password'],\n",
    "                        db=DATABASE_CREDENTIALS['database'],\n",
    "                        port=DATABASE_CREDENTIALS['port'],\n",
    "                        ssl=DATABASE_CREDENTIALS['ssl'],\n",
    "                        sslmode=DATABASE_CREDENTIALS['sslmode'],\n",
    "                        certificate_base64=DATABASE_CREDENTIALS['certificate_base64']\n",
    "                    ),\n",
    "                    location=LocationSchemaName(\n",
    "                        schema_name= SCHEMA_NAME\n",
    "                    )\n",
    "                )\n",
    "             ).result\n",
    "    else:\n",
    "        print('Setting up internal datamart')\n",
    "        added_data_mart_result = wos_client.data_marts.add(\n",
    "                background_mode=False,\n",
    "                name=\"WOS Data Mart\",\n",
    "                description=\"Data Mart created by WOS tutorial notebook\", \n",
    "                internal_database = True).result\n",
    "        \n",
    "    data_mart_id = added_data_mart_result.metadata.id\n",
    "    \n",
    "else:\n",
    "    data_mart_id=data_marts[0].metadata.id\n",
    "    print('Using existing datamart {}'.format(data_mart_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbd4919034234cfa8fb20553e4fc77fd"
   },
   "source": [
    "## Remove existing service provider connected with used WML instance.\n",
    "Multiple service providers for the same engine instance are avaiable in Watson OpenScale. To avoid multiple service providers of used WML instance in the tutorial notebook the following code deletes existing service provder(s) and then adds new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94324f4327f24ac180048f2529fe1b2d"
   },
   "outputs": [],
   "source": [
    "SERVICE_PROVIDER_NAME = \"Watson Machine Learning V2\"\n",
    "SERVICE_PROVIDER_DESCRIPTION = \"Added by tutorial WOS notebook.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dde66305683a4f38b7b6b97a1801478e"
   },
   "outputs": [],
   "source": [
    "service_providers = wos_client.service_providers.list().result.service_providers\n",
    "for service_provider in service_providers:\n",
    "    service_instance_name = service_provider.entity.name\n",
    "    if service_instance_name == SERVICE_PROVIDER_NAME:\n",
    "        service_provider_id = service_provider.metadata.id\n",
    "        wos_client.service_providers.delete(service_provider_id)\n",
    "        print(\"Deleted existing service_provider for WML instance: {}\".format(service_provider_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdfac8ed7e0149bd8bba0674fc29f8cc"
   },
   "source": [
    "## Add service provider\n",
    "Watson OpenScale needs to be bound to the Watson Machine Learning instance to capture payload data into and out of the model.\n",
    "\n",
    "**Note:** You can bind more than one engine instance if needed by calling `wos_client.service_providers.add` method. Next, you can refer to particular service provider using `service_provider_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c146d6fe301e43b08d0ca4fab34362df"
   },
   "outputs": [],
   "source": [
    "added_service_provider_result = wos_client.service_providers.add(\n",
    "        name=SERVICE_PROVIDER_NAME,\n",
    "        description=SERVICE_PROVIDER_DESCRIPTION,\n",
    "        service_type=ServiceTypes.WATSON_MACHINE_LEARNING,\n",
    "        deployment_space_id = space_id,\n",
    "        operational_space_id = \"production\",\n",
    "        credentials=WMLCredentialsCP4D(\n",
    "            url=WML_CREDENTIALS[\"url\"],\n",
    "            username=WML_CREDENTIALS[\"username\"],\n",
    "            password=WML_CREDENTIALS[\"password\"],\n",
    "            instance_id=None\n",
    "        ),\n",
    "        background_mode=False\n",
    "    ).result\n",
    "service_provider_id = added_service_provider_result.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d255529f755a4ede994063172455f2d9"
   },
   "outputs": [],
   "source": [
    "wos_client.service_providers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ea735e06d844309abdf2b7b41c560df"
   },
   "outputs": [],
   "source": [
    "asset_deployment_details = wos_client.service_providers.list_assets(data_mart_id=data_mart_id, service_provider_id=service_provider_id, deployment_id = deployment_uid, deployment_space_id = space_id).result['resources'][0]\n",
    "asset_deployment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87ab02f282df4089863f0d1f07881573"
   },
   "outputs": [],
   "source": [
    "model_asset_details_from_deployment=wos_client.service_providers.get_deployment_asset(data_mart_id=data_mart_id,service_provider_id=service_provider_id,deployment_id=deployment_uid,deployment_space_id=space_id)\n",
    "model_asset_details_from_deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62c326d9-05a5-402c-ab56-9ae881d10eba"
   },
   "source": [
    "## Subscriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04e9ace9-0788-47d5-9316-ddad6492214c"
   },
   "source": [
    "### Remove existing credit risk subscriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcf012cb-c9ca-41a8-9240-9768e5a1583f"
   },
   "source": [
    "This code removes previous subscriptions to the German Credit model to refresh the monitors with the new model and new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ec262e8da76433882ce39ef29bda26a"
   },
   "outputs": [],
   "source": [
    "wos_client.subscriptions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "416c6961-0010-46f8-b25c-11a1e8cf5f21",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subscriptions = wos_client.subscriptions.list().result.subscriptions\n",
    "for subscription in subscriptions:\n",
    "    sub_model_id = subscription.entity.asset.asset_id\n",
    "    if sub_model_id == model_uid:\n",
    "        wos_client.subscriptions.delete(subscription.metadata.id)\n",
    "        print('Deleted existing subscription for model', sub_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "392068d3-ca60-4dd1-a7bc-26d86944e6ca"
   },
   "source": [
    "This code creates the model subscription in OpenScale using the Python client API. Note that we need to provide the model unique identifier, and some information about the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3d0b0a3-2418-4ff1-89a9-dd8bb58c6f3a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subscription_details = wos_client.subscriptions.add(\n",
    "        data_mart_id=data_mart_id,\n",
    "        background_mode=False,\n",
    "        service_provider_id=service_provider_id,\n",
    "        asset=Asset(\n",
    "            asset_id=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"asset_id\"],\n",
    "            name=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"name\"],\n",
    "            url=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"url\"],\n",
    "            asset_type=AssetTypes.MODEL,\n",
    "            input_data_type=InputDataType.STRUCTURED,\n",
    "            problem_type=ProblemType.BINARY_CLASSIFICATION\n",
    "        ),\n",
    "        deployment=AssetDeploymentRequest(\n",
    "            deployment_id=asset_deployment_details['metadata']['guid'],\n",
    "            name=asset_deployment_details['entity']['name'],\n",
    "            deployment_type= DeploymentTypes.ONLINE,\n",
    "            url=asset_deployment_details['entity']['scoring_endpoint']['url']\n",
    "        ),\n",
    "        asset_properties=AssetPropertiesRequest(\n",
    "            label_column='Risk',\n",
    "            probability_fields=['probability'],\n",
    "            prediction_field='predictedLabel',\n",
    "            feature_fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"],\n",
    "            categorical_fields = [\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"],\n",
    "            training_data_reference=TrainingDataReference(type='cos',\n",
    "                                                          location=COSTrainingDataReferenceLocation(bucket = BUCKET_NAME,\n",
    "                                                                                                    file_name = training_data_file_name),\n",
    "                                                          connection=COSTrainingDataReferenceConnection.from_dict({\n",
    "                                                                        \"resource_instance_id\": COS_RESOURCE_CRN,\n",
    "                                                                        \"url\": COS_ENDPOINT,\n",
    "                                                                        \"api_key\": COS_API_KEY_ID,\n",
    "                                                                        \"iam_url\": IAM_URL})),\n",
    "            training_data_schema=SparkStruct.from_dict(model_asset_details_from_deployment[\"entity\"][\"asset_properties\"][\"training_data_schema\"])\n",
    "        )\n",
    "    ).result\n",
    "subscription_id = subscription_details.metadata.id\n",
    "subscription_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22bb6493-5dbf-4f4f-aae1-3cea90694cc4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(5)\n",
    "payload_data_set_id = None\n",
    "payload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n",
    "                                                target_target_id=subscription_id, \n",
    "                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n",
    "if payload_data_set_id is None:\n",
    "    print(\"Payload data set not found. Please check subscription status.\")\n",
    "else:\n",
    "    print(\"Payload data set id: \", payload_data_set_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca1e2b77-a779-4714-a0b6-7596c7e06db5"
   },
   "outputs": [],
   "source": [
    "wos_client.data_sets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28f0d500-8919-4121-9785-ab3a59c4effb"
   },
   "source": [
    "### Score the model so we can configure monitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6f4e0d51-fbcf-47ff-ae19-c92436bd40c3"
   },
   "source": [
    "Now that the WML service has been bound and the subscription has been created, we need to send a request to the model before we configure OpenScale. This allows OpenScale to create a payload log in the datamart with the correct schema, so it can capture data coming into and out of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce458c00-1059-4ca1-a8e2-dabbe64a8dbf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\n",
    "values = [\n",
    "  [\"no_checking\",13,\"credits_paid_to_date\",\"car_new\",1343,\"100_to_500\",\"1_to_4\",2,\"female\",\"none\",3,\"savings_insurance\",46,\"none\",\"own\",2,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",24,\"prior_payments_delayed\",\"furniture\",4567,\"500_to_1000\",\"1_to_4\",4,\"male\",\"none\",4,\"savings_insurance\",36,\"none\",\"free\",2,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",26,\"all_credits_paid_back\",\"car_new\",863,\"less_100\",\"less_1\",2,\"female\",\"co-applicant\",2,\"real_estate\",38,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",14,\"no_credits\",\"car_new\",2368,\"less_100\",\"1_to_4\",3,\"female\",\"none\",3,\"real_estate\",29,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",4,\"no_credits\",\"car_new\",250,\"less_100\",\"unemployed\",2,\"female\",\"none\",3,\"real_estate\",23,\"none\",\"rent\",1,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",17,\"credits_paid_to_date\",\"car_new\",832,\"100_to_500\",\"1_to_4\",2,\"male\",\"none\",2,\"real_estate\",42,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",33,\"outstanding_credit\",\"appliances\",5696,\"unknown\",\"greater_7\",4,\"male\",\"co-applicant\",4,\"unknown\",54,\"none\",\"free\",2,\"skilled\",1,\"yes\",\"yes\"],\n",
    "  [\"0_to_200\",13,\"prior_payments_delayed\",\"retraining\",1375,\"100_to_500\",\"4_to_7\",3,\"male\",\"none\",3,\"real_estate\",37,\"none\",\"own\",2,\"management_self-employed\",1,\"none\",\"yes\"]\n",
    "]\n",
    "\n",
    "payload_scoring = {\"fields\": fields,\"values\": values}\n",
    "payload = {\n",
    "    wml_client.deployments.ScoringMetaNames.INPUT_DATA: [payload_scoring]\n",
    "}\n",
    "scoring_response = wml_client.deployments.score(deployment_uid, payload)\n",
    "\n",
    "print('Single record scoring result:', '\\n fields:', scoring_response['predictions'][0]['fields'], '\\n values: ', scoring_response['predictions'][0]['values'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fe8d26c7e6249b7af55d4460be31a04"
   },
   "source": [
    "## Check if WML payload logging worked else manually store payload records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30d2bbe7a25649908b451455455bacd9"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n",
    "time.sleep(5)\n",
    "pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "print(\"Number of records in the payload logging table: {}\".format(pl_records_count))\n",
    "if pl_records_count == 0:\n",
    "    print(\"Payload logging did not happen, performing explicit payload logging.\")\n",
    "    wos_client.data_sets.store_records(data_set_id=payload_data_set_id, request_body=[PayloadRecord(\n",
    "                   scoring_id=str(uuid.uuid4()),\n",
    "                   request=payload_scoring,\n",
    "                   response={\"fields\": scoring_response['predictions'][0]['fields'], \"values\":scoring_response['predictions'][0]['values']},\n",
    "                   response_time=460\n",
    "               )])\n",
    "    time.sleep(5)\n",
    "    pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "    print(\"Number of records in the payload logging table: {}\".format(pl_records_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34994a57-b35e-4b15-af31-92f662da83ea"
   },
   "source": [
    "\n",
    "# Quality monitoring and feedback logging <a name=\"quality\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5549b783-cf11-4014-8529-5e5a28988f57"
   },
   "source": [
    "## Enable quality monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "307026d0-5b9e-49cd-8623-62530db5926e"
   },
   "source": [
    "The code below waits ten seconds to allow the payload logging table to be set up before it begins enabling monitors. First, it turns on the quality (accuracy) monitor and sets an alert threshold of 70%. OpenScale will show an alert on the dashboard if the model accuracy measurement (area under the curve, in the case of a binary classifier) falls below this threshold.\n",
    "\n",
    "The second paramater supplied, `min_feedback_data_size`, specifies the minimum number of feedback records OpenScale needs before it calculates a new measurement and `max_rows_per_evaluation` specifies the maximum number of the records for which quality metrics can be evaluated. The quality monitor runs hourly, but the accuracy reading in the dashboard will not change until an additional 50 feedback records have been added, via the user interface, the Python client, or the supplied feedback endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3e9d933-cc6d-43d8-b8ff-df82ba6b15b2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(10)\n",
    "max_records = None\n",
    "#Update the max_records value when you want to consider it during quality metrics evaluation\n",
    "#max_records = 80\n",
    "\n",
    "target = Target(\n",
    "        target_type=TargetTypes.SUBSCRIPTION,\n",
    "        target_id=subscription_id\n",
    ")\n",
    "\n",
    "parameters =  dict()\n",
    "parameters[\"min_feedback_data_size\"] = 50\n",
    "if max_records is not None:\n",
    "    parameters[\"max_rows_per_evaluation\"] = max_records\n",
    "\n",
    "thresholds = [\n",
    "                {\n",
    "                    \"metric_id\": \"area_under_roc\",\n",
    "                    \"type\": \"lower_limit\",\n",
    "                    \"value\": .80\n",
    "                }\n",
    "            ]\n",
    "quality_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.QUALITY.ID,\n",
    "    target=target,\n",
    "    parameters=parameters,\n",
    "    thresholds=thresholds\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "df697eb4e66348409654859b4d9e4166"
   },
   "outputs": [],
   "source": [
    "quality_monitor_instance_id = quality_monitor_details.metadata.id\n",
    "quality_monitor_instance_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "528069bd-9b0c-440a-92c0-c33908a00d2a"
   },
   "source": [
    "## Feedback logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e2e77e7-d645-456b-9a45-ec5a1c715210"
   },
   "source": [
    "The code below downloads and stores enough feedback data to meet the minimum threshold so that OpenScale can calculate a new accuracy measurement. It then kicks off the accuracy monitor. The monitors run hourly, or can be initiated via the Python API, the REST API, or the graphical user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9cddba8-e579-4c30-8c0a-657953d3c2cf"
   },
   "outputs": [],
   "source": [
    "!rm additional_feedback_data_v2.json\n",
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/Cloud%20Pak%20for%20Data/WML/assets/data/credit_risk/additional_feedback_data_v2.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3693ded2956d4fb58f2e823b815221f0"
   },
   "source": [
    "## Get feedback logging dataset ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a429003593e440e28a5940c7dd4995df"
   },
   "outputs": [],
   "source": [
    "feedback_dataset_id = None\n",
    "feedback_dataset = wos_client.data_sets.list(type=DataSetTypes.FEEDBACK, \n",
    "                                                target_target_id=subscription_id, \n",
    "                                                target_target_type=TargetTypes.SUBSCRIPTION).result\n",
    "print(feedback_dataset)\n",
    "feedback_dataset_id = feedback_dataset.data_sets[0].metadata.id\n",
    "if feedback_dataset_id is None:\n",
    "    print(\"Feedback data set not found. Please check quality monitor status.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1160b84ead54ed6946c405170aeadf4"
   },
   "outputs": [],
   "source": [
    "with open('additional_feedback_data_v2.json') as feedback_file:\n",
    "    additional_feedback_data = json.load(feedback_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e71198141e8848a99c0b40e8c0237a5b"
   },
   "outputs": [],
   "source": [
    "wos_client.data_sets.store_records(feedback_dataset_id, request_body=additional_feedback_data, background_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f78dd14dd9346ee8a469d3c33134035"
   },
   "outputs": [],
   "source": [
    "wos_client.data_sets.get_records_count(data_set_id=feedback_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b61c034f584b4a6c81c86441741b329b"
   },
   "outputs": [],
   "source": [
    "run_details = wos_client.monitor_instances.run(monitor_instance_id=quality_monitor_instance_id, background_mode=False).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d495df720574b4d9701ea08f4056aff"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=quality_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82e4c42f-ead9-4b79-84d7-b8db48a24764"
   },
   "source": [
    "# Fairness, drift monitoring and explanations \n",
    " <a name=\"fairness\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d938bd94-155c-48ff-80a6-7be71406d54f"
   },
   "source": [
    "The code below configures fairness monitoring for our model. It turns on monitoring for two features, Sex and Age. In each case, we must specify:\n",
    "  * Which model feature to monitor\n",
    "  * One or more **majority** groups, which are values of that feature that we expect to receive a higher percentage of favorable outcomes\n",
    "  * One or more **minority** groups, which are values of that feature that we expect to receive a higher percentage of unfavorable outcomes\n",
    "  * The threshold at which we would like OpenScale to display an alert if the fairness measurement falls below (in this case, 95%)\n",
    "\n",
    "Additionally, we must specify which outcomes from the model are favourable outcomes, and which are unfavourable. We must also provide the number of records OpenScale will use to calculate the fairness score. In this case, OpenScale's fairness monitor will run hourly, but will not calculate a new fairness rating until at least 200 records have been added. Finally, to calculate fairness, OpenScale must perform some calculations on the training data, so we provide the dataframe containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8d00b1d4d0549e0933163928779c2d7"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "448aabea-59a6-4222-9b59-c3e61df7a6c5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    "\n",
    ")\n",
    "parameters = {\n",
    "    \"features\": [\n",
    "        {\"feature\": \"Sex\",\n",
    "         \"majority\": ['male'],\n",
    "         \"minority\": ['female'],\n",
    "         \"threshold\": 0.95\n",
    "         },\n",
    "        {\"feature\": \"Age\",\n",
    "         \"majority\": [[26, 75]],\n",
    "         \"minority\": [[18, 25]],\n",
    "         \"threshold\": 0.95\n",
    "         }\n",
    "    ],\n",
    "    \"favourable_class\": [\"No Risk\"],\n",
    "    \"unfavourable_class\": [\"Risk\"],\n",
    "    \"min_records\": 100\n",
    "}\n",
    "\n",
    "fairness_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.FAIRNESS.ID,\n",
    "    target=target,\n",
    "    parameters=parameters).result\n",
    "fairness_monitor_instance_id =fairness_monitor_details.metadata.id\n",
    "fairness_monitor_instance_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9920ea9-dec8-463d-9bc4-b0c511607b82"
   },
   "source": [
    "## Drift configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_instances = wos_client.monitor_instances.list().result.monitor_instances\n",
    "for monitor_instance in monitor_instances:\n",
    "    monitor_def_id=monitor_instance.entity.monitor_definition_id\n",
    "    if monitor_def_id == \"drift\" and monitor_instance.entity.target.target_id == subscription_id:\n",
    "        wos_client.monitor_instances.delete(monitor_instance.metadata.id)\n",
    "        print('Deleted existing drift monitor instance with id: ', monitor_instance.metadata.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bfb8b47-b47c-49e4-9184-ab072db18992"
   },
   "outputs": [],
   "source": [
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    "\n",
    ")\n",
    "parameters = {\n",
    "    \"min_samples\": 100,\n",
    "    \"drift_threshold\": 0.1,\n",
    "    \"train_drift_model\": True,\n",
    "    \"enable_model_drift\": False,\n",
    "    \"enable_data_drift\": True\n",
    "}\n",
    "\n",
    "drift_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.DRIFT.ID,\n",
    "    target=target,\n",
    "    parameters=parameters\n",
    ").result\n",
    "\n",
    "drift_monitor_instance_id = drift_monitor_details.metadata.id\n",
    "drift_monitor_instance_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1ae1381-63a3-47fb-b495-3c71f5266c96"
   },
   "source": [
    "## Score the model again now that monitoring is configured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f89bdd68-3076-4431-a46a-2928894e1167"
   },
   "source": [
    "This next section randomly selects 200 records from the data feed and sends those records to the model for predictions. This is enough to exceed the minimum threshold for records set in the previous section, which allows OpenScale to begin calculating fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "238f1881-aa23-4ee2-a05c-bce19720c936"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/Cloud%20Pak%20for%20Data/WML/assets/data/credit_risk/german_credit_feed.json\n",
    "!ls -lh german_credit_feed.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5bac60b-03a9-4ee8-8b2e-bb778c13a8ad"
   },
   "source": [
    "Score 200 randomly chosen records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27d75928-7811-45c1-8ba8-cd65e2fabbe1"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open('german_credit_feed.json', 'r') as scoring_file:\n",
    "    scoring_data = json.load(scoring_file)\n",
    "\n",
    "fields = scoring_data['fields']\n",
    "values = []\n",
    "for _ in range(200):\n",
    "    values.append(random.choice(scoring_data['values']))\n",
    "payload_scoring = {\"input_data\": [{\"fields\": fields, \"values\": values}]}\n",
    "\n",
    "scoring_response = wml_client.deployments.score(deployment_uid, payload_scoring)\n",
    "time.sleep(5)\n",
    "\n",
    "if pl_records_count == 8:\n",
    "    print(\"Payload logging did not happen, performing explicit payload logging.\")\n",
    "    wos_client.data_sets.store_records(data_set_id=payload_data_set_id, request_body=[PayloadRecord(\n",
    "                   scoring_id=str(uuid.uuid4()),\n",
    "                   request=payload_scoring,\n",
    "                   response=scoring_response,\n",
    "                   response_time=460\n",
    "               )])\n",
    "    time.sleep(5)\n",
    "    pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "    print(\"Number of records in the payload logging table: {}\".format(pl_records_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ace07604bccf4add8c47745e28eb26de"
   },
   "outputs": [],
   "source": [
    "print('Number of records in payload table: ', wos_client.data_sets.get_records_count(data_set_id=payload_data_set_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdc0d0ad-3a75-455f-86f0-0b22c9fa9e09"
   },
   "source": [
    "## Run fairness monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b09545f3-99aa-44ef-94fd-6bc372bcc2a8"
   },
   "source": [
    "Kick off a fairness monitor run on current data. The monitor runs hourly, but can be manually initiated using the Python client, the REST API, or the graphical user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39cc51ca-0bac-48ff-800f-d0257a8dc0cd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "run_details = wos_client.monitor_instances.run(monitor_instance_id=fairness_monitor_instance_id, background_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31ac2bd5-a430-4b3a-9a9f-8f476afb9eb5"
   },
   "outputs": [],
   "source": [
    "time.sleep(10)\n",
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=fairness_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9642a519-47d3-4846-a55b-887e1aa7f6db"
   },
   "source": [
    "## Run drift monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1aef1a1-8a62-4d3b-84b6-f3c226dd087b"
   },
   "source": [
    "Kick off a drift monitor run on current data. The monitor runs every hour, but can be manually initiated using the Python client, the REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0920dae-f509-4460-89e5-b3c9120c8403"
   },
   "outputs": [],
   "source": [
    "drift_run_details = wos_client.monitor_instances.run(monitor_instance_id=drift_monitor_instance_id, background_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1f0a0cf-55c1-4de6-b54f-d181eeda114a"
   },
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=drift_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "400f0779-185a-4305-a6f0-401dddcdb38d"
   },
   "source": [
    "## Configure Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecc98f66-be54-4698-bc80-7dcfed5fbb0c"
   },
   "source": [
    "Finally, we provide OpenScale with the training data to enable and configure the explainability features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cebaeb41-2d87-44c2-aff0-f7bd86bba968",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "parameters = {\n",
    "    \"enabled\": True\n",
    "}\n",
    "explainability_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.EXPLAINABILITY.ID,\n",
    "    target=target,\n",
    "    parameters=parameters\n",
    ").result\n",
    "\n",
    "explainability_monitor_id = explainability_details.metadata.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1ff66e9-685f-49fb-9d71-65a9fcb7cb43"
   },
   "source": [
    "## Run explanation for sample record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ce14cf6-92f4-4c66-9076-4dac78ab8f80"
   },
   "outputs": [],
   "source": [
    "pl_records_resp = wos_client.data_sets.get_list_of_records(data_set_id=payload_data_set_id, limit=1, offset=0).result\n",
    "scoring_ids = [pl_records_resp[\"records\"][0][\"entity\"][\"values\"][\"scoring_id\"]]\n",
    "print(\"Running explanations on scoring IDs: {}\".format(scoring_ids))\n",
    "explanation_types = [\"lime\", \"contrastive\"]\n",
    "result = wos_client.monitor_instances.explanation_tasks(scoring_ids=scoring_ids, explanation_types=explanation_types).result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "641625d7-724c-429d-909c-3afef1936b3c"
   },
   "source": [
    "# Custom monitors and metrics <a name=\"custom\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e053b5f-1591-429a-9c48-af60874ed31a"
   },
   "source": [
    "## Register custom monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40483a8a-b492-4655-921a-53cfa57262ea"
   },
   "outputs": [],
   "source": [
    "def get_definition(monitor_name):\n",
    "    monitor_definitions = wos_client.monitor_definitions.list().result.monitor_definitions\n",
    "    \n",
    "    for definition in monitor_definitions:\n",
    "        if monitor_name == definition.entity.name:\n",
    "            return definition\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "311c740a-5fa3-4a5e-b564-f25e7c923838"
   },
   "outputs": [],
   "source": [
    "monitor_name = 'my model performance'\n",
    "metrics = [MonitorMetricRequest(name='sensitivity',\n",
    "                                thresholds=[MetricThreshold(type=MetricThresholdTypes.LOWER_LIMIT, default=0.8)]),\n",
    "          MonitorMetricRequest(name='specificity',\n",
    "                                thresholds=[MetricThreshold(type=MetricThresholdTypes.LOWER_LIMIT, default=0.75)])]\n",
    "tags = [MonitorTagRequest(name='region', description='customer geographical region')]\n",
    "\n",
    "existing_definition = get_definition(monitor_name)\n",
    "\n",
    "if existing_definition is None:\n",
    "    custom_monitor_details = wos_client.monitor_definitions.add(name=monitor_name, metrics=metrics, tags=tags, background_mode=False).result\n",
    "else:\n",
    "    custom_monitor_details = existing_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77dc3061364745a3bbb353b4fb09a58d"
   },
   "source": [
    "## Show available monitors types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "de0f36b55e74467981ca201b944aebd6"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_definitions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47214aff-2540-4290-af74-53dcfb96241b"
   },
   "source": [
    "### Get monitors uids and details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3df1f437-4f12-4e72-9934-70d5b6069638"
   },
   "outputs": [],
   "source": [
    "custom_monitor_id = custom_monitor_details.metadata.id\n",
    "\n",
    "print(custom_monitor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fb0255b9-1491-4eb3-ba77-3ac54534538a"
   },
   "outputs": [],
   "source": [
    "custom_monitor_details = wos_client.monitor_definitions.get(monitor_definition_id=custom_monitor_id).result\n",
    "print('Monitor definition details:', custom_monitor_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cff5854-7613-473a-9830-92c338583200"
   },
   "source": [
    "## Enable custom monitor for subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d458c6a9-4606-450b-a67d-911ece8681f6"
   },
   "outputs": [],
   "source": [
    "target = Target(\n",
    "        target_type=TargetTypes.SUBSCRIPTION,\n",
    "        target_id=subscription_id\n",
    "    )\n",
    "\n",
    "thresholds = [MetricThresholdOverride(metric_id='sensitivity', type = MetricThresholdTypes.LOWER_LIMIT, value=0.9)]\n",
    "\n",
    "custom_monitor_instance_details = wos_client.monitor_instances.create(\n",
    "            data_mart_id=data_mart_id,\n",
    "            background_mode=False,\n",
    "            monitor_definition_id=custom_monitor_id,\n",
    "            target=target\n",
    ").result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d937c063-c597-4433-8104-eddea8ad8d2c"
   },
   "source": [
    "### Get monitor instance id and configuration details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6480b1cf-68d0-4f2c-b318-9b13ce136336"
   },
   "outputs": [],
   "source": [
    "custom_monitor_instance_id = custom_monitor_instance_details.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92a18acea7884b7280ae946189aaf3fe"
   },
   "outputs": [],
   "source": [
    "custom_monitor_instance_details = wos_client.monitor_instances.get(custom_monitor_instance_id).result\n",
    "print(custom_monitor_instance_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b945c45-0098-480d-9855-521397e03b5a"
   },
   "source": [
    "## Storing custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8a79b833-7b43-42cd-89d9-29415cc2d115"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import MonitorMeasurementRequest\n",
    "custom_monitoring_run_id = \"11122223333111abc\"\n",
    "measurement_request = [MonitorMeasurementRequest(timestamp=datetime.now(timezone.utc), \n",
    "                                                 metrics=[{\"specificity\": 0.78, \"sensitivity\": 0.67, \"region\": \"us-south\"}], run_id=custom_monitoring_run_id)]\n",
    "print(measurement_request[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ef5f4809917426284bb23226e698016"
   },
   "outputs": [],
   "source": [
    "published_measurement_response = wos_client.monitor_instances.measurements.add(\n",
    "    monitor_instance_id=custom_monitor_instance_id,\n",
    "    monitor_measurement_request=measurement_request).result\n",
    "published_measurement_id = published_measurement_response[0][\"measurement_id\"]\n",
    "print(published_measurement_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b25c31fb-186c-444f-85f3-02c7ed735af4"
   },
   "source": [
    "### List and get custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8873a3e2-a2d0-48cd-bb6e-4fa82457878d"
   },
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "published_measurement = wos_client.monitor_instances.measurements.get(monitor_instance_id=custom_monitor_instance_id, measurement_id=published_measurement_id).result\n",
    "print(published_measurement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4c95961-dccf-40ea-8c7d-c3ae71c25634"
   },
   "source": [
    "# Historical data <a name=\"historical\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ca15cd1-3115-410c-b2a9-c678bae7129d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historyDays = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7073e79a-13c0-41e7-9d35-44873d29eb1f"
   },
   "source": [
    " ## Insert historical payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "497d614a-7b6f-4b37-8e44-55e6d1912a57"
   },
   "source": [
    "The next section of the notebook downloads and writes historical data to the payload and measurement tables to simulate a production model that has been monitored and receiving regular traffic for the last seven days. This historical data can be viewed in the Watson OpenScale user interface. The code uses the Python and REST APIs to write this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "951112a7-dd40-4981-902d-812ace7e7fa1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/historical_data/credit_risk/history_fairness_v2.json\n",
    "!ls -lh history_fairness_v2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "583721f5-5505-4ce7-93f0-013c134f35cc"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import Source\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import Measurements\n",
    "with open(\"history_fairness_v2.json\") as f:\n",
    "    fairness_values = json.load(f)\n",
    "    for day in range(historyDays):\n",
    "        print('Loading day', day + 1)\n",
    "        daily_measurement_requests = []\n",
    "        sources_list = []\n",
    "        for hour in range(24):\n",
    "            score_time = (datetime.now(timezone.utc) + timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            index = (day * 24 + hour) % len(fairness_values) # wrap around and reuse values if needed\n",
    "            fairness_values[index][\"timestamp\"] = score_time\n",
    "            #print(score_time) \n",
    "            fairness_value = fairness_values[index]\n",
    "            metrics_list = fairness_value[\"metrics\"]\n",
    "            sources = fairness_value[\"sources\"]\n",
    "            sources_list = []\n",
    "            for source in sources:\n",
    "                source_id = source[\"id\"]\n",
    "                source_type = source[\"type\"]\n",
    "                source_data = source[\"data\"]\n",
    "                if source_id == \"bias_detection_summary\":\n",
    "                    source_data[\"evaluated_at\"] = score_time\n",
    "                    source_data[\"favourable_class\"] = [\"No Risk\"]\n",
    "                    source_data[\"unfavourable_class\"] = [\"Risk\"]\n",
    "                    source_data[\"score_type\"] = \"disparate impact\"\n",
    "                sources_list.append(\n",
    "                    Source(\n",
    "                        id=source_id,\n",
    "                        type=source_type,\n",
    "                        data=source_data\n",
    "                    )\n",
    "                )  \n",
    "            measurement_request = MonitorMeasurementRequest(metrics=metrics_list, sources=sources_list, timestamp=score_time)\n",
    "            daily_measurement_requests.append(measurement_request)\n",
    "        measurements_client = Measurements(wos_client)\n",
    "        measurements_client.add(monitor_instance_id=fairness_monitor_instance_id, monitor_measurement_request=daily_measurement_requests)     \n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d7c37db-a49d-486d-be89-ed12ccf1afbb"
   },
   "source": [
    "## Insert historical debias metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1164430b-fb50-444b-bad1-ed4ecead9e9a"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/historical_data/credit_risk/history_debias_v2.json\n",
    "!ls -lh history_debias_v2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e01e0f8-959e-4dcd-b408-ca81ea941262"
   },
   "outputs": [],
   "source": [
    "with open(\"history_debias_v2.json\") as f:\n",
    "    debias_values = json.load(f)\n",
    "    for day in range(historyDays):\n",
    "        print('Loading day', day + 1)\n",
    "        daily_measurement_requests = []\n",
    "        sources_list = []\n",
    "        for hour in range(24):\n",
    "            score_time = (datetime.now(timezone.utc) + timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            index = (day * 24 + hour) % len(debias_values) # wrap around and reuse values if needed\n",
    "            debias_values[index][\"timestamp\"] = score_time\n",
    "            debias_value = debias_values[index]\n",
    "            metrics_list = debias_value[\"metrics\"]\n",
    "            sources = debias_value[\"sources\"]\n",
    "            sources_list = []\n",
    "            for source in sources:\n",
    "                sources_list.append(\n",
    "                    Source(\n",
    "                        id=source[\"id\"],\n",
    "                        type=source[\"type\"],\n",
    "                        data=source[\"data\"]\n",
    "                    )\n",
    "                )  \n",
    "            measurement_request = MonitorMeasurementRequest(metrics=metrics_list, sources=sources_list, timestamp=score_time)\n",
    "            daily_measurement_requests.append(measurement_request)\n",
    "        measurements_client = Measurements(wos_client)\n",
    "        measurements_client.add(monitor_instance_id=fairness_monitor_instance_id, monitor_measurement_request=daily_measurement_requests)         \n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aeafdae-089a-415d-9258-26d9cb6466bf"
   },
   "source": [
    "## Insert historical quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "349162e0-bde0-4f07-a223-472d2296bdd2"
   },
   "outputs": [],
   "source": [
    "measurements = [0.76, 0.78, 0.68, 0.72, 0.73, 0.77, 0.80]\n",
    "for day in range(historyDays):\n",
    "    quality_measurement_requests = []\n",
    "    print('Loading day', day + 1)\n",
    "    for hour in range(24):\n",
    "        score_time = datetime.utcnow() + timedelta(hours=(-(24*day + hour + 1)))\n",
    "        score_time = score_time.isoformat() + \"Z\"\n",
    "        \n",
    "        metric = {\"area_under_roc\": measurements[day]}\n",
    "                \n",
    "        measurement_request = MonitorMeasurementRequest(timestamp=score_time,metrics = [metric])\n",
    "        quality_measurement_requests.append(measurement_request)\n",
    "        \n",
    "        \n",
    "    response = wos_client.monitor_instances.measurements.add(\n",
    "                                            monitor_instance_id=quality_monitor_instance_id,\n",
    "                                            monitor_measurement_request=quality_measurement_requests).result    \n",
    "    \n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8825b0ea-1196-4760-ac50-abab2d177f25"
   },
   "source": [
    "## Insert historical confusion matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdbb9d1b-382d-42ea-8949-9570e5a95110"
   },
   "outputs": [],
   "source": [
    "!rm history_quality_metrics.json\n",
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/historical_data/credit_risk/history_quality_metrics.json\n",
    "!ls -lh history_quality_metrics.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67e341d8-8f05-4242-bb96-348b468e8f59"
   },
   "outputs": [],
   "source": [
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import Source\n",
    "\n",
    "with open('history_quality_metrics.json') as json_file:\n",
    "    records = json.load(json_file)\n",
    "    \n",
    "for day in range(historyDays):\n",
    "    index = 0\n",
    "    cm_measurement_requests = []\n",
    "    print('Loading day', day + 1)\n",
    "    \n",
    "    for hour in range(24):\n",
    "        score_time = datetime.utcnow() + timedelta(hours=(-(24*day + hour + 1)))\n",
    "        score_time = score_time.isoformat() + \"Z\"\n",
    "\n",
    "        metric = records[index]['metrics']\n",
    "        source = records[index]['sources']\n",
    "\n",
    "        \n",
    "        measurement_request = {\"timestamp\": score_time, \"metrics\": [metric], \"sources\": [source]}\n",
    "        cm_measurement_requests.append(measurement_request)\n",
    "\n",
    "        index+=1\n",
    "\n",
    "    response = wos_client.monitor_instances.measurements.add(monitor_instance_id=quality_monitor_instance_id, monitor_measurement_request=cm_measurement_requests).result    \n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9063310f-4518-4001-83bb-342c259b9e2e"
   },
   "source": [
    "## Insert historical performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2090d9c2-fe8b-4326-830d-afd5f86f3c6c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = Target(\n",
    "        target_type=TargetTypes.INSTANCE,\n",
    "        target_id=payload_data_set_id\n",
    "    )\n",
    "\n",
    "\n",
    "performance_monitor_instance_details = wos_client.monitor_instances.create(\n",
    "            data_mart_id=data_mart_id,\n",
    "            background_mode=False,\n",
    "            monitor_definition_id=wos_client.monitor_definitions.MONITORS.PERFORMANCE.ID,\n",
    "            target=target\n",
    ").result\n",
    "performance_monitor_instance_id = performance_monitor_instance_details.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc2a8c5122aa43878fb94f05f9d41e4b"
   },
   "outputs": [],
   "source": [
    "for day in range(historyDays):\n",
    "    performance_measurement_requests = []\n",
    "    print('Loading day', day + 1)\n",
    "    for hour in range(24):\n",
    "        score_time = datetime.utcnow() + timedelta(hours=(-(24*day + hour + 1)))\n",
    "        score_time = score_time.isoformat() + \"Z\"\n",
    "        score_count = random.randint(60, 600)\n",
    "        \n",
    "        metric = {\"record_count\": score_count, \"data_set_type\": \"scoring_payload\"}\n",
    "        \n",
    "        measurement_request = {\"timestamp\": score_time, \"metrics\": [metric]}\n",
    "        performance_measurement_requests.append(measurement_request)\n",
    "        \n",
    "    response = wos_client.monitor_instances.measurements.add(\n",
    "                                            monitor_instance_id=performance_monitor_instance_id,\n",
    "                                            monitor_measurement_request=performance_measurement_requests).result    \n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb02981d-5bab-46a1-9078-734decb6901e"
   },
   "source": [
    "## Insert historical drift measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ce7e80a-19b9-4f9b-bb19-010f18c6efbe"
   },
   "outputs": [],
   "source": [
    "!rm history_drift_measurement_*.json\n",
    "    !wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/historical_data/credit_risk/history_drift_measurement_0.json\n",
    "    !wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/historical_data/credit_risk/history_drift_measurement_1.json\n",
    "    !wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/historical_data/credit_risk/history_drift_measurement_2.json\n",
    "    !wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/historical_data/credit_risk/history_drift_measurement_3.json\n",
    "    !wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/historical_data/credit_risk/history_drift_measurement_4.json\n",
    "    !wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/historical_data/credit_risk/history_drift_measurement_5.json\n",
    "    !wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/historical_data/credit_risk/history_drift_measurement_6.json\n",
    "!ls -lh history_drift_measurement_*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae815fd4-97b9-48d5-b8de-9e61219f4a64"
   },
   "outputs": [],
   "source": [
    "for day in range(historyDays):\n",
    "    drift_measurements = []\n",
    "\n",
    "    with open(\"history_drift_measurement_{}.json\".format(day), 'r') as history_file:\n",
    "        drift_daily_measurements = json.load(history_file)\n",
    "    print('Loading day', day + 1)\n",
    "\n",
    "    #Historical data contains 8 records per day - each represents 3 hour drift window.\n",
    "    \n",
    "    for nb_window, records in enumerate(drift_daily_measurements):\n",
    "        for record in records:\n",
    "            window_start =  datetime.utcnow() + timedelta(hours=(-(24 * day + (nb_window+1)*3 + 1))) # first_payload_record_timestamp_in_window (oldest)\n",
    "            window_end = datetime.utcnow() + timedelta(hours=(-(24 * day + nb_window*3 + 1)))# last_payload_record_timestamp_in_window (most recent)\n",
    "            #modify start and end time for each record\n",
    "            record['sources'][0]['data']['start'] = window_start.isoformat() + \"Z\"\n",
    "            record['sources'][0]['data']['end'] = window_end.isoformat() + \"Z\"\n",
    "            \n",
    "            \n",
    "            metric = record['metrics'][0]\n",
    "            source = record['sources'][0]\n",
    "\n",
    "            measurement_request = {\"timestamp\": window_start.isoformat() + \"Z\", \"metrics\": [metric], \"sources\": [source]}\n",
    "            \n",
    "            drift_measurements.append(measurement_request)\n",
    "        \n",
    "    response = wos_client.monitor_instances.measurements.add(\n",
    "                                            monitor_instance_id=drift_monitor_instance_id,\n",
    "                                            monitor_measurement_request=drift_measurements).result    \n",
    "\n",
    "    \n",
    "    print(\"Daily loading finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1987216c-4254-443e-b33c-77ec0436f3b5"
   },
   "source": [
    "## Additional data to help debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02ba6d51-8303-40d6-84b8-27e4815b1db8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Datamart:', data_mart_id)\n",
    "print('Model:', model_uid)\n",
    "print('Deployment:', deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba17f3b7-98eb-4da1-a3b2-10f5977aa1c4"
   },
   "source": [
    "## Identify transactions for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3b8e963-a64a-4415-9ba5-63a624e4b03c"
   },
   "source": [
    "Transaction IDs identified by the cells below can be copied and pasted into the Explainability tab of the OpenScale dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf869a3f-b925-432e-b73f-ac48f4f9d2ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wos_client.data_sets.show_records(payload_data_set_id, limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bb2868e-25ec-4ee1-bb51-12c3df03e580"
   },
   "source": [
    "## Congratulations!\n",
    "\n",
    "You have finished the hands-on lab for IBM Watson OpenScale. You can now view the OpenScale Dashboard: (https://url-to-your-cp4d-cluster/aiopenscale). Click on the tile for the German Credit model to see fairness, accuracy, and performance monitors. Click on the timeseries graph to get detailed information on transactions during a specific time window.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
