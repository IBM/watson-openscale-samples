{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "902d68f2-2df2-4df9-87b6-e55bda94bca3"
   },
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ad514b6-2e0a-4f7d-8ffa-d6aa3ae7dee9"
   },
   "source": [
    "This notebook should be run with **Default Spark 3.3 & Python 3.9** or **Python 3.10** runtime environment. \n",
    "\n",
    "If you are viewing this in Watson Studio and do not see Python 3.9.x in the upper right corner of your screen, please update the runtime now.\n",
    "\n",
    "It requires service credentials for the following services:\n",
    "  * Watson OpenScale\n",
    "  * Watson Machine Learning \n",
    "  * DB2\n",
    "  \n",
    "The notebook will train, create and deploy a German Credit Risk model, and configure OpenScale to monitor that deployment. Model Evaluation will also be triggered and published Fact will be retrieved.\n",
    "\n",
    "**Note**: The AI Factsheets add-on must be installed on the CPD cluster for the facts to be published and retrieved successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d003619e-9cc1-4840-9a4e-2faa5c627f61"
   },
   "source": [
    "### Contents\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Model Building and Deployment](#model)\n",
    "- [Configure OpenScale](#openscale)\n",
    "- [Monitor Configurations](#monitor)\n",
    "- [MRM Evaluation](#mrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a53dcf29-97e2-4609-9dcc-13668572614d"
   },
   "source": [
    "# 1. Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "516df632-58c8-4eca-aff0-f52c12042dc6"
   },
   "source": [
    "## 1.1 Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7513d0eb-71c8-40ab-b4f3-d27b18193c23"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36bc0a86683f4a03876cbb3c5cf5a2a7"
   },
   "outputs": [],
   "source": [
    "# Install WML and WOS SDKs\n",
    "\n",
    "!pip install --upgrade ibm-watson-machine-learning | tail -n 1\n",
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5d87e790-5836-43e6-81f3-c34751992a65"
   },
   "outputs": [],
   "source": [
    "# Install pyspark if runtime environment doesn't include Spark\n",
    "\n",
    "!pip install --upgrade pyspark==3.3.0 --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3503cf3c-0ddd-4b66-a9ea-c267937207ab"
   },
   "source": [
    "**Note** - Restart the kernel now to use the updated libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2587e52f-db09-46af-98c3-74a33fcde83c"
   },
   "source": [
    "## 1.2 Configure credentials\n",
    "\n",
    "Provide OpenScale, Watson Machine Learning, and DB2 service credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed4ec16a-c557-4d65-8afa-9cec64f58006"
   },
   "outputs": [],
   "source": [
    "cpd_url = \"***\"\n",
    "cpd_username = \"***\"\n",
    "cpd_password = \"***\"\n",
    "\n",
    "cpd_url = cpd_url.rstrip(\"/\")\n",
    "\n",
    "WOS_CREDENTIALS = {\n",
    "    \"url\": cpd_url,\n",
    "    \"username\": cpd_username,\n",
    "    \"password\": cpd_password\n",
    "}\n",
    "\n",
    "WML_CREDENTIALS = {\n",
    "    \"url\": \"***\",\n",
    "    \"password\": \"***\",\n",
    "    \"username\": \"***\",\n",
    "    \"instance_id\": \"***\",\n",
    "    \"version\": \"4.7\"\n",
    "}\n",
    "\n",
    "DB2_CREDENTIALS = {\n",
    "    \"hostname\": \"***\",\n",
    "    \"username\": \"***\",\n",
    "    \"password\": \"***\",\n",
    "    \"database_name\": \"***\",\n",
    "    \"port\": 50000,\n",
    "    \"ssl\": False\n",
    "}\n",
    "\n",
    "# Location details of German Credit Risk training data\n",
    "TRAINING_DATA_SCHEMA_NAME = \"***\"\n",
    "TRAINING_DATA_TABLE_NAME = \"***\"\n",
    "\n",
    "# Location details of German Credit Risk evaluation data \n",
    "EVALUATION_DATA_SCHEMA_NAME = \"***\"\n",
    "EVALUATION_DATA_TABLE_NAME = TEST_DATA_SET_NAME = \"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08a093e2-1e64-4e10-8d72-fb2177e0c6dc"
   },
   "source": [
    "# 2. Model Building and Deployment <a name=\"model\"></a>\n",
    "\n",
    "In this section you will learn how to train Spark MLLib model and next deploy it as web-service using Watson Machine Learning service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa3bef1d-f97e-49dd-bf24-abac17df40cd"
   },
   "source": [
    "## 2.1 Load the training data from Github <a name=\"model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aa63bdb-6bea-43a8-9d2d-dc4b2521f496"
   },
   "outputs": [],
   "source": [
    "!rm german_credit_data_biased_training.csv\n",
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/Cloud%20Pak%20for%20Data/WML/assets/data/credit_risk/german_credit_data_biased_training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b52cd3cf-0588-4bdf-8eeb-d52ba3a2c61a"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "pd_data = pd.read_csv(\"german_credit_data_biased_training.csv\", sep=\",\", header=0)\n",
    "df_data = spark.read.csv(path=\"german_credit_data_biased_training.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0cbc3a9-aab6-4f80-a178-255ad1f39f7c"
   },
   "source": [
    "## 2.2 Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6562d1a0-00f7-4c75-8cd8-fd768a6b2d1d"
   },
   "outputs": [],
   "source": [
    "df_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37450bbd-d7fa-45e1-9cd3-1e7194b3e585"
   },
   "outputs": [],
   "source": [
    "print(\"Number of records: \" + str(df_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a9e577d-9292-4b6a-b5ec-193821af2444"
   },
   "source": [
    "## 2.3 Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c4d03bd-e43e-4cc6-a8fb-c350f5d39e49"
   },
   "outputs": [],
   "source": [
    "spark_df = df_data\n",
    "(train_data, test_data) = spark_df.randomSplit([0.8, 0.2], 24)\n",
    "\n",
    "print(\"Number of records for training: \" + str(train_data.count()))\n",
    "print(\"Number of records for evaluation: \" + str(test_data.count()))\n",
    "\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d11700e7-bb13-4025-a753-f96ffeffc934"
   },
   "source": [
    "The code below creates a **Random Forest Classifier** with Spark, setting up string indexers for the categorical features and the label column. Finally, this notebook creates a pipeline including the indexers and the model and does an initial **Area Under ROC** evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15a1f237-bad4-4ebd-8f8a-bd84380209c7"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "features = [x for x in spark_df.columns if x != 'Risk']\n",
    "categorical_features = ['CheckingStatus', 'CreditHistory', 'LoanPurpose', 'ExistingSavings', 'EmploymentDuration', 'Sex', 'OthersOnLoan', 'OwnsProperty', 'InstallmentPlans', 'Housing', 'Job', 'Telephone', 'ForeignWorker']\n",
    "categorical_num_features = [x + '_IX' for x in categorical_features]\n",
    "si_list = [StringIndexer(inputCol=x, outputCol=y) for x, y in zip(categorical_features, categorical_num_features)]\n",
    "va_features = VectorAssembler(inputCols=categorical_num_features + [x for x in features if x not in categorical_features], outputCol=\"features\")\n",
    "si_label = StringIndexer(inputCol=\"Risk\", outputCol=\"label\").fit(spark_df)\n",
    "label_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=si_label.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fb7070e4-d15f-4701-b808-b7e87b5a4e89"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages= si_list + [si_label, va_features, classifier, label_converter])\n",
    "\n",
    "model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5e781bbd-f3d5-41df-8fa4-6b0876951bcd"
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)\n",
    "evaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",  metricName='areaUnderROC')\n",
    "area_under_curve = evaluatorDT.evaluate(predictions)\n",
    "\n",
    "evaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",  metricName='areaUnderPR')\n",
    "area_under_PR = evaluatorDT.evaluate(predictions)\n",
    "\n",
    "# Default evaluation is areaUnderROC\n",
    "print(\"areaUnderROC = %g\" % area_under_curve, \"areaUnderPR = %g\" % area_under_PR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ba8547f-853c-4622-b805-4f0766032fd0"
   },
   "source": [
    "## 2.4 Create and Save the Model\n",
    "\n",
    "Save and deploy the German Credit Risk model into the WML instance that is designated as **Pre-Production**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "259ee74c-6d06-4384-9986-71aec948d51b"
   },
   "outputs": [],
   "source": [
    "PRE_PROD_MODEL_NAME = \"GCR Model\"\n",
    "PRE_PROD_DEPLOYMENT_NAME = \"GCR Model Deployment\"\n",
    "SPACE_ID = \"***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d06b302-6dd0-4c40-ac25-b688dc7a7aad"
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "wml_client = APIClient(WML_CREDENTIALS)\n",
    "print(wml_client.version)\n",
    "wml_client.set.default_space(SPACE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbe9586b-0486-4518-a7a0-d8595b559416"
   },
   "source": [
    "### 2.4.1 Cleaning up existing model, deployments, subscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0d2d21f-f6f5-4a49-84c0-61e131be9aa1"
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.wml_client_error import WMLClientError\n",
    "\n",
    "deployments_list = wml_client.deployments.get_details()\n",
    "models_to_delete = []\n",
    "deployments_deleted = []\n",
    "for deployment in deployments_list[\"resources\"]:\n",
    "    model_id = deployment[\"entity\"][\"asset\"][\"id\"]\n",
    "    dep_model_name = wml_client.repository.get_details(model_id)[\"metadata\"][\"name\"]\n",
    "    deployment_id = deployment[\"metadata\"][\"id\"]\n",
    "    if deployment[\"metadata\"][\"name\"] == PRE_PROD_DEPLOYMENT_NAME or dep_model_name == PRE_PROD_MODEL_NAME:\n",
    "        deployments_deleted.append(deployment_id)\n",
    "        if model_id not in models_to_delete:\n",
    "            models_to_delete.append(model_id)\n",
    "\n",
    "for deployment_id in deployments_deleted:\n",
    "    try:\n",
    "        print(\"Deleting deployment id\", deployment_id)\n",
    "        wml_client.deployments.delete(deployment_id)\n",
    "    except WMLClientError as wce:\n",
    "        if \"deployment_does_not_exist\" in wce.error_msg:\n",
    "            # Shadow deployment\n",
    "            pass\n",
    "        else:\n",
    "            raise wce\n",
    "\n",
    "for model_id in models_to_delete:\n",
    "    print(\"Deleting model id\", model_id)\n",
    "    wml_client.repository.delete(model_id)\n",
    "wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79710cd8-55e3-4fec-84d7-316dd7bb414c"
   },
   "source": [
    "### 2.4.2 Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02fc9d6a-4bfa-4537-bcfa-c4d6678dece7"
   },
   "outputs": [],
   "source": [
    "model_props = {\n",
    "    wml_client.repository.ModelMetaNames.NAME: PRE_PROD_MODEL_NAME,\n",
    "    wml_client.repository.ModelMetaNames.TYPE: 'mllib_3.3',\n",
    "    wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: wml_client.software_specifications.get_id_by_name(\"spark-mllib_3.3\")\n",
    "}\n",
    "\n",
    "published_model_details = wml_client.repository.store_model(model=model, meta_props=model_props, \n",
    "                                                        training_data=train_data, pipeline=pipeline)\n",
    "model_uid = wml_client.repository.get_model_id(published_model_details)\n",
    "print(\"Model UID:\" + model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c613b44-d0f4-4109-acf3-e4682dcb8a83"
   },
   "source": [
    "## 2.5 Deploy the Model\n",
    "\n",
    "The next section of the notebook deploys the model as a RESTful web service in Watson Machine Learning. The deployed model will have a scoring URL you can use to send data to the model for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fa6d7296-c474-494a-acc1-f92882467191"
   },
   "outputs": [],
   "source": [
    "deployment_details = wml_client.deployments.create(\n",
    "    model_uid, \n",
    "    meta_props={\n",
    "        wml_client.deployments.ConfigurationMetaNames.NAME: \"{}\".format(PRE_PROD_DEPLOYMENT_NAME),\n",
    "        wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    ")\n",
    "\n",
    "scoring_url = wml_client.deployments.get_scoring_href(deployment_details)\n",
    "deployment_uid = wml_client.deployments.get_uid(deployment_details)\n",
    "\n",
    "print(\"Scoring URL: {}\".format(scoring_url))\n",
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a99a8d30-9a6a-4671-ac7e-0597603b60e1"
   },
   "source": [
    "### 2.5.1 Sample scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48ab20a1-7e11-46b2-aef6-5993160ef8ad"
   },
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\",\n",
    "                  \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\",\n",
    "                  \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n",
    "                  \"Telephone\", \"ForeignWorker\"]\n",
    "values = [\n",
    "            [\"no_checking\", 13, \"credits_paid_to_date\", \"car_new\", 1343, \"100_to_500\", \"1_to_4\", 2, \"female\", \"none\", 3,\n",
    "             \"savings_insurance\", 46, \"none\", \"own\", 2, \"skilled\", 1, \"none\", \"yes\"],\n",
    "            [\"no_checking\", 24, \"prior_payments_delayed\", \"furniture\", 4567, \"500_to_1000\", \"1_to_4\", 4, \"male\", \"none\",\n",
    "             4, \"savings_insurance\", 36, \"none\", \"free\", 2, \"management_self-employed\", 1, \"none\", \"yes\"],\n",
    "        ]\n",
    "\n",
    "scoring_payload = {\"input_data\": [{\"fields\": fields, \"values\": values}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2068a984-8da7-4030-906c-faa236330a42"
   },
   "outputs": [],
   "source": [
    "scoring_response = wml_client.deployments.score(deployment_uid, scoring_payload)\n",
    "scoring_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f42e76c1-e8ec-48f4-aab7-87e254c997d2"
   },
   "source": [
    "# 3. Configure OpenScale <a name=\"openscale\"></a>\n",
    "\n",
    "The subsequent cells will now import the necessary libraries and set up a Python OpenScale client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10ba9d55-48ae-43c5-adf2-78dc0ce2b7a0"
   },
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "from ibm_watson_openscale import APIClient\n",
    "\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45117df4-19dc-498b-a808-835d0e977ac8"
   },
   "source": [
    "### 3.1 Initialize the APIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "900292c5-3c4b-41fd-b6f6-6680d2aac825"
   },
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "from ibm_watson_openscale import APIClient as WOSAPIClient\n",
    "\n",
    "SERVICE_INSTANCE_ID = DATA_MART_ID = \"00000000-0000-0000-0000-000000000000\"\n",
    "wos_client = WOSAPIClient(\n",
    "    authenticator=CloudPakForDataAuthenticator(\n",
    "        url=cpd_url,\n",
    "        username=cpd_username,\n",
    "        password=cpd_password,\n",
    "        disable_ssl_verification=True\n",
    "    ),\n",
    "    service_url=cpd_url,\n",
    "    service_instance_id=SERVICE_INSTANCE_ID\n",
    ")\n",
    "\n",
    "print(wos_client.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95b9875c-180d-43fa-9825-a5c815756ff7"
   },
   "outputs": [],
   "source": [
    "# Listing service providers\n",
    "\n",
    "wos_client.service_providers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e02460cd-5f41-4cbc-a425-53a0cfa4fb0c"
   },
   "outputs": [],
   "source": [
    "# Copy the ID of your service provider from the `id` column in the output of the cell above\n",
    "\n",
    "SERVICE_PROVIDER_ID = \"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7b179ab-930c-4380-9d73-df0fe8afd0b7"
   },
   "source": [
    "### 3.2 Add Subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b583b56c-70f6-498b-bf58-986ec96208b9"
   },
   "outputs": [],
   "source": [
    "# Remove existing credit risk subscription\n",
    "\n",
    "wos_client.subscriptions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36e509f9-49bd-4d6a-b653-afd0d5596ed7"
   },
   "outputs": [],
   "source": [
    "subscriptions = wos_client.subscriptions.list().result.subscriptions\n",
    "for subscription in subscriptions:\n",
    "    sub_model_id = subscription.entity.asset.asset_id\n",
    "    if sub_model_id == model_uid:\n",
    "        wos_client.subscriptions.delete(subscription.metadata.id)\n",
    "        print('Deleted existing subscription for model', sub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26727b2e-d527-479c-8d00-7ec16d505235"
   },
   "outputs": [],
   "source": [
    "asset_deployment_details = wos_client.service_providers.list_assets(data_mart_id=DATA_MART_ID, \n",
    "    service_provider_id=SERVICE_PROVIDER_ID, deployment_id = deployment_uid, deployment_space_id=SPACE_ID).result['resources'][0]\n",
    "asset_deployment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f62a2af4-9707-4f99-9c5e-3bb5166a2834"
   },
   "outputs": [],
   "source": [
    "model_asset_details_from_deployment=wos_client.service_providers.get_deployment_asset(data_mart_id=DATA_MART_ID,\n",
    "    service_provider_id=SERVICE_PROVIDER_ID, deployment_id=deployment_uid, deployment_space_id=SPACE_ID)\n",
    "model_asset_details_from_deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3e1b973-1c6f-40d1-a1cb-f0bac9a55eb1"
   },
   "outputs": [],
   "source": [
    "subscription_details = wos_client.subscriptions.add(\n",
    "        data_mart_id=DATA_MART_ID,\n",
    "        background_mode=False,\n",
    "        service_provider_id=SERVICE_PROVIDER_ID,\n",
    "        asset=Asset(\n",
    "            asset_id=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"asset_id\"],\n",
    "            name=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"name\"],\n",
    "            url=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"url\"],\n",
    "            asset_type=AssetTypes.MODEL,\n",
    "            input_data_type=InputDataType.STRUCTURED,\n",
    "            problem_type=ProblemType.BINARY_CLASSIFICATION\n",
    "        ),\n",
    "        deployment=AssetDeploymentRequest(\n",
    "            deployment_id=asset_deployment_details['metadata']['guid'],\n",
    "            name=asset_deployment_details['entity']['name'],\n",
    "            deployment_type= DeploymentTypes.ONLINE,\n",
    "            url=asset_deployment_details['entity']['scoring_endpoint']['url']\n",
    "        ),\n",
    "        asset_properties=AssetPropertiesRequest(\n",
    "            label_column='Risk',\n",
    "            probability_fields=['probability'],\n",
    "            prediction_field='predictedLabel',\n",
    "            feature_fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"],\n",
    "            categorical_fields = [\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"],\n",
    "            training_data_reference=TrainingDataReference(\n",
    "            type=\"db2\",\n",
    "            location=DB2TrainingDataReferenceLocation(\n",
    "                    table_name=TRAINING_DATA_TABLE_NAME,\n",
    "                    schema_name=TRAINING_DATA_SCHEMA_NAME\n",
    "                ),\n",
    "                connection=DB2TrainingDataReferenceConnection.from_dict(DB2_CREDENTIALS)\n",
    "            ),\n",
    "            training_data_schema=SparkStruct.from_dict(model_asset_details_from_deployment[\"entity\"][\"asset_properties\"][\"training_data_schema\"])\n",
    "        )\n",
    "    ).result\n",
    "\n",
    "subscription_id = subscription_details.metadata.id\n",
    "subscription_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30b79ea6-b648-4a28-ad63-f13f6e99a7f5"
   },
   "outputs": [],
   "source": [
    "# Check Payload Logging table status\n",
    "\n",
    "import time\n",
    "\n",
    "time.sleep(5)\n",
    "payload_data_set_id = None\n",
    "payload_data_set_id = wos_client.data_sets.list(\n",
    "    type=DataSetTypes.PAYLOAD_LOGGING, \n",
    "    target_target_id=subscription_id, \n",
    "    target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n",
    "\n",
    "if payload_data_set_id is None:\n",
    "    print(\"Payload data set not found. Please check subscription status.\")\n",
    "else:\n",
    "    print(\"Payload data set id: \", payload_data_set_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8bb95e7-c217-46cc-8fb5-22f0668459ab"
   },
   "outputs": [],
   "source": [
    "# List all Subscription Data Sets\n",
    "\n",
    "wos_client.data_sets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4ee1c3f-5848-4753-bf56-1986dc7cbbc7"
   },
   "source": [
    "### 3.3 Score the model before Monitor Configurations\n",
    "\n",
    "Now that the WML service has been bound and the subscription has been created, we need to send a request to the model before we configure OpenScale. This allows OpenScale to create a payload log in the datamart with the correct schema, so it can capture data coming into and out of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c45f7cad-0b8e-4dce-929f-66dcf29bddca"
   },
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\n",
    "values = [\n",
    "  [\"no_checking\",13,\"credits_paid_to_date\",\"car_new\",1343,\"100_to_500\",\"1_to_4\",2,\"female\",\"none\",3,\"savings_insurance\",46,\"none\",\"own\",2,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",24,\"prior_payments_delayed\",\"furniture\",4567,\"500_to_1000\",\"1_to_4\",4,\"male\",\"none\",4,\"savings_insurance\",36,\"none\",\"free\",2,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",26,\"all_credits_paid_back\",\"car_new\",863,\"less_100\",\"less_1\",2,\"female\",\"co-applicant\",2,\"real_estate\",38,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",14,\"no_credits\",\"car_new\",2368,\"less_100\",\"1_to_4\",3,\"female\",\"none\",3,\"real_estate\",29,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",4,\"no_credits\",\"car_new\",250,\"less_100\",\"unemployed\",2,\"female\",\"none\",3,\"real_estate\",23,\"none\",\"rent\",1,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",17,\"credits_paid_to_date\",\"car_new\",832,\"100_to_500\",\"1_to_4\",2,\"male\",\"none\",2,\"real_estate\",42,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",33,\"outstanding_credit\",\"appliances\",5696,\"unknown\",\"greater_7\",4,\"male\",\"co-applicant\",4,\"unknown\",54,\"none\",\"free\",2,\"skilled\",1,\"yes\",\"yes\"],\n",
    "  [\"0_to_200\",13,\"prior_payments_delayed\",\"retraining\",1375,\"100_to_500\",\"4_to_7\",3,\"male\",\"none\",3,\"real_estate\",37,\"none\",\"own\",2,\"management_self-employed\",1,\"none\",\"yes\"]\n",
    "]\n",
    "\n",
    "payload_scoring = {\"fields\": fields,\"values\": values}\n",
    "payload = {\n",
    "    wml_client.deployments.ScoringMetaNames.INPUT_DATA: [payload_scoring]\n",
    "}\n",
    "scoring_response = wml_client.deployments.score(deployment_uid, payload)\n",
    "\n",
    "print('Single record scoring result:', '\\n fields:', scoring_response['predictions'][0]['fields'], '\\n values: ', scoring_response['predictions'][0]['values'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0a0738f4-00c6-43f2-83b8-9b5922e86f8d"
   },
   "outputs": [],
   "source": [
    "# Check whether WML payload logging worked; else manually store payload records\n",
    "\n",
    "import uuid\n",
    "from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n",
    "time.sleep(5)\n",
    "pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "print(\"Number of records in the payload logging table: {}\".format(pl_records_count))\n",
    "if pl_records_count == 0:\n",
    "    print(\"Payload logging did not happen, performing explicit payload logging.\")\n",
    "    wos_client.data_sets.store_records(data_set_id=payload_data_set_id, request_body=[PayloadRecord(\n",
    "                   scoring_id=str(uuid.uuid4()),\n",
    "                   request=payload_scoring,\n",
    "                   response={\"fields\": scoring_response['predictions'][0]['fields'], \"values\":scoring_response['predictions'][0]['values']},\n",
    "                   response_time=460\n",
    "               )])\n",
    "    time.sleep(5)\n",
    "    pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "    print(\"Number of records in the payload logging table: {}\".format(pl_records_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fc7c9b5-53b5-43a0-9f79-046601dc65c2"
   },
   "source": [
    "# 4. Monitor Configurations <a name=\"monitor\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f55bf10b-85c2-4509-a213-45f6349c6049"
   },
   "source": [
    "### 4.1 Quality Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acea4e6a-3bbe-4015-b876-e3c8f62f3241"
   },
   "source": [
    "The cell below waits ten seconds to allow the payload logging table to be set up before it begins enabling monitors. First, it turns on the quality (accuracy) monitor and sets an alert threshold of 80%.\n",
    "\n",
    "The second paramater supplied, `min_feedback_data_size`, specifies the minimum number of feedback records OpenScale needs before it calculates a new measurement and `max_rows_per_evaluation` specifies the maximum number of the records for which quality metrics can be evaluated. The quality monitor runs hourly, but the accuracy reading in the dashboard will not change until an additional 50 feedback records have been added, via the user interface, the Python client, or the supplied feedback logging endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78a0a128-ed48-47cb-b9eb-9087f8527b37"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(10)\n",
    "max_records = None\n",
    "#Update the max_records value when you want to consider it during quality metrics evaluation\n",
    "#max_records = 80\n",
    "\n",
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "\n",
    "parameters =  dict()\n",
    "parameters[\"min_feedback_data_size\"] = 50\n",
    "if max_records is not None:\n",
    "    parameters[\"max_rows_per_evaluation\"] = max_records\n",
    "\n",
    "thresholds = [\n",
    "    {\n",
    "        \"metric_id\": \"area_under_roc\",\n",
    "        \"type\": \"lower_limit\",\n",
    "        \"value\": 0.8\n",
    "    }\n",
    "]\n",
    "\n",
    "quality_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=DATA_MART_ID,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.QUALITY.ID,\n",
    "    target=target,\n",
    "    parameters=parameters,\n",
    "    thresholds=thresholds\n",
    ").result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eb6106f-507d-4da4-9067-733264ae8a7d"
   },
   "source": [
    "### 4.2 Fairness Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b1e8b9f-55f3-4ba6-98cc-c993dd56ca7c"
   },
   "source": [
    "The code below configures fairness monitoring for our model. It turns on monitoring for two features, `Sex` and `Age`. In each case, we must specify:\n",
    "  * Which model feature to monitor.\n",
    "  * One or more **majority** groups, which are values of that feature that we expect to receive a higher percentage of favorable outcomes.\n",
    "  * One or more **minority** groups, which are values of that feature that we expect to receive a higher percentage of unfavorable outcomes.\n",
    "  * The threshold at which we would like OpenScale to display an alert if the fairness measurement falls below (in this case, 95%).\n",
    "\n",
    "Additionally, we must specify which outcomes from the model are favourable outcomes, and which are unfavourable. We must also provide the number of records OpenScale will use to calculate the fairness score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3246422f-101a-4c6e-8743-e6d1f201c464"
   },
   "outputs": [],
   "source": [
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    \"features\": [\n",
    "        {\"feature\": \"Sex\",\n",
    "         \"majority\": ['male'],\n",
    "         \"minority\": ['female'],\n",
    "         \"threshold\": 0.95\n",
    "         },\n",
    "        {\"feature\": \"Age\",\n",
    "         \"majority\": [[26, 75]],\n",
    "         \"minority\": [[18, 25]],\n",
    "         \"threshold\": 0.95\n",
    "         }\n",
    "    ],\n",
    "    \"favourable_class\": [\"No Risk\"],\n",
    "    \"unfavourable_class\": [\"Risk\"],\n",
    "    \"min_records\": 50\n",
    "}\n",
    "\n",
    "fairness_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=DATA_MART_ID,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.FAIRNESS.ID,\n",
    "    target=target,\n",
    "    parameters=parameters).result\n",
    "\n",
    "fairness_monitor_instance_id =fairness_monitor_details.metadata.id\n",
    "fairness_monitor_instance_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5433d53-fdbb-4aa3-88a9-e37eec6a729a"
   },
   "source": [
    "### 4.3 Drift Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8c4f7a1-21fd-4cde-83cf-81c08e630942"
   },
   "outputs": [],
   "source": [
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    \"min_samples\": 50,\n",
    "    \"drift_threshold\": 0.1,\n",
    "    \"train_drift_model\": True,\n",
    "    \"enable_model_drift\": True,\n",
    "    \"enable_data_drift\": True\n",
    "}\n",
    "\n",
    "drift_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=DATA_MART_ID,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.DRIFT.ID,\n",
    "    target=target,\n",
    "    parameters=parameters\n",
    ").result\n",
    "\n",
    "drift_monitor_instance_id = drift_monitor_details.metadata.id\n",
    "drift_monitor_instance_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41fe18c5-eadf-45be-a47a-ba111c9ca522"
   },
   "source": [
    "### 4.4 Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "166c4ed2-d5df-4229-94a8-982116b058e6"
   },
   "outputs": [],
   "source": [
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "parameters = {\n",
    "    \"enabled\": True\n",
    "}\n",
    "explainability_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=DATA_MART_ID,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.EXPLAINABILITY.ID,\n",
    "    target=target,\n",
    "    parameters=parameters\n",
    ").result\n",
    "\n",
    "explainability_monitor_id = explainability_details.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50442029-d063-417d-913a-45bae68ab36f"
   },
   "outputs": [],
   "source": [
    "# Run Sample Explanation\n",
    "\n",
    "pl_records_resp = wos_client.data_sets.get_list_of_records(data_set_id=payload_data_set_id, limit=1, offset=0).result\n",
    "scoring_ids = [pl_records_resp[\"records\"][0][\"entity\"][\"values\"][\"scoring_id\"]]\n",
    "\n",
    "print(\"Running explanations on scoring IDs: {}\".format(scoring_ids))\n",
    "explanation_types = [\"lime\", \"contrastive\"]\n",
    "result = wos_client.monitor_instances.explanation_tasks(scoring_ids=scoring_ids, explanation_types=explanation_types, subscription_id=subscription_id).result\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "853d614e-732f-4f1e-a4ad-aa9dca13c535"
   },
   "source": [
    "### 4.5 MRM Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e401efb0-57f7-4faf-9c77-a72f47e5d231"
   },
   "outputs": [],
   "source": [
    "# Configuring MRM\n",
    "\n",
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "parameters = {\n",
    "    \"enabled\": True\n",
    "}\n",
    "mrm_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=DATA_MART_ID,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=\"mrm\",\n",
    "    target=target,\n",
    "    parameters=parameters\n",
    ").result\n",
    "\n",
    "MRM_MONITOR_INSTANCE_ID = mrm_details.metadata.id\n",
    "MRM_MONITOR_INSTANCE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baa151826ff248bb8b9b02e92df03d03"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_definitions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef5d09b9-37b0-4624-b125-3e69ec0ae55e"
   },
   "source": [
    "## 5. MRM Evaluation <a name=\"mrm\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "760284c9-ea56-4154-8e2d-bd52a79671bc"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "time.sleep(20)\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"type\": \"db2\",\n",
    "  \"connection\": DB2_CREDENTIALS,\n",
    "  \"location\": {\n",
    "    \"schema_name\": EVALUATION_DATA_SCHEMA_NAME,\n",
    "    \"table_name\": EVALUATION_DATA_TABLE_NAME\n",
    "    }\n",
    "})\n",
    "\n",
    "file_name = \"test_data.json\"\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    file.write(payload)\n",
    "\n",
    "response = wos_client.monitor_instances.mrm.evaluate_risk(\n",
    "                monitor_instance_id = MRM_MONITOR_INSTANCE_ID,\n",
    "                test_data_set_name = TEST_DATA_SET_NAME,\n",
    "                feedback_data_path = file_name,\n",
    "                content_type = \"application/json\")\n",
    "\n",
    "print(response.result._to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15a1194b-845b-491f-855d-94fe95c2192d"
   },
   "source": [
    "### 5.1 Checking MRM evaluation progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ba8672d-f949-42b4-b81c-9d6601f39c1e"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_risk_evaluations():\n",
    "    \n",
    "    response = wos_client.monitor_instances.mrm.get_risk_evaluation(\n",
    "                    monitor_instance_id = MRM_MONITOR_INSTANCE_ID).result\n",
    "    \n",
    "    return response._to_dict()\n",
    "\n",
    "risk_evaluations_resp = get_risk_evaluations()\n",
    "\n",
    "while risk_evaluations_resp[\"entity\"][\"status\"][\"state\"] == \"UPLOAD_IN_PROGRESS\":\n",
    "    print(\"UPLOAD_IN_PROGRESS\")\n",
    "    time.sleep(50)\n",
    "    risk_evaluations_resp = get_risk_evaluations()\n",
    "\n",
    "while risk_evaluations_resp[\"entity\"][\"status\"][\"state\"] not in [\"finished\", \"error\"]:\n",
    "    print(\"EVALUATION_IN_PROGRESS\")\n",
    "    time.sleep(50)\n",
    "    risk_evaluations_resp = get_risk_evaluations()\n",
    "\n",
    "mrm_evaluation_state = risk_evaluations_resp[\"entity\"][\"status\"][\"state\"]\n",
    "if mrm_evaluation_state == \"finished\":\n",
    "    print(\"EVALUATION_COMPLETED\")\n",
    "else:\n",
    "    print(\"MRM evaluation failed with state {}, error {}\".format(mrm_evaluation_state, risk_evaluations_resp.json()[\"entity\"][\"status\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b4cac67-f5c0-44f6-a64c-d1f27e06fb0a"
   },
   "source": [
    "### 5.2 Get Published Fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "077fd4b3-ca47-42f4-afcb-0c318d56ca45"
   },
   "outputs": [],
   "source": [
    "def get_published_fact():\n",
    "\n",
    "    url = \"{}/v1/aigov/model_inventory/models/{}/system_facts?space_id={}&deployment_id={}\".format(\n",
    "        cpd_url, model_uid, SPACE_ID, deployment_uid)\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': 'Bearer {}'.format(wos_client.authenticator.token_manager.get_token()),\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, verify=False)\n",
    "    return response\n",
    "\n",
    "# Wait for a minute before fetching the published Fact\n",
    "time.sleep(60)\n",
    "\n",
    "published_fact = get_published_fact()\n",
    "print(json.dumps(published_fact.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have reached the end of the demo notebook. Thanks for trying it out :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef44eb79-f30e-45d7-aab2-691fd304088e"
   },
   "source": [
    "### Authors\n",
    "Developed by [Harshit Sharma](mailto:harshit2@in.ibm.com), Staff Software Engineer, Watson OpenScale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
