{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on generating an explanation for an image-based binary classifier model on Watson OpenScale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "- [1. Setup](#setup)\n",
    "- [2. Creating and deploying an image-based model](#deployment)\n",
    "- [3. Subscriptions](#subscription)\n",
    "- [4. Explainability](#explainability)\n",
    "\n",
    "\n",
    "**Note:** This notebook works correctly with kernel `IBM Runtime 22.1 on Python 3.9 / IBM Runtime 22.2 on Python 3.10` if you are using IBM Watson Studio or `Python 3.9.x / Python 3.10.x` if using any other tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup\n",
    "\n",
    "### 1.1 Install OS and WML packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-watson-machine-learning --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Restart the kernel to assure the new libraries are being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WOS_CREDENTIALS (CP4D)\n",
    "- WML_CREDENTIALS (CP4D)\n",
    "- DATABASE_CREDENTIALS (DB2 on CP4D or Cloud Object Storage (COS))\n",
    "- SCHEMA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"***\",\n",
    "    \"username\": \"***\",\n",
    "    \"password\": \"***\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {\n",
    "                   \"url\": \"***\",\n",
    "                   \"username\": \"***\",\n",
    "                   \"password\" : \"***\",\n",
    "                   \"instance_id\": \"wml_local\",\n",
    "                   \"version\" : \"4.6\" #If your env is CP4D 4.x.x then specify \"4.x.x\" instead of \"4.6\"\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deployment\"></a>\n",
    "## 2. Creating and deploying an image-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a binary classifier which classifies an image as a Dog or a Cat (Probability: 1 = dog, 0 = cat). The dataset can be downloaded from here: https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data. The dataset can also be found here: https://ibm.box.com/shared/static/itl0el289mz06py2e6aemehx6lge1rou.zip\n",
    "\n",
    "Now, create a folder named `data` and inside it create subdirectories: `train` and `validation`. Further, create folders named `dogs` and `cats` (as shown below) with 1024 dog and cat images in the `train` directory and 416 dog and cat images in the `validation` directory respectively. Post unzipping the downloaded zip file, use the images from the `train` folder found after unzipping `train.zip`.\n",
    "\n",
    "```python\n",
    "data/\n",
    "    train/\n",
    "        dogs/ # 1024 pictures\n",
    "            dog.1.jpg\n",
    "            dog.2.jpg\n",
    "            ...\n",
    "        cats/ # 1024 pictures\n",
    "            cat.1.jpg\n",
    "            cat.2.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/ # 416 pictures\n",
    "            dog.1025.jpg\n",
    "            dog.1026.jpg\n",
    "            ...\n",
    "        cats/ # 416 pictures\n",
    "            cat.1025.jpg\n",
    "            cat.1026.jpg\n",
    "            ...\n",
    "```\n",
    "\n",
    "Note: Keras and TensorFlow versions supported by WML are: Keras 2.2.5 with TensorFlow 1.15 backend. This combination is used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Uncomment the code only if you are not running this in IBM watson Studio\n",
    "\n",
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install keras_sequential_ascii\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "#print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you are running this in IBM watson Studio, Upload the zipped data folder created to watson studio project and run the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# from ibm_watson_studio_lib import access_project_or_space\n",
    "# wslib = access_project_or_space()\n",
    "# wslib.download_file(\"data.zip\")\n",
    "\n",
    "# z = zipfile.ZipFile(\"data.zip\")\n",
    "# z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the images\n",
    "img_width, img_height = 90, 90\n",
    "\n",
    "train_data_dir = 'data/train/'\n",
    "validation_data_dir = 'data/validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Please modify the paths above accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "#used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "\n",
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10 # One can increase the no. of epochs to get better accuracy\n",
    "train_samples = 2048\n",
    "validation_samples = 832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_n = base_model()\n",
    "cnn_n.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizing model structure\n",
    "sequential_model_to_ascii_printout(cnn_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "cnn_n.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_steps=validation_samples // batch_size,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_n.save('dog_cat_cnn.h5')\n",
    "!rm dog_cat_cnn.tar*\n",
    "!tar -czvf dog_cat_cnn.tar.gz dog_cat_cnn.h5\n",
    "!rm dog_cat_cnn.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cnn_n.evaluate_generator(validation_generator, validation_samples)\n",
    "print(scores)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Storing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "wml_client = APIClient(WML_CREDENTIALS)\n",
    "wml_client.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_client.spaces.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WML_SPACE_ID='***' # use space id here\n",
    "wml_client.set.default_space(WML_SPACE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Dog-Cat binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "software_spec_uid = wml_client.software_specifications.get_uid_by_name(\"tensorflow_rt22.2-py3.10\")\n",
    "print(\"Software Specification ID: {}\".format(software_spec_uid))\n",
    "model_props = {\n",
    "        wml_client.repository.ModelMetaNames.NAME:\"{}\".format(MODEL_NAME),\n",
    "        wml_client.repository.ModelMetaNames.TYPE: 'tensorflow_2.9',\n",
    "        wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Storing model ...\")\n",
    "published_model_details = wml_client.repository.store_model(\n",
    "    model='dog_cat_cnn.tar.gz', \n",
    "    meta_props=model_props, \n",
    ")\n",
    "\n",
    "model_uid = wml_client.repository.get_model_id(published_model_details)\n",
    "print(\"Done\")\n",
    "print(\"Model ID: {}\".format(model_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_details = wml_client.deployments.create(\n",
    "    model_uid, \n",
    "    meta_props={\n",
    "        wml_client.deployments.ConfigurationMetaNames.NAME: \"{}\".format(MODEL_NAME + \" deployment\"),\n",
    "        wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    ")\n",
    "scoring_url = wml_client.deployments.get_scoring_href(deployment_details)\n",
    "deployment_uid=wml_client.deployments.get_id(deployment_details)\n",
    "\n",
    "print(\"Scoring URL:\" + scoring_url)\n",
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Subscriptions <a id=\"subscription\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Configuring OpenScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install scikit-image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize\n",
    "\n",
    "img = mpimg.imread(\"data/train/dogs/dog.0.jpg\")\n",
    "img = resize(img, (90, 90))\n",
    "print(img.shape)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "from ibm_watson_openscale import APIClient\n",
    "\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "\n",
    "\n",
    "authenticator = CloudPakForDataAuthenticator(\n",
    "        url=WOS_CREDENTIALS['url'],\n",
    "        username=WOS_CREDENTIALS['username'],\n",
    "        password=WOS_CREDENTIALS['password'],\n",
    "        disable_ssl_verification=True\n",
    "    )\n",
    "\n",
    "wos_client = APIClient(service_url=WOS_CREDENTIALS['url'],authenticator=authenticator)\n",
    "wos_client.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DB_CREDENTIALS= {\"hostname\":\"\",\"username\":\"\",\"password\":\"\",\"database\":\"\",\"port\":\"\",\"ssl\":True,\"sslmode\":\"\",\"certificate_base64\":\"\"}\n",
    "DB_CREDENTIALS = None\n",
    "KEEP_MY_INTERNAL_POSTGRES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_marts = wos_client.data_marts.list().result.data_marts\n",
    "if len(data_marts) == 0:\n",
    "    if DB_CREDENTIALS is not None:\n",
    "        if SCHEMA_NAME is None: \n",
    "            print(\"Please specify the SCHEMA_NAME and rerun the cell\")\n",
    "\n",
    "        print('Setting up external datamart')\n",
    "        added_data_mart_result = wos_client.data_marts.add(\n",
    "                background_mode=False,\n",
    "                name=\"WOS Data Mart\",\n",
    "                description=\"Data Mart created by WOS tutorial notebook\",\n",
    "                database_configuration=DatabaseConfigurationRequest(\n",
    "                  database_type=DatabaseType.POSTGRESQL,\n",
    "                    credentials=PrimaryStorageCredentialsLong(\n",
    "                        hostname=DB_CREDENTIALS['hostname'],\n",
    "                        username=DB_CREDENTIALS['username'],\n",
    "                        password=DB_CREDENTIALS['password'],\n",
    "                        db=DB_CREDENTIALS['database'],\n",
    "                        port=DB_CREDENTIALS['port'],\n",
    "                        ssl=True,\n",
    "                        sslmode=DB_CREDENTIALS['sslmode'],\n",
    "                        certificate_base64=DB_CREDENTIALS['certificate_base64']\n",
    "                    ),\n",
    "                    location=LocationSchemaName(\n",
    "                        schema_name= SCHEMA_NAME\n",
    "                    )\n",
    "                )\n",
    "             ).result\n",
    "    else:\n",
    "        print('Setting up internal datamart')\n",
    "        added_data_mart_result = wos_client.data_marts.add(\n",
    "                background_mode=False,\n",
    "                name=\"WOS Data Mart\",\n",
    "                description=\"Data Mart created by WOS tutorial notebook\", \n",
    "                internal_database = True).result\n",
    "        \n",
    "    data_mart_id = added_data_mart_result.metadata.id\n",
    "    \n",
    "else:\n",
    "    data_mart_id=data_marts[0].metadata.id\n",
    "    print('Using existing datamart {}'.format(data_mart_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_PROVIDER_NAME = \"Image Binary WML V2_test\"\n",
    "SERVICE_PROVIDER_DESCRIPTION = \"Added by tutorial WOS notebook.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_providers = wos_client.service_providers.list().result.service_providers\n",
    "for service_provider in service_providers:\n",
    "    service_instance_name = service_provider.entity.name\n",
    "    if service_instance_name == SERVICE_PROVIDER_NAME:\n",
    "        service_provider_id = service_provider.metadata.id\n",
    "        wos_client.service_providers.delete(service_provider_id)\n",
    "        print(\"Deleted existing service_provider for WML instance: {}\".format(service_provider_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_service_provider_result = wos_client.service_providers.add(\n",
    "        name=SERVICE_PROVIDER_NAME,\n",
    "        description=SERVICE_PROVIDER_DESCRIPTION,\n",
    "        service_type=ServiceTypes.WATSON_MACHINE_LEARNING,\n",
    "        deployment_space_id = WML_SPACE_ID,\n",
    "        operational_space_id = \"production\",\n",
    "        credentials=WMLCredentialsCP4D(\n",
    "            url=WML_CREDENTIALS[\"url\"],\n",
    "            username=WML_CREDENTIALS[\"username\"],\n",
    "            password=WML_CREDENTIALS[\"password\"],\n",
    "            instance_id=None\n",
    "        ),\n",
    "        background_mode=False\n",
    "    ).result\n",
    "service_provider_id = added_service_provider_result.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_deployment_details = wos_client.service_providers.list_assets(data_mart_id=data_mart_id, service_provider_id=service_provider_id, deployment_id = deployment_uid,deployment_space_id = WML_SPACE_ID).result['resources'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_asset_details_from_deployment=wos_client.service_providers.get_deployment_asset(data_mart_id=data_mart_id,service_provider_id=service_provider_id,deployment_id=deployment_uid,deployment_space_id=WML_SPACE_ID)\n",
    "model_asset_details_from_deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Subscribe the asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptions = wos_client.subscriptions.list().result.subscriptions\n",
    "for subscription in subscriptions:\n",
    "    sub_model_id = subscription.entity.asset.asset_id\n",
    "    if sub_model_id == model_uid:\n",
    "        wos_client.subscriptions.delete(subscription.metadata.id)\n",
    "        print('Deleted existing subscription for model', sub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import ScoringEndpointRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_details = wos_client.subscriptions.add(\n",
    "        data_mart_id=data_mart_id,\n",
    "        service_provider_id=service_provider_id,\n",
    "        asset=Asset(\n",
    "            asset_id=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"asset_id\"],\n",
    "            name=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"name\"],\n",
    "            url=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"url\"],\n",
    "            asset_type=AssetTypes.MODEL,\n",
    "            input_data_type=InputDataType.UNSTRUCTURED_IMAGE,\n",
    "            problem_type=ProblemType.BINARY_CLASSIFICATION\n",
    "        ),\n",
    "        deployment=AssetDeploymentRequest(\n",
    "            deployment_id=asset_deployment_details['metadata']['guid'],\n",
    "            name=asset_deployment_details['entity']['name'],\n",
    "            deployment_type= DeploymentTypes.ONLINE,\n",
    "            url=model_asset_details_from_deployment['entity']['asset']['url'],\n",
    "            scoring_endpoint=ScoringEndpointRequest(url=scoring_url) # scoring model without shadow deployment\n",
    "        ),\n",
    "        asset_properties=AssetPropertiesRequest(\n",
    "            probability_fields=['probability']\n",
    "            )\n",
    "    ).result\n",
    "subscription_id = subscription_details.metadata.id\n",
    "subscription_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(5)\n",
    "payload_data_set_id = None\n",
    "payload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n",
    "                                                target_target_id=subscription_id, \n",
    "                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n",
    "if payload_data_set_id is None:\n",
    "    print(\"Payload data set not found. Please check subscription status.\")\n",
    "else:\n",
    "    print(\"Payload data set id: \", payload_data_set_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Score the model and get transaction-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_data={\"input_data\": [{\"values\": [img.tolist()]}]}\n",
    "predictions = wml_client.deployments.score(deployment_uid, scoring_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.data_sets.get_records_count(payload_data_set_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"explainability\"></a>\n",
    "## 4. Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Configure Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "parameters = {\n",
    "    \"enabled\": True\n",
    "}\n",
    "explainability_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.EXPLAINABILITY.ID,\n",
    "    target=target,\n",
    "    parameters=parameters\n",
    ").result\n",
    "\n",
    "explainability_monitor_id = explainability_details.metadata.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Get explanation for the transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_records_resp = wos_client.data_sets.get_list_of_records(data_set_id=payload_data_set_id, limit=1, offset=0).result\n",
    "scoring_ids = [pl_records_resp[\"records\"][0][\"entity\"][\"values\"][\"scoring_id\"]]\n",
    "print(\"Running explanations on scoring IDs: {}\".format(scoring_ids))\n",
    "explanation_types = [\"lime\", \"contrastive\"]\n",
    "result = wos_client.monitor_instances.explanation_tasks(scoring_ids=scoring_ids, explanation_types=explanation_types, subscription_id=subscription_id).result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_task_id=result.to_dict()['metadata']['explanation_task_ids'][0]\n",
    "explanation=wos_client.monitor_instances.get_explanation_tasks(explanation_task_id=explanation_task_id, subscription_id=subscription_id).result.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The explanation images can be obtained using the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "time.sleep(45) # sleep for 45 second so explanation finishes\n",
    "pred = explanation[\"entity\"]['explanations'][0]['predictions'][0]\n",
    "print(\"Explanation for {} region:\".format(pred[\"value\"]))\n",
    "\n",
    "img = pred[\"explanation\"][0][\"full_image\"]\n",
    "img_data = base64.b64decode(img)\n",
    "Image.open(io.BytesIO(img_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred = explanation[\"entity\"]['explanations'][0]['predictions'][1]\n",
    "print(\"Explanation for {} region:\".format(pred[\"value\"]))\n",
    "\n",
    "img = pred[\"explanation\"][0][\"full_image\"]\n",
    "img_data = base64.b64decode(img)\n",
    "Image.open(io.BytesIO(img_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Quality\"></a>\n",
    "## 5. Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Configure Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "parameters = {\n",
    "    \"min_feedback_data_size\": 20\n",
    "}\n",
    "quality_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.QUALITY.ID,\n",
    "    target=target,\n",
    "    parameters=parameters\n",
    ").result\n",
    "\n",
    "quality_monitor_id = quality_details.metadata.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Store feedback record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_dataset_id = None\n",
    "feedback_dataset = wos_client.data_sets.list(type=DataSetTypes.FEEDBACK, \n",
    "                                                target_target_id=subscription_id, \n",
    "                                                target_target_type=TargetTypes.SUBSCRIPTION).result\n",
    "print(feedback_dataset)\n",
    "feedback_dataset_id = feedback_dataset.data_sets[0].metadata.id\n",
    "if feedback_dataset_id is None:\n",
    "    print(\"Feedback data set not found. Please check quality monitor status.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = []\n",
    "for i in range(10):\n",
    "    catimagePath = \"data/validation/cats/cat.\" + str(i+1) + \".jpg\"\n",
    "    dogimagePath = \"data/validation/dogs/dog.\" + str(i+1) + \".jpg\"\n",
    "    catimg = mpimg.imread(catimagePath)\n",
    "    catimg = resize(catimg, (90, 90))\n",
    "    dogimg = mpimg.imread(dogimagePath)\n",
    "    dogimg = resize(dogimg, (90, 90))\n",
    "    catelement = {\"scoring_input\":catimg.tolist(), \"target\":0}\n",
    "    dogelement = {\"scoring_input\":dogimg.tolist(), \"target\":1}\n",
    "    feedback.append(catelement)\n",
    "    feedback.append(dogelement)\n",
    "wos_client.data_sets.store_records(feedback_dataset_id, request_body=feedback, background_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Run Quality monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_details = wos_client.monitor_instances.run(monitor_instance_id=quality_monitor_id, background_mode=False).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=quality_monitor_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
