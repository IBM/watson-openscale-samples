{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9022bf7",
   "metadata": {},
   "source": [
    "# Watson OpenScale Fairness Metrics and Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1fe6a",
   "metadata": {},
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "The notebook will train a German Credit Risk model, compute Fairness Metrics **Statistical Parity Difference** and **Smoothed Empirical Differential** on the model prediction and then show how **Fair Score Transformer** can be used to transform the model output for fair prediction.<br/>\n",
    "\n",
    "This document includes below sections, you will *`edit`* and *`restart`* notebook kernel in **Setup** section:\n",
    "\n",
    "- [1.Introduction](#introduction)\n",
    "- [2.Setup Envrionments](#setup)\n",
    "- [3.Statistical Parity Difference](#spd)\n",
    "- [4.Smoothed Empirical Differential](#sed)\n",
    "- [5.Fair Score Transformer](#fst)\n",
    "\n",
    "**Note:** This notebook should be run using with **Python 3.9.x** runtime. It requires service credentials for the following services:\n",
    "  * Watson OpenScale <br/>\n",
    "  * IBM Analytics Engine <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee20870",
   "metadata": {},
   "source": [
    "## 2. Setup Envrionments <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cd0e6",
   "metadata": {},
   "source": [
    "### 2.1 Package installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2734bc",
   "metadata": {},
   "source": [
    "*[Optional]* ignore warning messages to make output more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642752ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c200347",
   "metadata": {},
   "source": [
    "Install packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6fe610",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1\n",
    "!pip install --upgrade ibm-metrics-plugin --user | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57591666",
   "metadata": {},
   "source": [
    "**Action: Restrat the kernel\\!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b5c9f",
   "metadata": {},
   "source": [
    "### 2.2 Configure credentials for WASTON OpenScale \n",
    "Configure credentials for WASTON OpenScale into the authenticator, which will be used in OpenScale client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "\n",
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"<cluster-url>\",\n",
    "    \"username\": \"<username>\",\n",
    "    \"password\": \"<password>\",\n",
    "    \"instance_id\": \"<openscale instance id>\"\n",
    "}\n",
    "\n",
    "authenticator = CloudPakForDataAuthenticator(\n",
    "    url=WOS_CREDENTIALS[\"url\"],\n",
    "    username=WOS_CREDENTIALS[\"username\"],\n",
    "    password=WOS_CREDENTIALS[\"password\"],\n",
    "    disable_ssl_verification=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c378e63",
   "metadata": {},
   "source": [
    "### 2.3 Configure credentials for IBM Analytics Engine - Spark\n",
    "\n",
    "Make sure that the Apache Spark manager on IBM Analytics Engine is running, and then provide the following details:\n",
    "\n",
    "- IAE_SPARK_DISPLAY_NAME: _Display Name of the Spark instance in IBM Analytics Engine_\n",
    "- IAE_SPARK_JOBS_ENDPOINT: _Spark Jobs Endpoint for IBM Analytics Engine_\n",
    "- IBM_CPD_VOLUME: _IBM Cloud Pak for Data storage volume name_\n",
    "- IBM_CPD_USERNAME: _IBM Cloud Pak for Data username_\n",
    "- IBM_CPD_APIKEY: _IBM Cloud Pak for Data API key_\n",
    "- IAE_INSTANCE_ID: _IBM Analytics Engine spark instance id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d87fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IAE_SPARK_DISPLAY_NAME = \"<spark-engine-name>\"\n",
    "IAE_SPARK_JOBS_ENDPOINT = \"<spark-job-endpoint-for-ibm-analytics-engine>\"\n",
    "IBM_CPD_VOLUME = \"<ibm-cpd-volume>\"\n",
    "IBM_CPD_USERNAME = \"<ibm-cloud-pak-for-data-username>\"\n",
    "IBM_CPD_APIKEY = \"<ibm-cloud-pak-for-data-apikey>\"\n",
    "IAE_INSTANCE_ID = \"<ibm-analytics-engine-spark-instance-id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e81fb6",
   "metadata": {},
   "source": [
    "The credential informations will be used to run spark job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {\n",
    "            \"connection\": {\n",
    "                \"endpoint\": IAE_SPARK_JOBS_ENDPOINT,\n",
    "                \"location_type\": \"cpd_iae\",\n",
    "                \"display_name\": IAE_SPARK_DISPLAY_NAME,\n",
    "                \"instance_id\": IAE_INSTANCE_ID,\n",
    "                \"volume\": IBM_CPD_VOLUME\n",
    "            },\n",
    "            \"credentials\": {\n",
    "                \"username\": IBM_CPD_USERNAME,\n",
    "                \"apikey\":IBM_CPD_APIKEY\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7696b",
   "metadata": {},
   "source": [
    "### 2.4 Configure resource setting for Spark job\n",
    "\n",
    "To configure how much of your Spark Cluster resources this job can consume, edit the following values:\n",
    "\n",
    "- max_num_executors: _Maximum Number of executors to launch for this session_\n",
    "- min_executors: _Minimum Number of executors to launch for this session_\n",
    "- executor_cores: _Number of cores to use for each executor_   \n",
    "- executor_memory: _Amount of memory (in GBs) to use per executor process_\n",
    "- driver_cores: _Number of cores to use for the driver process_\n",
    "- driver_memory: _Amount of memory (in GBs) to use for the driver process_\n",
    "\n",
    "These informations will be configured into spark job parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0286e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_parameters = {\n",
    "                \"max_num_executors\": 4,\n",
    "                \"min_executors\": 1,\n",
    "                \"executor_cores\": 1,\n",
    "                \"executor_memory\": 1,\n",
    "                \"driver_cores\": 1,\n",
    "                \"driver_memory\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65363d",
   "metadata": {},
   "source": [
    "### 2.5 Configure storage parameters for Spark job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7487df",
   "metadata": {},
   "source": [
    "In this notebook, DB2 is used as the storage source of input datasets. \n",
    "#### Storage Inputs\n",
    "\n",
    "Please enter a name and description for your JDBC Storage\n",
    "\n",
    "- JDBC_CONNECTION_NAME: _Custom display name for the JDBC Storage Connection_\n",
    "- JDBC_CONNECTION_DESCRIPTION: _Custom description for the JDBC Storage Connection_\n",
    "\n",
    "To connect to your JDBC storage, you must provide the following details:\n",
    "\n",
    " - JDBC_HOST: Hostname of the JDBC Connection\n",
    " - JDBC_PORT: Port of the JDBC Connection\n",
    " - JDBC_USE_SSL: Boolean Flag to indicate whether to use SSL while connecting.\n",
    " - JDBC_SSL_CERTIFICATE: SSL Certificate [Base64 encoded string] of the JDBC Connection. Ignored if JDBC_USE_SSL is False.\n",
    " - JDBC_DRIVER: Class name of the JDBC driver to use to connect.\n",
    " - JDBC_USERNAME: Username of the JDBC Connection\n",
    " - JDBC_PASSWORD: Password of the JDBC Connection\n",
    " - JDBC_DATABASE_NAME: Name of the Database to connect to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "JDBC_HOST = \"<Hostname of the JDBC Connection>\"\n",
    "JDBC_PORT = \"<Port of the JDBC Connection>\"\n",
    "JDBC_USE_SSL = \"<Boolean Flag to indicate whether to use SSL while connecting.>\"\n",
    "JDBC_SSL_CERTIFICATE = \"<SSL Certificate [Base64 encoded string] of the JDBC Connection. Ignored if JDBC_USE_SSL is False.>\"\n",
    "JDBC_DRIVER = \"<Class name of the JDBC driver to use to connect.>\"\n",
    "JDBC_USERNAME = \"<Username of the JDBC Connection>\"\n",
    "JDBC_PASSWORD = \"<Password of the JDBC Connection>\"\n",
    "JDBC_DATABASE_NAME = \"<Name of the Database to connect to.>\"\n",
    "\n",
    "jdbc_url = \"jdbc:db2://{}:{}/{}\".format(JDBC_HOST, JDBC_PORT, JDBC_DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e353e4c",
   "metadata": {},
   "source": [
    "These informations will be configrued into storage_details session of spark job parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_details = {\n",
    "    \"type\": \"jdbc\",\n",
    "    \"connection\": {\n",
    "        \"jdbc_driver\": JDBC_DRIVER,\n",
    "        \"jdbc_url\": jdbc_url,\n",
    "        \"use_ssl\": JDBC_USE_SSL,\n",
    "        \"certificate\": JDBC_SSL_CERTIFICATE,\n",
    "        \"location_type\": \"jdbc\"\n",
    "    },\n",
    "    \"credentials\":{\n",
    "        \"username\": JDBC_USERNAME,\n",
    "        \"password\": JDBC_PASSWORD,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452d7b5",
   "metadata": {},
   "source": [
    "#### Training table metadata\n",
    "\n",
    "Each quality monitor could use its own training table from the database, so the table metadata will be addressed respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc523e5",
   "metadata": {},
   "source": [
    "### 2.6 Setup OpenScale client \n",
    "Setup a Python OpenScale client with above setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_openscale import APIClient as OpenScaleAPIClient\n",
    "\n",
    "client = OpenScaleAPIClient(\n",
    "    service_url=WOS_CREDENTIALS['url'],\n",
    "    service_instance_id=WOS_CREDENTIALS[\"instance_id\"],\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77101c",
   "metadata": {},
   "source": [
    "## 3. Statistical Parity Difference <a name=\"spd\"></a>\n",
    "\n",
    "**Statistical Parity Difference** is a fairness metric that can be used to describe the fairness for the model predictions.\n",
    "It is the difference between the ratio of favourable outcomes in unprivileged and privileged groups. It can\n",
    "be computed from either the input dataset or the dataset output from a classifier (predicted dataset). A value\n",
    "of 0 implies both groups have equal benefit, a value less than 0 implies higher benefit for the privileged group, and a value greater than 0 implies higher benefit for the unprivileged group.<br>\n",
    "$$ð‘ƒ(ð‘Œ=1|ð·=unprivileged)âˆ’ð‘ƒ(ð‘Œ=1|ð·=privileged)$$\n",
    "\n",
    "Take the German credit risk datasets as example, if user set\n",
    "+ privileged group as Sex=\"male\" \n",
    "+ unprivileged group as Sex=\"female\"\n",
    "\n",
    "and set\n",
    "+ favourable label as Risk=\"No Risk\"\n",
    "+ unfavourable label as Risk=\"Risk\"\n",
    "\n",
    "then, the SPD result \n",
    "+ spd > 0 means the unpriviliage group Sex=\"female\" has higher rate to be marked as favourable label \"No Risk\" than priviliage group Sex=\"male\".\n",
    "+ spd = 0 means the unpriviliage group Sex=\"female\" has same rate to be marked as favourable label \"No Risk\" with priviliage group Sex=\"male\".\n",
    "+ spd < 0 means the unpriviliage group Sex=\"female\" has lower rate to be marked as favourable label \"No Risk\" than priviliage group Sex=\"male\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a184a",
   "metadata": {},
   "source": [
    "### 3.1 Prepare input for Statistical Parity Difference\n",
    "The quality monitor stores metadata in the training table.\n",
    "\n",
    "- TRAIN_SCHEMA_NAME: _Schema name where training table is present_\n",
    "- TRAIN_TABLE_NAME: _Name of the training table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975792d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCHEMA_NAME = \"***\"\n",
    "TRAIN_TABLE_NAME = \"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3eec4",
   "metadata": {},
   "source": [
    "These informations will be configured into tables session of spark job paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d741e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    {\n",
    "        \"database\": JDBC_DATABASE_NAME,\n",
    "        \"schema\": TRAIN_SCHEMA_NAME,\n",
    "        \"table\": TRAIN_TABLE_NAME,\n",
    "        \"type\": \"training\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc2ba9",
   "metadata": {},
   "source": [
    "### 3.2  Statistical Parity Difference Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd78e03",
   "metadata": {},
   "source": [
    "Setup configuration to compute *Statistical Parity Difference*,<br/>\n",
    "\n",
    "Configure label and problem type in the overall section.\n",
    "- **problem_type(str)**: `binary` and `multi-classification` is supported.\n",
    "- **label_column(str)**: Column name of label in the data frame\n",
    "\n",
    "Inside `fairness` as below, there are three sections which is required to configure.\n",
    "- **metrics_configuration(dict)**: Configure *Statistical Parity Difference* as one of the metrics with name `FairnessMetricType.SPD.value`, and it requires a `features` property to describe which features the metric will be computed upon. *Statistical Parity Difference* is supported to run with individual features (eg. `[[\"a\"],[\"b\"]]`), but not suppored to run with intersectional features (eg. `[[\"a\", \"b\"]]`).\n",
    "\n",
    "- **protected_attributes(list)**: Describe privileged group defintion for features upon which this metric will be computed. Configure each feature with below information:\n",
    "  - feature(str): Name of the feature, which should be same as configured in `features` of `metrics_configuration` section.\n",
    "  - reference_group(list): List of feature values which make a sample privileged. \n",
    "\n",
    "- **favourable_label(list)**: A list of favourable labels or outcomes of the model.\n",
    "\n",
    "\n",
    "**Note** that `label_column` used here is the new added `pred` column.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_metrics_plugin.common.utils.constants import FairnessMetricType, MetricGroupType\n",
    "spd_config = {\n",
    "            \"problem_type\": \"***\",\n",
    "            \"label_column\" : \"***\",\n",
    "            \"fairness\": {\n",
    "                            \"metrics_configuration\": {\n",
    "                                FairnessMetricType.SPD.value: {\n",
    "                                    \"features\": [ [\"***\"] ]                                \n",
    "                                }\n",
    "                            },\n",
    "                            \"protected_attributes\": [\n",
    "                                {\n",
    "                                    \"feature\": \"***\",\n",
    "                                    \"reference_group\": [\"***\"]\n",
    "                                }\n",
    "                            ],\n",
    "                            \"favourable_label\": [\"***\"]\n",
    "                        }\n",
    "        }\n",
    "\n",
    "spd_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aa441a",
   "metadata": {},
   "source": [
    "### 3.3 Compute Statistical Parity Difference\n",
    "IAE credentials and spark job parameters will be used here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5cd5b7",
   "metadata": {},
   "source": [
    "update all configurations into the spark job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf33191",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = {\n",
    "            \"spark_settings\": spark_parameters,\n",
    "            \"arguments\": {\n",
    "                \"monitoring_run_id\": \"my_monitoring_run_id\",\n",
    "                \"storage\": storage_details,\n",
    "                \"tables\": tables,\n",
    "                \"metric_configuration\": spd_config\n",
    "            }\n",
    "        }\n",
    "\n",
    "job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681cf940",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = client.ai_metrics.compute_metrics_as_job(credentials, job_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86167b2",
   "metadata": {},
   "source": [
    "### 3.4 Check Statistical Parity Difference result\n",
    "The feature and its statistical parity difference value will be stored as a pair under FairnessMetricType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84514f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb77ecf",
   "metadata": {},
   "source": [
    "## 4. Smoothed Empirical Differential<a name=\"sed\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fcde75",
   "metadata": {},
   "source": [
    "**Smoothed Empirical Differential(SED)** is a fairness metric that can be used to describe the fairness for the model predictions. It is used to quantify the differential in the probability of favorable/unfavorable outcomes between intersecting groups divided by features. All intersecting groups are equal, there is no unprivileged or privileged groups. \n",
    "\n",
    "SED value is the minimum ratio of Dirichlet smoothed probability of favorable and unfavorable outcomes between different intersecting groups in the dataset. Its value is between 0 and 1, excluding 0 and 1. The bigger, the better.\n",
    "\n",
    "Take the German credit risk datasets as example, assume:\n",
    "\n",
    "+ the favorable outcomes of label column is \"No Risk\",\n",
    "+ the unfavorable outcomes of label column is \"Risk\".\n",
    "\n",
    "if user divide dataset by *feature \"Sex\"*ï¼Œthere will be two intersecting groups:\n",
    "+ intersecting group Sex=\"male\" \n",
    "+ intersecting group Sex=\"female\"\n",
    "\n",
    "and assume:\n",
    "\n",
    "+ the Dirichlet smoothed probability of favorable outcomes \"No Risk\" in intersecting group \"Sex\"=\"male\" is 0.2\n",
    "+ the Dirichlet smoothed probability of unfavorable outcomes \"Risk\" in intersecting group \"Sex\"=\"male\" is 0.8\n",
    "+ the Dirichlet smoothed probability of favorable outcomes \"No Risk\" in intersecting group \"Sex\"=\"female\" is 0.4\n",
    "+ the Dirichlet smoothed probability of unfavorable outcomes \"Risk\" in intersecting group \"Sex\"=\"female\" is 0.6\n",
    "\n",
    "then, calculate the label differential between intersecting groups (*Note that it always chooses the smaller one as the numerator or the bigger one as the denominator*): \n",
    "\n",
    "+ the favorable outcomes' differential between intersecting group \"Sex\"=\"male\" and \"Sex\"=\"female\" will be 0.2/0.4=0.5\n",
    "+ the unfavorable outcomes' differential between intersecting group \"Sex\"=\"male\" and \"Sex\"=\"female\" will be 0.6/0.8=0.75\n",
    "\n",
    "then, calculate the differential between intersecting groups:\n",
    "+ the differential between intersecting group \"Sex\"=\"male\" and \"Sex\"=\"female\" will be min(0.5, 0.75)=0.5\n",
    "\n",
    "Since there are only two intersecting groups, so,\n",
    "\n",
    "+ the final differentials of dataset will be 0.5.\n",
    "\n",
    "*References: James R. Foulds, Rashidul Islam, Kamrun Naher Keya, Shimei Pan, \"An Intersectional Definition of Fairness\", Department of Information Systems, University of Maryland, Baltimore County, USA*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0aa58b",
   "metadata": {},
   "source": [
    "### 4.1 Prepare input for Smoothed Empirical Differential \n",
    "update the schema and table for Smoothed Empirical Differential in spark job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCHEMA_NAME = \"***\"\n",
    "TRAIN_TABLE_NAME = \"***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be077612",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    {\n",
    "        \"database\": JDBC_DATABASE_NAME,\n",
    "        \"schema\": TRAIN_SCHEMA_NAME,\n",
    "        \"table\": TRAIN_TABLE_NAME,\n",
    "        \"type\": \"training\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69befbdb",
   "metadata": {},
   "source": [
    "### 4.2 Smoothed Empirical Differential Configurations \n",
    "\n",
    "Configure label and problem type in the overall section.\n",
    "- **problem_type(str)**: `binary` and `multi-classification` is supported.\n",
    "- **label_column(str)**: Column name of label in the data frame.\n",
    "\n",
    "Inside `fairness` as below, there are three sections which is required to configure.\n",
    "- **metrics_configuration(dict)**: Configure *Smoothed Empirical Differential* as one of the metrics with name `FairnessMetricType.SED.value`, and it requires a `features` property to describes which features the metric will be computed upon. *Smoothed Empirical Differential* is supported to run with individual features (eg. `[[\"a\"],[\"b\"]]`) and with intersectional features (eg. `[[\"a\", \"b\"]]`).\n",
    "\n",
    "- **protected_attributes(list)**: Describe protected features upon which this metric will be computed. Configure each feature with such information:\n",
    "  - feature(str): Name of the feature, which should be same as configured in `features` of `metrics_configuration` section.\n",
    "\n",
    "- **favourable_label(list)**: A list of favourable labels or outcomes of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c4a8c",
   "metadata": {},
   "source": [
    "Update the Smoothed Empirical Differential configurations, which will be configured into spark job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29fec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sed_config = {\n",
    "            \"problem_type\":\"binary\",\n",
    "            \"label_column\" : \"***\",\n",
    "            \"fairness\": {\n",
    "                            \"metrics_configuration\": {\n",
    "                                FairnessMetricType.SED.value: {\n",
    "                                    \"features\": [ [\"***\"] ]                                \n",
    "                                }\n",
    "                            },\n",
    "                            \"protected_attributes\": [\n",
    "                                {\n",
    "                                    \"feature\": \"***\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"favourable_label\": [\"***\"]\n",
    "                        }\n",
    "        }\n",
    "\n",
    "sed_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69018db",
   "metadata": {},
   "source": [
    "### 4.3 Compuate Smoothed Empirical Differential \n",
    "IAE credentials and spark job parameters will be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4084941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = {\n",
    "            \"spark_settings\": spark_parameters,\n",
    "            \"arguments\": {\n",
    "                \"monitoring_run_id\": \"my_monitoring_run_id\",\n",
    "                \"storage\": storage_details,\n",
    "                \"tables\": tables,\n",
    "                \"metric_configuration\": sed_config\n",
    "            }\n",
    "        }\n",
    "\n",
    "job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = client.ai_metrics.compute_metrics_as_job(credentials, job_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2264cc6a",
   "metadata": {},
   "source": [
    "### 4.4 Check Smoothed Empirical Differential result\n",
    "The features and smoothed empirical differential values will be stored as a pair under FairnessMetricType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7dfed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784ae0f",
   "metadata": {},
   "source": [
    "## 5. Fair Score Transformer <a name=\"fst\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f059d12",
   "metadata": {},
   "source": [
    "**Fair Score Transformer** can be used as post-processing technique that transforms probability estimates ( or scores) of `probabilistic binary classication` model with respect to fairness goals like statistical parity or equalized odds. To use **Fair Score Transformer** in OpenScale, you need first train a **Fair Score Transformer** and then use it to transform scores.\n",
    "\n",
    "*References: D. Wei, K. Ramamurthy, and F. Calmon, \"Optimized Score Transformation for Fair Classification\", International Conference on Artificial Intelligence and Statistics, 2020.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18652f2",
   "metadata": {},
   "source": [
    "### 5.1 Prepare input for Fair Score Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392b2b5",
   "metadata": {},
   "source": [
    "To train a Fair Score Transformer, below columns in the dataframe will be used:</br>\n",
    "***estimate column***: contains the estimate values calculated by the trained classification model.</br>\n",
    "***protected attribute column***: contains the corresponding protected attributes the trained classification model uses.</br>\n",
    "***label column (optional)***: contains the ground true values of the estimates column. it is not required to train the transformer but required to compute accuray with the trained transformer.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11446ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCHEMA_NAME = \"***\"\n",
    "TRAIN_TABLE_NAME = \"***\"\n",
    "\n",
    "ESTIMATE_COLUMN = \"***\"\n",
    "PROTECTED_ATTRIBUTE_COLUMN = \"***\"\n",
    "LABEL_COLUMN = \"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88390030",
   "metadata": {},
   "source": [
    "Update these informations to spark job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    {\n",
    "        \"database\": JDBC_DATABASE_NAME,\n",
    "        \"schema\": TRAIN_SCHEMA_NAME,\n",
    "        \"table\": TRAIN_TABLE_NAME,\n",
    "        \"type\": \"training\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac71ce7",
   "metadata": {},
   "source": [
    "### 5.2 Fair Score Transformer Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b1fc0",
   "metadata": {},
   "source": [
    "Setup configuration to fit **Fair Score Transformer**. Inside `metrics_configuration` as below, specify the name of the transformer with `FairnessMetricType.FST.value`. To configure it, you need to provide `params` and `features` information as below. This notebook will transform scores with respect to the **Statistical Parity Difference** fairness goal (set `criteria` as `MSP`).\n",
    "\n",
    "- **params**: Parameters of Fair Score Transformer\n",
    "  - epsilon (float): Bound on mean statistical parity or mean equalized odds.\n",
    "  - criteria (str): Optimize for mean statistical parity (\"MSP\") or mean equalized odds (\"MEO\").\n",
    "  - Aprobabilistic (bool): Indicator of whether actual protected attribute values (False) or probabilistic estimates (True) are provided. Default False.\n",
    "  - iterMax (float): Maximum number of ADMM iterations. Default 1e3.\n",
    "- **features**: Columns definition in the dataframe\n",
    "  - probabilities: Column name of probability estimates.\n",
    "  - protected: Column name of protected attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\"probabilities\": ESTIMATE_COLUMN, \"protected\": PROTECTED_ATTRIBUTE_COLUMN}\n",
    "fst_configuration = {\n",
    "    \"fairness\": {\n",
    "        \"metrics_configuration\": {\n",
    "            FairnessMetricType.FST.value: {\n",
    "                \"params\": {\n",
    "                    \"epsilon\": 0.01,\n",
    "                    \"criteria\": \"MSP\",\n",
    "                    \"Aprobabilistic\": False,\n",
    "                    \"iterMax\": 1e3\n",
    "                },\n",
    "                \"features\": columns\n",
    "            }\n",
    "        }     \n",
    "    }\n",
    "}\n",
    "\n",
    "fst_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d135af0",
   "metadata": {},
   "source": [
    "### 5.3 Fit Fair Score Transformer\n",
    "IAE credentials and spark job parameters will be used here. the timeout is in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbaf978",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = {\n",
    "            \"spark_settings\": spark_parameters,\n",
    "            \"arguments\": {\n",
    "                \"monitoring_run_id\": \"my_monitoring_run_id\",\n",
    "                \"storage\": storage_details,\n",
    "                \"tables\": tables,\n",
    "                \"metric_configuration\": fst_configuration\n",
    "            }\n",
    "        }\n",
    "\n",
    "job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c150cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fst = client.ai_metrics.fit_transformer_as_job(credentials, job_params, timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b01a000",
   "metadata": {},
   "source": [
    "### 5.4 Use the Trained Fair Score Transformer\n",
    "\n",
    "#### Compute transformed estimates with Fair Score Transformer\n",
    "Trained transformer can be used to compute new probability estimates and it requires the exactly same columns as fitting phase.</br> \n",
    "\n",
    "**Note:** No matter what column name is used for the existing probability estimates, the new probability estimates column will be named as **r_transformed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARK_DF = spark.createDataFrame(\"***\")\n",
    "# probs_df = fst.predict_proba(spark, SPARK_DF, columns, keep_cols=LABEL_COLUMN)\n",
    "# probs_df .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584f5d6",
   "metadata": {},
   "source": [
    "#### Compute new labels based on transformed estimates with Fair Score Transformer\n",
    "\n",
    "Trained transformer can also be used to compute new class labels based on transformed probability estimates, and it requires the exactly same columns as fitting phase. \n",
    "\n",
    "**Note:** No matter what column name is used for the `label` column, the new class labels column will be named as **r_transformed_thresh**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARK_DF = spark.createDataFrame(\"***\")\n",
    "# predict_df = fst.predict(spark, SPARK_DF, columns, keep_cols=LABEL_COLUMN)\n",
    "# predict_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79a4da",
   "metadata": {},
   "source": [
    "#### Save the trained Fair Score Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845378e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(fst, open(\"fst.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da63ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
