{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9022bf7",
   "metadata": {},
   "source": [
    "# Watson OpenScale Fairness Metrics and Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1fe6a",
   "metadata": {},
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "The notebook will compute Fairness Metrics **Statistical Parity Difference**, **Smoothed Empirical Differential**, on the model prediction and then show how **Fair Score Transformer** can be used to transform the model output for fair prediction. and then compute **Performance measures** to evalue the model performance, do **Multi-Dimensinal Subset Scan** search any potiencial biases,<br/>\n",
    "\n",
    "This document includes below sections, you will *`edit`* and *`restart`* notebook kernel in **Setup** section:\n",
    "\n",
    "- [1.Introduction](#introduction)\n",
    "- [2.Setup Envrionments](#setup)\n",
    "- [3.Statistical Parity Difference](#spd)\n",
    "- [4.Smoothed Empirical Differential](#sed)\n",
    "- [5.Fair Score Transformer](#fst)\n",
    "- [6.Performance measures](#measures)\n",
    "- [7.Multi-Dimensinal Subset Scan](#mdss)\n",
    "\n",
    "**Note:** This notebook should be run using with **Python 3.9.x** runtime. It requires service credentials for the following services:\n",
    "  * Watson OpenScale <br/>\n",
    "  * IBM Analytics Engine <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee20870",
   "metadata": {},
   "source": [
    "## 2. Setup Envrionments <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cd0e6",
   "metadata": {},
   "source": [
    "### 2.1 Package installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2734bc",
   "metadata": {},
   "source": [
    "*[Optional]* ignore warning messages to make output more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642752ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c200347",
   "metadata": {},
   "source": [
    "Install packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6fe610",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1\n",
    "!pip install --upgrade ibm-metrics-plugin --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57591666",
   "metadata": {},
   "source": [
    "**Action: Restrat the kernel\\!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b5c9f",
   "metadata": {},
   "source": [
    "### 2.2 Configure credentials for WASTON OpenScale \n",
    "Configure credentials for WASTON OpenScale into the authenticator, which will be used in OpenScale client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672cff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "\n",
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"<cluster-url>\",\n",
    "    \"username\": \"<username>\",\n",
    "    \"password\": \"<password>\",\n",
    "    \"instance_id\": \"<openscale instance id>\"\n",
    "}\n",
    "\n",
    "authenticator = CloudPakForDataAuthenticator(\n",
    "    url=WOS_CREDENTIALS[\"url\"],\n",
    "    username=WOS_CREDENTIALS[\"username\"],\n",
    "    password=WOS_CREDENTIALS[\"password\"],\n",
    "    disable_ssl_verification=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c378e63",
   "metadata": {},
   "source": [
    "### 2.3 Configure credentials for IBM Analytics Engine - Spark\n",
    "\n",
    "Make sure that the Apache Spark manager on IBM Analytics Engine is running, and then provide the following details:\n",
    "\n",
    "- IAE_SPARK_DISPLAY_NAME: _Display Name of the Spark instance in IBM Analytics Engine_\n",
    "- IAE_SPARK_JOBS_ENDPOINT: _Spark Jobs Endpoint for IBM Analytics Engine_\n",
    "- IBM_CPD_VOLUME: _IBM Cloud Pak for Data storage volume name_\n",
    "- IBM_CPD_USERNAME: _IBM Cloud Pak for Data username_\n",
    "- IBM_CPD_APIKEY: _IBM Cloud Pak for Data API key_\n",
    "- IAE_INSTANCE_ID: _IBM Analytics Engine spark instance id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eff1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "IAE_SPARK_DISPLAY_NAME = \"<spark-engine-name>\"\n",
    "IAE_SPARK_JOBS_ENDPOINT = \"<spark-job-endpoint-for-ibm-analytics-engine>\"\n",
    "IBM_CPD_VOLUME = \"<ibm-cpd-volume>\"\n",
    "IBM_CPD_USERNAME = \"<ibm-cloud-pak-for-data-username>\"\n",
    "IBM_CPD_APIKEY = \"<ibm-cloud-pak-for-data-apikey>\"\n",
    "IAE_INSTANCE_ID = \"<ibm-analytics-engine-spark-instance-id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e81fb6",
   "metadata": {},
   "source": [
    "The credential informations will be used to run spark job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {\n",
    "            \"connection\": {\n",
    "                \"endpoint\": IAE_SPARK_JOBS_ENDPOINT,\n",
    "                \"location_type\": \"cpd_iae\",\n",
    "                \"display_name\": IAE_SPARK_DISPLAY_NAME,\n",
    "                \"instance_id\": IAE_INSTANCE_ID,\n",
    "                \"volume\": IBM_CPD_VOLUME\n",
    "            },\n",
    "            \"credentials\": {\n",
    "                \"username\": IBM_CPD_USERNAME,\n",
    "                \"apikey\":IBM_CPD_APIKEY\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7696b",
   "metadata": {},
   "source": [
    "### 2.4 Configure resource setting for Spark job\n",
    "\n",
    "To configure how much of your Spark Cluster resources this job can consume, edit the following values:\n",
    "\n",
    "- max_num_executors: _Maximum Number of executors to launch for this session_\n",
    "- min_executors: _Minimum Number of executors to launch for this session_\n",
    "- executor_cores: _Number of cores to use for each executor_   \n",
    "- executor_memory: _Amount of memory (in GBs) to use per executor process_\n",
    "- driver_cores: _Number of cores to use for the driver process_\n",
    "- driver_memory: _Amount of memory (in GBs) to use for the driver process_\n",
    "\n",
    "These informations will be configured into spark job parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0286e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_parameters = {\n",
    "                \"max_num_executors\": 4,\n",
    "                \"min_executors\": 1,\n",
    "                \"executor_cores\": 1,\n",
    "                \"executor_memory\": 1,\n",
    "                \"driver_cores\": 1,\n",
    "                \"driver_memory\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65363d",
   "metadata": {},
   "source": [
    "### 2.5 Configure storage parameters for Spark job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7487df",
   "metadata": {},
   "source": [
    "In this notebook, DB2 is used as the storage source of input datasets. \n",
    "#### Storage Inputs\n",
    "\n",
    "Please enter a name and description for your JDBC Storage\n",
    "\n",
    "- JDBC_CONNECTION_NAME: _Custom display name for the JDBC Storage Connection_\n",
    "- JDBC_CONNECTION_DESCRIPTION: _Custom description for the JDBC Storage Connection_\n",
    "\n",
    "To connect to your JDBC storage, you must provide the following details:\n",
    "\n",
    " - JDBC_HOST: Hostname of the JDBC Connection\n",
    " - JDBC_PORT: Port of the JDBC Connection\n",
    " - JDBC_USE_SSL: Boolean Flag to indicate whether to use SSL while connecting.\n",
    " - JDBC_SSL_CERTIFICATE: SSL Certificate [Base64 encoded string] of the JDBC Connection. Ignored if JDBC_USE_SSL is False.\n",
    " - JDBC_DRIVER: Class name of the JDBC driver to use to connect.\n",
    " - JDBC_USERNAME: Username of the JDBC Connection\n",
    " - JDBC_PASSWORD: Password of the JDBC Connection\n",
    " - JDBC_DATABASE_NAME: Name of the Database to connect to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "JDBC_HOST = \"<Hostname of the JDBC Connection>\"\n",
    "JDBC_PORT = \"<Port of the JDBC Connection>\"\n",
    "JDBC_USE_SSL = \"<Boolean Flag to indicate whether to use SSL while connecting.>\"\n",
    "JDBC_SSL_CERTIFICATE = \"<SSL Certificate [Base64 encoded string] of the JDBC Connection. Ignored if JDBC_USE_SSL is False.>\"\n",
    "JDBC_DRIVER = \"<Class name of the JDBC driver to use to connect.>\"\n",
    "JDBC_USERNAME = \"<Username of the JDBC Connection>\"\n",
    "JDBC_PASSWORD = \"<Password of the JDBC Connection>\"\n",
    "JDBC_DATABASE_NAME = \"<Name of the Database to connect to.>\"\n",
    "\n",
    "jdbc_url = \"jdbc:db2://{}:{}/{}\".format(JDBC_HOST, JDBC_PORT, JDBC_DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e353e4c",
   "metadata": {},
   "source": [
    "These informations will be configrued into storage_details session of spark job parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_details = {\n",
    "    \"type\": \"jdbc\",\n",
    "    \"connection\": {\n",
    "        \"jdbc_driver\": JDBC_DRIVER,\n",
    "        \"jdbc_url\": jdbc_url,\n",
    "        \"use_ssl\": JDBC_USE_SSL,\n",
    "        \"certificate\": JDBC_SSL_CERTIFICATE,\n",
    "        \"location_type\": \"jdbc\"\n",
    "    },\n",
    "    \"credentials\":{\n",
    "        \"username\": JDBC_USERNAME,\n",
    "        \"password\": JDBC_PASSWORD,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452d7b5",
   "metadata": {},
   "source": [
    "#### Training table metadata\n",
    "\n",
    "Each quality monitor could use its own training table from the database, so the table metadata will be addressed respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc523e5",
   "metadata": {},
   "source": [
    "### 2.6 Setup OpenScale client \n",
    "Setup a Python OpenScale client with above setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_openscale import APIClient as OpenScaleAPIClient\n",
    "\n",
    "client = OpenScaleAPIClient(\n",
    "    service_url=WOS_CREDENTIALS['url'],\n",
    "    service_instance_id=WOS_CREDENTIALS[\"instance_id\"],\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77101c",
   "metadata": {},
   "source": [
    "## 3. Statistical Parity Difference <a name=\"spd\"></a>\n",
    "\n",
    "**Statistical Parity Difference** is a fairness metric that can be used to describe the fairness for the model predictions.\n",
    "It is the difference between the ratio of favourable outcomes in unprivileged and privileged groups. It can\n",
    "be computed from either the input dataset or the dataset output from a classifier (predicted dataset). A value\n",
    "of 0 implies both groups have equal benefit, a value less than 0 implies higher benefit for the privileged group, and a value greater than 0 implies higher benefit for the unprivileged group.<br>\n",
    "$$𝑃(𝑌=1|𝐷=unprivileged)−𝑃(𝑌=1|𝐷=privileged)$$\n",
    "\n",
    "Take the German credit risk datasets as example, if user set\n",
    "+ privileged group as Sex=\"male\" \n",
    "+ unprivileged group as Sex=\"female\"\n",
    "\n",
    "and set\n",
    "+ favourable label as Risk=\"No Risk\"\n",
    "+ unfavourable label as Risk=\"Risk\"\n",
    "\n",
    "then, the SPD result \n",
    "+ spd > 0 means the unpriviliage group Sex=\"female\" has higher rate to be marked as favourable label \"No Risk\" than priviliage group Sex=\"male\".\n",
    "+ spd = 0 means the unpriviliage group Sex=\"female\" has same rate to be marked as favourable label \"No Risk\" with priviliage group Sex=\"male\".\n",
    "+ spd < 0 means the unpriviliage group Sex=\"female\" has lower rate to be marked as favourable label \"No Risk\" than priviliage group Sex=\"male\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a184a",
   "metadata": {},
   "source": [
    "### 3.1 Prepare input for Statistical Parity Difference\n",
    "The quality monitor stores metadata in the training table.\n",
    "\n",
    "- TRAIN_SCHEMA_NAME: _Schema name where training table is present_\n",
    "- TRAIN_TABLE_NAME: _Name of the training table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCHEMA_NAME = \"***\"\n",
    "TRAIN_TABLE_NAME = \"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3eec4",
   "metadata": {},
   "source": [
    "These informations will be configured into tables session of spark job paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d741e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    {\n",
    "        \"database\": JDBC_DATABASE_NAME,\n",
    "        \"schema\": TRAIN_SCHEMA_NAME,\n",
    "        \"table\": TRAIN_TABLE_NAME,\n",
    "        \"type\": \"training\"\n",
    "    }\n",
    "]\n",
    "\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc2ba9",
   "metadata": {},
   "source": [
    "### 3.2  Statistical Parity Difference Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd78e03",
   "metadata": {},
   "source": [
    "Setup configuration to compute *Statistical Parity Difference*,<br/>\n",
    "\n",
    "Configure label and problem type in the overall section.\n",
    "- **problem_type(str)**: `binary` and `multi-classification` is supported.\n",
    "- **label_column(str)**: Column name of label in the data frame\n",
    "\n",
    "Inside `fairness` as below, there are three sections which is required to configure.\n",
    "- **metrics_configuration(dict)**: Configure *Statistical Parity Difference* as one of the metrics with name `FairnessMetricType.SPD.value`, and it requires a `features` property to describe which features the metric will be computed upon. *Statistical Parity Difference* is supported to run with individual features (eg. `[[\"a\"],[\"b\"]]`), but not suppored to run with intersectional features (eg. `[[\"a\", \"b\"]]`).\n",
    "\n",
    "- **protected_attributes(list)**: Describe privileged group defintion for features upon which this metric will be computed. Configure each feature with below information:\n",
    "  - feature(str): Name of the feature, which should be same as configured in `features` of `metrics_configuration` section.\n",
    "  - reference_group(list): List of feature values which make a sample privileged. \n",
    "\n",
    "- **favourable_label(list)**: A list of favourable labels or outcomes of the model.\n",
    "\n",
    "\n",
    "**Note** that `label_column` used here is the new added `pred` column.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b03375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_metrics_plugin.common.utils.constants import FairnessMetricType, MetricGroupType\n",
    "spd_config = {\n",
    "            \"problem_type\": \"***\",\n",
    "            \"label_column\" : \"***\",\n",
    "            \"fairness\": {\n",
    "                            \"metrics_configuration\": {\n",
    "                                FairnessMetricType.SPD.value: {\n",
    "                                    \"features\": [ [\"***\"] ]                                \n",
    "                                }\n",
    "                            },\n",
    "                            \"protected_attributes\": [\n",
    "                                {\n",
    "                                    \"feature\": \"***\",\n",
    "                                    \"reference_group\": [\"***\"]\n",
    "                                }\n",
    "                            ],\n",
    "                            \"favourable_label\": [\"***\"]\n",
    "                        }\n",
    "        }\n",
    "\n",
    "spd_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aa441a",
   "metadata": {},
   "source": [
    "### 3.3 Compute Statistical Parity Difference\n",
    "IAE credentials and spark job parameters will be used here. the timeout is in seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5cd5b7",
   "metadata": {},
   "source": [
    "update all configurations into the spark job parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf33191",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = {\n",
    "            \"spark_settings\": spark_parameters,\n",
    "            \"arguments\": {\n",
    "                \"monitoring_run_id\": \"my_monitoring_run_id\",\n",
    "                \"storage\": storage_details,\n",
    "                \"tables\": tables,\n",
    "                \"metric_configuration\": spd_config\n",
    "            }\n",
    "        }\n",
    "\n",
    "job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681cf940",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.ai_metrics.compute_metrics_as_job(credentials, job_params, timeout=600)\n",
    "metrics = client.ai_metrics.get_job_output(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86167b2",
   "metadata": {},
   "source": [
    "### 3.4 Check Statistical Parity Difference result\n",
    "The feature and its statistical parity difference value will be stored as a pair under FairnessMetricType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84514f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb77ecf",
   "metadata": {},
   "source": [
    "## 4. Smoothed Empirical Differential<a name=\"sed\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fcde75",
   "metadata": {},
   "source": [
    "**Smoothed Empirical Differential(SED)** is a fairness metric that can be used to describe the fairness for the model predictions. It is used to quantify the differential in the probability of favorable/unfavorable outcomes between intersecting groups divided by features. All intersecting groups are equal, there is no unprivileged or privileged groups. \n",
    "\n",
    "SED value is the minimum ratio of Dirichlet smoothed probability of favorable and unfavorable outcomes between different intersecting groups in the dataset. Its value is between 0 and 1, excluding 0 and 1. The bigger, the better.\n",
    "\n",
    "Take the German credit risk datasets as example, assume:\n",
    "\n",
    "+ the favorable outcomes of label column is \"No Risk\",\n",
    "+ the unfavorable outcomes of label column is \"Risk\".\n",
    "\n",
    "if user divide dataset by *feature \"Sex\"*，there will be two intersecting groups:\n",
    "+ intersecting group Sex=\"male\" \n",
    "+ intersecting group Sex=\"female\"\n",
    "\n",
    "and assume:\n",
    "\n",
    "+ the Dirichlet smoothed probability of favorable outcomes \"No Risk\" in intersecting group \"Sex\"=\"male\" is 0.2\n",
    "+ the Dirichlet smoothed probability of unfavorable outcomes \"Risk\" in intersecting group \"Sex\"=\"male\" is 0.8\n",
    "+ the Dirichlet smoothed probability of favorable outcomes \"No Risk\" in intersecting group \"Sex\"=\"female\" is 0.4\n",
    "+ the Dirichlet smoothed probability of unfavorable outcomes \"Risk\" in intersecting group \"Sex\"=\"female\" is 0.6\n",
    "\n",
    "then, calculate the label differential between intersecting groups (*Note that it always chooses the smaller one as the numerator or the bigger one as the denominator*): \n",
    "\n",
    "+ the favorable outcomes' differential between intersecting group \"Sex\"=\"male\" and \"Sex\"=\"female\" will be 0.2/0.4=0.5\n",
    "+ the unfavorable outcomes' differential between intersecting group \"Sex\"=\"male\" and \"Sex\"=\"female\" will be 0.6/0.8=0.75\n",
    "\n",
    "then, calculate the differential between intersecting groups:\n",
    "+ the differential between intersecting group \"Sex\"=\"male\" and \"Sex\"=\"female\" will be min(0.5, 0.75)=0.5\n",
    "\n",
    "Since there are only two intersecting groups, so,\n",
    "\n",
    "+ the final differentials of dataset will be 0.5.\n",
    "\n",
    "*References: James R. Foulds, Rashidul Islam, Kamrun Naher Keya, Shimei Pan, \"An Intersectional Definition of Fairness\", Department of Information Systems, University of Maryland, Baltimore County, USA*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0aa58b",
   "metadata": {},
   "source": [
    "### 4.1 Prepare input for Smoothed Empirical Differential \n",
    "update the schema and table for Smoothed Empirical Differential in spark job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCHEMA_NAME = \"***\"\n",
    "TRAIN_TABLE_NAME = \"***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be077612",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    {\n",
    "        \"database\": JDBC_DATABASE_NAME,\n",
    "        \"schema\": TRAIN_SCHEMA_NAME,\n",
    "        \"table\": TRAIN_TABLE_NAME,\n",
    "        \"type\": \"training\"\n",
    "    }\n",
    "]\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69befbdb",
   "metadata": {},
   "source": [
    "### 4.2 Smoothed Empirical Differential Configurations \n",
    "\n",
    "Configure label and problem type in the overall section.\n",
    "- **problem_type(str)**: `binary` and `multi-classification` is supported.\n",
    "- **label_column(str)**: Column name of label in the data frame.\n",
    "\n",
    "Inside `fairness` as below, there are three sections which is required to configure.\n",
    "- **metrics_configuration(dict)**: Configure *Smoothed Empirical Differential* as one of the metrics with name `FairnessMetricType.SED.value`, and it requires a `features` property to describes which features the metric will be computed upon. *Smoothed Empirical Differential* is supported to run with individual features (eg. `[[\"a\"],[\"b\"]]`) and with intersectional features (eg. `[[\"a\", \"b\"]]`).\n",
    "\n",
    "- **protected_attributes(list)**: Describe protected features upon which this metric will be computed. Configure each feature with such information:\n",
    "  - feature(str): Name of the feature, which should be same as configured in `features` of `metrics_configuration` section.\n",
    "\n",
    "- **favourable_label(list)**: A list of favourable labels or outcomes of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c4a8c",
   "metadata": {},
   "source": [
    "Update the Smoothed Empirical Differential configurations, which will be configured into spark job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29fec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sed_config = {\n",
    "            \"problem_type\":\"binary\",\n",
    "            \"label_column\" : \"***\",\n",
    "            \"fairness\": {\n",
    "                            \"metrics_configuration\": {\n",
    "                                FairnessMetricType.SED.value: {\n",
    "                                    \"features\": [ [\"***\"] ]                                \n",
    "                                }\n",
    "                            },\n",
    "                            \"protected_attributes\": [\n",
    "                                {\n",
    "                                    \"feature\": \"***\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"favourable_label\": [\"***\"]\n",
    "                        }\n",
    "        }\n",
    "\n",
    "sed_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69018db",
   "metadata": {},
   "source": [
    "### 4.3 Compuate Smoothed Empirical Differential \n",
    "update all configurations into the spark job parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4084941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = {\n",
    "            \"spark_settings\": spark_parameters,\n",
    "            \"arguments\": {\n",
    "                \"monitoring_run_id\": \"my_monitoring_run_id\",\n",
    "                \"storage\": storage_details,\n",
    "                \"tables\": tables,\n",
    "                \"metric_configuration\": sed_config\n",
    "            }\n",
    "        }\n",
    "\n",
    "job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.ai_metrics.compute_metrics_as_job(credentials, job_params, timeout=600)\n",
    "metrics = client.ai_metrics.get_job_output(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2264cc6a",
   "metadata": {},
   "source": [
    "### 4.4 Check Smoothed Empirical Differential result\n",
    "The features and smoothed empirical differential values will be stored as a pair under FairnessMetricType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7dfed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784ae0f",
   "metadata": {},
   "source": [
    "## 5. Fair Score Transformer <a name=\"fst\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f059d12",
   "metadata": {},
   "source": [
    "**Fair Score Transformer** can be used as post-processing technique that transforms probability estimates ( or scores) of `probabilistic binary classication` model with respect to fairness goals like statistical parity or equalized odds. To use **Fair Score Transformer** in OpenScale, you need first train a **Fair Score Transformer** and then use it to transform scores.\n",
    "\n",
    "*References: D. Wei, K. Ramamurthy, and F. Calmon, \"Optimized Score Transformation for Fair Classification\", International Conference on Artificial Intelligence and Statistics, 2020.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18652f2",
   "metadata": {},
   "source": [
    "### 5.1 Prepare input for Fair Score Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392b2b5",
   "metadata": {},
   "source": [
    "To train a Fair Score Transformer, below columns in the dataframe will be used:</br>\n",
    "***estimate column***: contains the estimate values calculated by the trained classification model.</br>\n",
    "***protected attribute column***: contains the corresponding protected attributes the trained classification model uses.</br>\n",
    "***label column (optional)***: contains the ground true values of the estimates column. it is not required to train the transformer but required to compute accuray with the trained transformer.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfbdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCHEMA_NAME = \"***\"\n",
    "TRAIN_TABLE_NAME = \"***\"\n",
    "\n",
    "ESTIMATE_COLUMN = \"***\"\n",
    "PROTECTED_ATTRIBUTE_COLUMN = \"***\"\n",
    "LABEL_COLUMN = \"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88390030",
   "metadata": {},
   "source": [
    "Update these informations to spark job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    {\n",
    "        \"database\": JDBC_DATABASE_NAME,\n",
    "        \"schema\": TRAIN_SCHEMA_NAME,\n",
    "        \"table\": TRAIN_TABLE_NAME,\n",
    "        \"type\": \"training\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac71ce7",
   "metadata": {},
   "source": [
    "### 5.2 Fair Score Transformer Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b1fc0",
   "metadata": {},
   "source": [
    "Setup configuration to fit **Fair Score Transformer**. Inside `metrics_configuration` as below, specify the name of the transformer with `FairnessMetricType.FST.value`. To configure it, you need to provide `params` and `features` information as below. This notebook will transform scores with respect to the **Statistical Parity Difference** fairness goal (set `criteria` as `MSP`).\n",
    "\n",
    "- **params**: Parameters of Fair Score Transformer\n",
    "  - epsilon (float): Bound on mean statistical parity or mean equalized odds.\n",
    "  - criteria (str): Optimize for mean statistical parity (\"MSP\") or mean equalized odds (\"MEO\").\n",
    "  - Aprobabilistic (bool): Indicator of whether actual protected attribute values (False) or probabilistic estimates (True) are provided. Default False.\n",
    "  - iterMax (float): Maximum number of ADMM iterations. Default 1e3.\n",
    "- **features**: Columns definition in the dataframe\n",
    "  - probabilities: Column name of probability estimates.\n",
    "  - protected: Column name of protected attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\"probabilities\": ESTIMATE_COLUMN, \"protected\": PROTECTED_ATTRIBUTE_COLUMN}\n",
    "fst_configuration = {\n",
    "    \"fairness\": {\n",
    "        \"metrics_configuration\": {\n",
    "            FairnessMetricType.FST.value: {\n",
    "                \"params\": {\n",
    "                    \"epsilon\": 0.01,\n",
    "                    \"criteria\": \"MSP\",\n",
    "                    \"Aprobabilistic\": False,\n",
    "                    \"iterMax\": 1e3\n",
    "                },\n",
    "                \"features\": columns\n",
    "            }\n",
    "        }     \n",
    "    }\n",
    "}\n",
    "\n",
    "fst_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d135af0",
   "metadata": {},
   "source": [
    "### 5.3 Fit Fair Score Transformer\n",
    "update all configurations into the spark job parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbaf978",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = {\n",
    "            \"spark_settings\": spark_parameters,\n",
    "            \"arguments\": {\n",
    "                \"monitoring_run_id\": \"my_monitoring_run_id\",\n",
    "                \"storage\": storage_details,\n",
    "                \"tables\": tables,\n",
    "                \"metric_configuration\": fst_configuration\n",
    "            }\n",
    "        }\n",
    "\n",
    "job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c150cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fst = client.ai_metrics.fit_transformer_as_job(credentials, job_params, timeout=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b01a000",
   "metadata": {},
   "source": [
    "### 5.4 Use the Trained Fair Score Transformer\n",
    "\n",
    "#### Compute transformed estimates with Fair Score Transformer\n",
    "Trained transformer can be used to compute new probability estimates and it requires the exactly same columns as fitting phase.</br> \n",
    "\n",
    "**Note:** No matter what column name is used for the existing probability estimates, the new probability estimates column will be named as **r_transformed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARK_DF = spark.createDataFrame(\"***\")\n",
    "# probs_df = fst.predict_proba(spark, SPARK_DF, columns, keep_cols=LABEL_COLUMN)\n",
    "# probs_df .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584f5d6",
   "metadata": {},
   "source": [
    "#### Compute new labels based on transformed estimates with Fair Score Transformer\n",
    "\n",
    "Trained transformer can also be used to compute new class labels based on transformed probability estimates, and it requires the exactly same columns as fitting phase. \n",
    "\n",
    "**Note:** No matter what column name is used for the `label` column, the new class labels column will be named as **r_transformed_thresh**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARK_DF = spark.createDataFrame(\"***\")\n",
    "# predict_df = fst.predict(spark, SPARK_DF, columns, keep_cols=LABEL_COLUMN)\n",
    "# predict_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79a4da",
   "metadata": {},
   "source": [
    "#### Save the trained Fair Score Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f450f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(fst, open(\"fst.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd88b8",
   "metadata": {},
   "source": [
    "## 6. Performance measures <a name=\"measures\"></a>\n",
    "\n",
    "\n",
    "#### Confusion matrix\n",
    "\n",
    "*Confusion matrix* is used to measure the performance of the classification model. It has a table of 4 different combinations. \n",
    "\n",
    "|  | Confusion Matrix |  |\n",
    "| :-: | :-: | :-: |\n",
    "| Actual\\Predicted | Negative | Positive |\n",
    "| Negative | TN | FP |\n",
    "| Positive | FN | TP |\n",
    "\n",
    "There are two things to noticed in the above image: \n",
    "\n",
    "    Predicted values: Values that are predicted by the model. \n",
    "    Actual Value: Values that are actually in a datasets.\n",
    "    \n",
    "Taking binary classification for understanding the model. Positive points belong to a positive class and Negative points to negative class. So it can be understood by these 4 points.\n",
    "\n",
    "    True Positive(TP): Values that are actually positive and predicted positive.\n",
    "    False Positive(FP): Values that are actually negative but predicted to positive.\n",
    "    False Negative(FN): Values that are actually positive but predicted to negative.\n",
    "    True Negative (TN): Values that are actually negative and predicted to negative.\n",
    "  \n",
    "\n",
    "#### Performance mesures\n",
    "\n",
    "Rate is a measure factor in a confusion matrix. It has 4 basic types:\n",
    "\n",
    "    True Positive Rate(TPR): True Positive/All Positive. The bigger, the better.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?TPR&space;=&space;\\frac{TP}{P}) \n",
    "\n",
    "    False Positive Rate(FPR): False Positive/All Negative. The smaller, the better.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FPR&space;=&space;\\frac{FP}{N}) \n",
    "\n",
    "    False Negative Rate(FNR): False Negative/All Positive. The smaller, the better.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FNR&space;=&space;\\frac{FN}{P})\n",
    "\n",
    "    True Negative Rate(TNR): True Negative/All Negative. The bigger, the better.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?TNR&space;=&space;\\frac{TN}{N}) \n",
    "\n",
    "and 3 variant types:\n",
    "\n",
    "    False Discovery Rate(FDR): False Positive/(True Positive+False Positive). The smaller, the better.\n",
    "![title](https://latex.codecogs.com/svg.image?FDR&space;=&space;\\frac{FP}{TP&plus;FP})\n",
    "\n",
    "    False Omission Rate(FOR): False Negative/(True Negative+False Negative). The smaller, the better.\n",
    "![title](https://latex.codecogs.com/svg.image?FOR&space;=&space;\\frac{FN}{TN&plus;FN})\n",
    "\n",
    "    Error Rate(ER): (False Positive+False Negative)/(All Positive + All Negative). The smaller, the better.\n",
    "![title](https://latex.codecogs.com/svg.image?ER&space;=&space;\\frac{FP&plus;FN}{P&plus;N}) \n",
    "\n",
    "\n",
    "#### Performance mesure metrics\n",
    "\n",
    "Base on performance measues, there are 12 metrics to measure the model fairness:\n",
    "\n",
    "**false_positive_rate_difference**: Returns the difference in FPR for the unprivileged and privileged groups. \n",
    "![title](https://latex.codecogs.com/svg.image?FPR_{D=unprivileged}-FPR_{D=privileged})\n",
    "\n",
    "since the samller the FPR, the better the performance, so: \n",
    " \n",
    "    A value greater than 0 indicates the privileged group has advantage in performance. \n",
    "    A value lower than 0 indicates the unprivileged group has advantage in performance. \n",
    "    A value of 0 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 0 the better.\n",
    "\n",
    "**false_positive_rate_ratio**: Returns the ratio of FPR for the unprivileged and privileged groups. \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{FPR_{D=unprivileged}}{FPR_{D=privileged}})\n",
    "\n",
    "since the samller the FPR, the better the performance, so: \n",
    " \n",
    "    A value greater than 1 indicates the privileged group has advantage in performance. \n",
    "    A value lower than 1 indicates the unprivileged group has advantage in performance. \n",
    "    A value of 1 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 1 the better.\n",
    "\n",
    "**false_negative_rate_difference**: Returns the difference in FNR for the unprivileged and privileged groups. \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FDR_{D=unprivileged}-FDR_{D=privileged})\n",
    "\n",
    "since the samller the FNR, the better the performance, so: \n",
    " \n",
    "    A value greater than 0 indicates the privileged group has advantage in performance. \n",
    "    A value lower than 0 indicates the unprivileged group has advantage in performance. \n",
    "    A value of 0 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 0 the better.\n",
    "\n",
    "**false_negative_rate_ratio**: Returns the ratio of FNR for the unprivileged and privileged groups. \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{FNR_{D=unprivileged}}{FNR_{D=privileged}})\n",
    "\n",
    "since the samller the FNR, the better the performance, so: \n",
    " \n",
    "    A value greater than 1 indicates the privileged group has advantage in performance. \n",
    "    A value lower than 1 indicates the unprivileged group has advantage in performance. \n",
    "    A value of 1 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 1 the better.\n",
    "\n",
    "**false_discovery_rate_difference**: Returns the difference in FDR for the unprivileged and privileged groups. \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FDR_{D=unprivileged}-FDR_{D=privileged})\n",
    "\n",
    "since the samller the FDR, the better the performance, so: \n",
    " \n",
    "    A value greater than 0 indicates the privileged group has advantage in performance. \n",
    "    A value lower than 0 indicates the unprivileged group has advantage in performance. \n",
    "    A value of 0 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 0 the better.\n",
    "\n",
    "**false_discovery_rate_ratio**: Returns the ratio of FDR for the unprivileged and privileged groups. \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{FDR_{D=unprivileged}}{FDR_{D=privileged}})\n",
    "\n",
    "since the samller the FDR, the better the performance, so: \n",
    " \n",
    "    A value greater than 1 indicates the privileged group has advantage in performance. \n",
    "    A value lower than 1 indicates the unprivileged group has advantage in performance. \n",
    "    A value of 1 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 1 the better.\n",
    "\n",
    "**false_omission_rate_difference**: Returns the difference in FOR for the unprivileged and privileged groups. \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FOR_{D=unprivileged}-FOR_{D=privileged})\n",
    "\n",
    "since the samller the FOR, the better the performance, so: \n",
    " \n",
    "    A value greater than 0 indicates the privileged group has advantage in performance. \n",
    "    A value lower than 0 indicates the unprivileged group has advantage in performance. \n",
    "    A value of 0 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 0 the better.\n",
    "\n",
    "**false_omission_rate_ratio**: Returns the ratio of FOR for the unprivileged and privileged groups. \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{FOR_{D=unprivileged}}{FOR_{D=privileged}})\n",
    "\n",
    "since the samller the FOR, the better the performance, so: \n",
    " \n",
    "    A value greater than 1 indicates the privileged group has advantage in performance. \n",
    "    A value lower than 1 indicates the unprivileged group has advantage in performance. \n",
    "    A value of 1 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 1 the better.\n",
    "\n",
    "**error_rate_difference**: Returns the difference in ER for the unprivileged and privileged groups. \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?ER_{D=unprivileged}-ER_{D=privileged})\n",
    "\n",
    "since the samller the ER, the better the performance, so: \n",
    " \n",
    "    A value greater than 0 indicates the privileged group has advantage in performance. \n",
    "    A value lower than 0 indicates the unprivileged group has advantage in performance. \n",
    "    A value of 0 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 0 the better.\n",
    "\n",
    "**error_rate_ratio**: Returns the ratio of ER for the unprivileged and privileged groups. \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{ER_{D=unprivileged}}{ER_{D=privileged}}) \n",
    "\n",
    "since the samller the ER, the better the performance, so: \n",
    " \n",
    "    A value greater than 1 indicates the privileged group has advantage in performance. \n",
    "    A value lower than 1 indicates the unprivileged group has advantage in performance. \n",
    "    A value of 1 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 1 the better.\n",
    "\n",
    "**average_odds_difference**: Returns the average of the difference in FPR and TPR for the unprivileged and privileged groups.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{FPR_{D=unprivileged}-FPR_{D=privileged}&plus;TPR_{D=unprivileged}-TPR_{D=privileged}}{2})\n",
    "\n",
    "since the samller the FPR, the better the performance, but the bigger the TPR, the better the performane, so: \n",
    " \n",
    "    A value not equal to 0 indicates the unprivileged group and the privileged group have different performances.\n",
    "    A value of 0 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 0 the better.\n",
    "\n",
    "**average_abs_odds_difference**: Returns the average of the absolute difference in FPR and TPR for the unprivileged and privileged groups.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{|FPR_{D=unprivileged}-FPR_{D=privileged}|&plus;|TPR_{D=unprivileged}-TPR_{D=privileged}|}{2})\n",
    "\n",
    "since absolute value is used, it could not be a negative number, so: \n",
    " \n",
    "    A value greater than 0 indicates the unprivileged group and the privileged group have different performances.\n",
    "    A value of 0 indicates the unprivileged group and the privileged group have same performance. no bias. \n",
    "    The closer to 0 the better.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750fb9a",
   "metadata": {},
   "source": [
    "### Configure Performance Measures\n",
    "\n",
    "To setup configurations to compute Performance Measures, the Top level parameters:\n",
    "\n",
    "- problem_type(enum): problem type. Possible values are \"binary\", \"multiclass\", \"regression\".\n",
    "- label_column: the column where OpenScale to get the label value.\n",
    "- fairness(dict(dict)): parameters for computing fairness metrics.\n",
    "\n",
    "Parameters in fairness body:\n",
    "- metrics_configuration(dict(dict)): metrics configuration. Format is a dict where the keys are FairnessMetricType and the values is a dict that includes metircs to calculated.\n",
    "- protected_attributes: column list that will be kept and protected when processing data. \n",
    "- favourable_label: the positive outcomes in OpenScale, which could be find in label_column and predict_column.\n",
    "- unfavourable_label: the negative outcomes in OpenScale, which could be find in label_column and predict_column.\n",
    "\n",
    "Metric parameters in metrics_configuration:\n",
    "- features(list): the column based on which to find out the unprivileged/privileged groups. it must be one at a time, or calculation will fail.\n",
    "- predict_column: the column where OpenScale get the model prediction output.\n",
    "\n",
    "\n",
    "Attributes prameters in protected_attributes:\n",
    "- feature: feature column that need to be protect.\n",
    "- reference_group: privileged groups at the systematic advantage, which could be find in feature column.\n",
    "- monitored_group: unprivileged groups at the systematic advantage, which could be find in feature column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f1d10",
   "metadata": {},
   "source": [
    "### 6.1 Prepare input to compute Performance Measures\n",
    "The quality monitor stores metadata in the training table.\n",
    "\n",
    "- TRAIN_SCHEMA_NAME: _Schema name where training table is present_\n",
    "- TRAIN_TABLE_NAME: _Name of the training table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8983625",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCHEMA_NAME = \"******\"\n",
    "TRAIN_TABLE_NAME = \"******\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f350261",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    {\n",
    "        \"database\": JDBC_DATABASE_NAME,\n",
    "        \"schema\": TRAIN_SCHEMA_NAME,\n",
    "        \"table\": TRAIN_TABLE_NAME,\n",
    "        \"type\": \"training\"\n",
    "    }\n",
    "]\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835d74bc",
   "metadata": {},
   "source": [
    "### 6.2 Configure metrics of Performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_metrics_plugin.common.utils.constants import FairnessMetricType, MetricGroupType\n",
    "\n",
    "measure_config = {\n",
    "            \"problem_type\": \"binary\",\n",
    "            \"label_column\": \"***\",\n",
    "            \"fairness\": {\n",
    "                \"metrics_configuration\": {\n",
    "                    FairnessMetricType.MEASURES.value: {\n",
    "                        \"average_odds_difference\": {\n",
    "                            \"features\": [[\"***\"], [\"***\"]],\n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"average_abs_odds_difference\": {\n",
    "                            \"features\": [[\"***\"], [\"***\"]],\n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"false_negative_rate_difference\": {\n",
    "                            \"features\": [[\"***\"], [\"***\"]],\n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"false_negative_rate_ratio\": {\n",
    "                            \"features\": [[\"***\"], [\"***\"]],\n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"false_positive_rate_difference\": {\n",
    "                            \"features\": [[\"***\"]],  \n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"false_positive_rate_ratio\": {\n",
    "                            \"features\": [[\"***\"], [\"***\"]],\n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"false_discovery_rate_ratio\": {\n",
    "                            \"features\": [[\"***\"], [\"***\"]],\n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"false_discovery_rate_difference\": {\n",
    "                            \"features\": [[\"***\"]],  \n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"false_omission_rate_difference\": {\n",
    "                            \"features\": [[\"***\"], [\"***\"]],\n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"false_omission_rate_ratio\": {\n",
    "                            \"features\": [[\"***\"], [\"***\"]],\n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"error_rate_difference\": {\n",
    "                            \"features\": [[\"***\"], [\"***\"]],\n",
    "                            \"predict_column\": \"***\"\n",
    "                        },\n",
    "                        \"error_rate_ratio\": {\n",
    "                            \"features\": [[\"***\"], [\"***\"]],\n",
    "                            \"predict_column\": \"***\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"protected_attributes\": [\n",
    "                    {\n",
    "                        \"feature\": \"***\",\n",
    "                        \"reference_group\": [\"***\"],\n",
    "                        \"monitored_group\": [\"***\"]\n",
    "                    },\n",
    "                    {\n",
    "                        \"feature\": \"***\",\n",
    "                        \"reference_group\": ***,\n",
    "                        \"monitored_group\": ***\n",
    "                    }\n",
    "                ],\n",
    "                \"favourable_label\": [\"***\"],\n",
    "                \"unfavourable_label\": [\"***\"]\n",
    "            }\n",
    "}\n",
    "\n",
    "measure_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43359818",
   "metadata": {},
   "source": [
    "### 6.3 Compute perforamnce measures\n",
    "update all configurations into the spark job parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = {\n",
    "            \"spark_settings\": spark_parameters,\n",
    "            \"arguments\": {\n",
    "                \"monitoring_run_id\": \"my_monitoring_run_id\",\n",
    "                \"storage\": storage_details,\n",
    "                \"tables\": tables,\n",
    "                \"metric_configuration\": measure_config\n",
    "            }\n",
    "        }\n",
    "\n",
    "job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.ai_metrics.compute_metrics_as_job(credentials, job_params)\n",
    "metrics = client.ai_metrics.get_job_output(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97873f28",
   "metadata": {},
   "source": [
    "### 6.4 Check Performance Measures result\n",
    "The features and performance measures values will be stored as a pair under FairnessMetricType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1d298",
   "metadata": {},
   "source": [
    "## 7. Multi-Dimensinal Subset Scan <a name=\"mdss\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a35ac0",
   "metadata": {},
   "source": [
    "Multi-Dimensional Subset Scan defines a general bias scan method to detect and identify which subgroup(s) of features have statistically signicant predictive bias for a probabilistic binary classier.\n",
    "\n",
    "References: Zhang, Z., & Neill, D. B. (2016). Identifying significant predictive bias in classifiers. arXiv preprint arXiv:1611.08292."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5bb259",
   "metadata": {},
   "source": [
    "### 7.1 Prepare input for Multi-Dimensinal Subset Scan\n",
    "The quality monitor stores metadata in the training table.\n",
    "\n",
    "- TRAIN_SCHEMA_NAME: _Schema name where training table is present_\n",
    "- TRAIN_TABLE_NAME: _Name of the training table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCHEMA_NAME = \"***\"\n",
    "TRAIN_TABLE_NAME = \"***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    {\n",
    "        \"database\": JDBC_DATABASE_NAME,\n",
    "        \"schema\": TRAIN_SCHEMA_NAME,\n",
    "        \"table\": TRAIN_TABLE_NAME,\n",
    "        \"type\": \"training\"\n",
    "    }\n",
    "]\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dffab3",
   "metadata": {},
   "source": [
    "### 7.2  Multi-Dimensinal Subset Scan Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b374b91",
   "metadata": {},
   "source": [
    "Setup configuration to compute *Multi-Dimensinal Subset Scan*,<br/>\n",
    "\n",
    "#### Multi-Dimensinal Subset Scan parameters:\n",
    "\n",
    "Configure label in the overall section.\n",
    "- **label_column(str)**: Column name of label in the data frame\n",
    "\n",
    "Inside `fairness` as below, there are three sections which is required to configure.\n",
    "- **metrics_configuration(dict)**: Configure *Multi-Dimensinal Subset Scan* as one of the metrics with name `FairnessMetricType.MDSS.value`, and it requires five properties, all of them have default values.   \n",
    "`expectation_column` describe which column is the expectation column. By default use the mean label column of the entire population.      \n",
    "`penalty` describe penalty coefficient. By default is 1.   \n",
    "`num_iters` describe number of iteration. By default is 1.     \n",
    "`direction` describe the desired direction (positive or negative). By default is \"positive\".           \n",
    "`scoreFunction` describe which scoring function can be used to score subset of records. By default is \"Bernoulli\". For scoring function \"BerkJones\", it has to be binary classification where the expectations is constant across all data records.   \n",
    "`alpha` the alpha threshold that will be used to compute the score when scoreFunction is Bernoulli. By default is 0.2.   \n",
    "\n",
    "- **favourable_label(list)**: A list of favourable labels or outcomes of the model.\n",
    "\n",
    "These informations will be configured into metric_configuration session of spark job parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d57d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_metrics_plugin.common.utils.constants import FairnessMetricType, MetricGroupType\n",
    "\n",
    "mdss_config = {\n",
    "    \"label_column\": \"***\",\n",
    "    \"fairness\": {\n",
    "        \"metrics_configuration\": {\n",
    "            FairnessMetricType.MDSS.value: {\n",
    "                \"expectation_column\": \"SCORES\",\n",
    "                \"penalty\": 1,\n",
    "                \"num_iters\": 1,\n",
    "                \"direction\": \"negative\",\n",
    "                \"scoreFunction\": \"Bernoulli\",\n",
    "                \"alpha\": 0.4\n",
    "            }\n",
    "        },\n",
    "        \"favourable_label\": [1]\n",
    "    }\n",
    "}\n",
    "\n",
    "mdss_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b439b0c",
   "metadata": {},
   "source": [
    "### 7.3 Perform Multi-Dimensinal Subset Scan\n",
    "IAE credentials and spark job parameters will be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = {\n",
    "            \"spark_settings\": spark_parameters,\n",
    "            \"arguments\": {\n",
    "                \"monitoring_run_id\": \"my_monitoring_run_id\",\n",
    "                \"storage\": storage_details,\n",
    "                \"tables\": tables,\n",
    "                \"metric_configuration\": mdss_config\n",
    "            }\n",
    "        }\n",
    "\n",
    "job_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73967eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.ai_metrics.compute_metrics_as_job(credentials, job_params, timeout=600)\n",
    "metrics = client.ai_metrics.get_job_output(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc6ac7",
   "metadata": {},
   "source": [
    "### 7.4 Check Multi-Dimensinal Subset Scan result\n",
    "The subset and scores for Multi-Dimensinal Subset Scan will be stored as a pair under FairnessMetricType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c48397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
