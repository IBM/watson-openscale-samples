{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad1fe6a",
   "metadata": {},
   "source": [
    "# Watson OpenScale Fairness Metrics and Transformers - Equality Metrics\n",
    "\n",
    "\n",
    "The notebook will introduce the meaning of Fairness Metrics **Equality Metrics** and show to compute Fairness Metrics **Equality Metrics** based on the model prediction explain the meaning of then show how **Equality Metrics**  can be used to transform the model output for fair prediction.<br/>\n",
    "\n",
    "This document includes below sections:\n",
    "\n",
    "- [1.Introduction of Equality Metrics](#measures)\n",
    "- [2.Setup Envrionments](#setup) \n",
    "- [3.Prepare input data](#input)\n",
    "- [4.Configurations](#configuration)\n",
    "- [5.Compute Equality Metrics](#compute)\n",
    "\n",
    "**Note:** This notebook should be run using **Python 3.10.x** runtime. It requires service credentials for the following services:\n",
    "  * Watson OpenScale <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc8c04",
   "metadata": {},
   "source": [
    "## 1. Introduction of Equality Metrics <a name=\"measures\"></a>\n",
    "\n",
    "### Equality metrics:\n",
    "\n",
    "**Confusion matrix** is used to measure the performance of the classification model. It has a table of 4 different combinations. \n",
    "\n",
    "|  | Confusion Matrix |  |\n",
    "| :-: | :-: | :-: |\n",
    "| Actual\\Predicted | Negative | Positive |\n",
    "| Negative | TN | FP |\n",
    "| Positive | FN | TP |\n",
    "\n",
    "There are two things to noticed in the above image: \n",
    "\n",
    "    Predicted values: Values that are predicted by the model. \n",
    "    Actual Value: Values that are actually in a datasets.\n",
    "    \n",
    "Taking binary classification for understanding the model. Positive points belong to a positive class and Negative points to negative class. So it can be understood by these 4 points.\n",
    "\n",
    "    True Positive(TP): Values that are actually positive and predicted positive.\n",
    "    False Positive(FP): Values that are actually negative but predicted to positive.\n",
    "    False Negative(FN): Values that are actually positive but predicted to negative.\n",
    "    True Negative (TN): Values that are actually negative and predicted to negative.\n",
    "\n",
    "Rate is a measure factor in a confusion matrix. It has also 4 basic types:\n",
    "\n",
    "    True Positive Rate(TPR): True Positive/All Positive \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?TPR&space;=&space;\\frac{TP}{P}) \n",
    "\n",
    "    False Positive Rate(FPR): False Positive/All Negative \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FPR&space;=&space;\\frac{FP}{N}) \n",
    "\n",
    "    False Negative Rate(FNR): False Negative/All Positive \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FNR&space;=&space;\\frac{FN}{P})\n",
    "\n",
    "    True Negative Rate(TNR): True Negative/All Negative \n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?TNR&space;=&space;\\frac{TN}{N}) \n",
    "\n",
    "and 3 variant types:\n",
    "\n",
    "    False Discovery Rate(FDR): False Positive/(True Positive+False Positive)\n",
    "![title](https://latex.codecogs.com/svg.image?FDR&space;=&space;\\frac{FP}{TP&plus;FP})\n",
    "\n",
    "    False Omission Rate(FOR): False Negative/(True Negative+False Negative)\n",
    "![title](https://latex.codecogs.com/svg.image?FOR&space;=&space;\\frac{FN}{TN&plus;FN})\n",
    "\n",
    "    Error Rate(ER): (False Positive+False Negative)/(All Positive + All Negative)\n",
    "![title](https://latex.codecogs.com/svg.image?ER&space;=&space;\\frac{FP&plus;FN}{P&plus;N}) \n",
    " \n",
    "Base on Confusion matrix, there are 12 metrics to measure the model performance:\n",
    "\n",
    "**false_positive_rate_difference**: Returns the difference in FPR for the unprivileged and privileged groups. A value of 0 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FPR_{D=unprivileged}-FPR_{D=privileged})\n",
    "\n",
    "**false_positive_rate_ratio**: Returns the ratio of FPR for the unprivileged and privileged groups. A value of 1 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{FPR_{D=unprivileged}}{FPR_{D=privileged}})\n",
    "\n",
    "**false_negative_rate_difference**: Returns the difference in FNR for the unprivileged and privileged groups. A value of 0 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FDR_{D=unprivileged}-FDR_{D=privileged})\n",
    "\n",
    "**false_negative_rate_ratio**: Returns the ratio of FNR for the unprivileged and privileged groups. A value of 1 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{FNR_{D=unprivileged}}{FNR_{D=privileged}})\n",
    "\n",
    "**false_discovery_rate_difference**: Returns the difference in FDR for the unprivileged and privileged groups. A value of 0 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FDR_{D=unprivileged}-FDR_{D=privileged})\n",
    "\n",
    "**false_discovery_rate_ratio**: Returns the ratio of FDR for the unprivileged and privileged groups. A value of 1 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{FDR_{D=unprivileged}}{FDR_{D=privileged}})\n",
    "\n",
    "**false_omission_rate_difference**: Returns the difference in FOR for the unprivileged and privileged groups. A value of 0 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?FOR_{D=unprivileged}-FOR_{D=privileged})\n",
    "\n",
    "**false_omission_rate_ratio**: Returns the ratio of FOR for the unprivileged and privileged groups. A value of 1 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{FOR_{D=unprivileged}}{FOR_{D=privileged}})\n",
    "\n",
    "**error_rate_difference**: Returns the difference in ER for the unprivileged and privileged groups. A value of 0 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?ER_{D=unprivileged}-ER_{D=privileged})\n",
    "\n",
    "**error_rate_ratio**: Returns the ratio of ER for the unprivileged and privileged groups. A value of 1 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{ER_{D=unprivileged}}{ER_{D=privileged}}) \n",
    "\n",
    "**average_odds_difference**: Returns the average of the difference in FPR and TPR for the unprivileged and privileged groups. A value of 0 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{FPR_{D=unprivileged}-FPR_{D=privileged}&plus;TPR_{D=unprivileged}-TPR_{D=privileged}}{2})\n",
    "\n",
    "**average_abs_odds_difference**: Returns the average of the absolute difference in FPR and TPR for the unprivileged and privileged groups. A value of 0 indicates equality of odds.\n",
    "\n",
    "![title](https://latex.codecogs.com/svg.image?\\frac{|FPR_{D=unprivileged}-FPR_{D=privileged}|&plus;|TPR_{D=unprivileged}-TPR_{D=privileged}|}{2})\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee20870",
   "metadata": {},
   "source": [
    "## 2. Setup Envrionments <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cd0e6",
   "metadata": {},
   "source": [
    "### 2.1 Package installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2734bc",
   "metadata": {},
   "source": [
    "*[Optional]* ignore warning messages to make output more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642752ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6fe610",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1\n",
    "!pip install --upgrade ibm_metrics_plugin --no-cache | tail -n 1\n",
    "!pip install --upgrade pyspark==3.3.1 | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57591666",
   "metadata": {},
   "source": [
    "#### Action: restart the kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b5c9f",
   "metadata": {},
   "source": [
    "### 2.2 Configure credentials for WASTON OpenScale \n",
    "Configure credentials for WASTON OpenScale into the authenticator, which will be used in OpenScale client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c8d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "\n",
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"<CP4D_HOST>\",\n",
    "    \"username\": \"<USERNAME>\",\n",
    "    \"password\": \"<PASSWORD>\",\n",
    "    \"instance_id\": \"<SERVICE_INSTANCE_ID>\"\n",
    "}\n",
    "\n",
    "authenticator = CloudPakForDataAuthenticator(\n",
    "    url=WOS_CREDENTIALS[\"url\"],\n",
    "    username=WOS_CREDENTIALS[\"username\"],\n",
    "    password=WOS_CREDENTIALS[\"password\"],\n",
    "    disable_ssl_verification=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc523e5",
   "metadata": {},
   "source": [
    "### 2.3 Setup OpenScale client \n",
    "Setup a Python OpenScale client with above setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_openscale import APIClient as OpenScaleAPIClient\n",
    "\n",
    "client = OpenScaleAPIClient(\n",
    "    service_url=WOS_CREDENTIALS['url'],\n",
    "    service_instance_id=WOS_CREDENTIALS[\"instance_id\"],\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4356fdc9",
   "metadata": {},
   "source": [
    "## 3. Prepare input data <a name=\"input\"></a>\n",
    "\n",
    "### 3.1 Download and load the training data from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm german_credit_data_biased_training.csv\n",
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/Cloud%20Pak%20for%20Data/WML/assets/data/credit_risk/german_credit_data_biased_training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pandas_df = pd.read_csv(\"german_credit_data_biased_training.csv\", sep=\",\", header=0)\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb52ea",
   "metadata": {},
   "source": [
    "### 3.2 Fake model predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80226817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fake_predict_for_german_credit_dataset(row):\n",
    "    if row['Telephone'] == 'yes':\n",
    "        return 'No Risk'\n",
    "    else:\n",
    "        return 'Risk'\n",
    "    \n",
    "pandas_df[\"Predict\"] = pandas_df.apply(lambda row: _fake_predict_for_german_credit_dataset(row), axis=1)\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763596ff",
   "metadata": {},
   "source": [
    "### 3.3 Create Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.driver.bindAddress\", \"127.0.0.1\").getOrCreate()\n",
    "spark_df = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52995c2",
   "metadata": {},
   "source": [
    "## 4. Configurations <a name=\"configuration\"></a>\n",
    "\n",
    "### Configuration Parameters\n",
    "\n",
    "To setup configurations to compute Equality Metrics, the Top level parameters:\n",
    "\n",
    "- problem_type(enum): problem type. Possible values are \"binary\", \"multiclass\", \"regression\".\n",
    "- label_column: the column where OpenScale to get the label value.\n",
    "- fairness(dict(dict)): parameters for computing fairness metrics.\n",
    "\n",
    "Parameters in fairness body:\n",
    "- metrics_configuration(dict(dict)): metrics configuration. Format is a dict where the keys are FairnessMetricType and the values is a dict that includes metircs to calculated.\n",
    "- protected_attributes: column list that will be kept and protected when processing data. \n",
    "- favourable_label: the positive outcomes in OpenScale, which could be find in label_column and predict_column.\n",
    "- unfavourable_label: the negative outcomes in OpenScale, which could be find in label_column and predict_column.\n",
    "\n",
    "Metric parameters in metrics_configuration:\n",
    "- features(list): the column based on which to find out the unprivileged/privileged groups. it must be one at a time, or calculation will fail.\n",
    "- predict_column: the column where OpenScale get the model prediction output.\n",
    "\n",
    "\n",
    "Attributes prameters in protected_attributes:\n",
    "- feature: feature column that need to be protect.\n",
    "- reference_group: privileged groups at the systematic advantage, which could be find in feature column.\n",
    "- monitored_group: unprivileged groups at the systematic advantage, which could be find in feature column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae91f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_metrics_plugin.common.utils.constants import FairnessMetricType\n",
    "\n",
    "measure_configuration = {\"configuration\": {\n",
    "            \"problem_type\": \"binary\",\n",
    "            \"label_column\": \"Risk\",\n",
    "            \"fairness\": {\n",
    "                \"metrics_configuration\": {\n",
    "                    FairnessMetricType.MEASURES.value: {\n",
    "                        \"average_odds_difference\": {\n",
    "                            \"features\": [[\"Sex\"], [\"Age\"]],\n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"average_abs_odds_difference\": {\n",
    "                            \"features\": [[\"Sex\"], [\"Age\"]],\n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"false_negative_rate_difference\": {\n",
    "                            \"features\": [[\"Sex\"], [\"Age\"]],\n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"false_negative_rate_ratio\": {\n",
    "                            \"features\": [[\"Sex\"], [\"Age\"]],\n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"false_positive_rate_difference\": {\n",
    "                            \"features\": [[\"Age\"]],  \n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"false_positive_rate_ratio\": {\n",
    "                            \"features\": [[\"Sex\"], [\"Age\"]],\n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"false_discovery_rate_ratio\": {\n",
    "                            \"features\": [[\"Sex\"], [\"Age\"]],\n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"false_discovery_rate_difference\": {\n",
    "                            \"features\": [[\"Sex\"]],  \n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"false_omission_rate_difference\": {\n",
    "                            \"features\": [[\"Sex\"], [\"Age\"]],\n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"false_omission_rate_ratio\": {\n",
    "                            \"features\": [[\"Sex\"], [\"Age\"]],\n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"error_rate_difference\": {\n",
    "                            \"features\": [[\"Sex\"], [\"Age\"]],\n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        },\n",
    "                        \"error_rate_ratio\": {\n",
    "                            \"features\": [[\"Sex\"], [\"Age\"]],\n",
    "                            \"predict_column\": \"Predict\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"protected_attributes\": [\n",
    "                    {\n",
    "                        \"feature\": \"Sex\",\n",
    "                        \"reference_group\": [\"male\"],\n",
    "                        \"monitored_group\": [\"female\"]\n",
    "                    },\n",
    "                    {\n",
    "                        \"feature\": \"Age\",\n",
    "                        \"reference_group\": [[26, 55], [56, 75]],\n",
    "                        \"monitored_group\": [[55, 60]]\n",
    "                    }\n",
    "                ],\n",
    "                \"favourable_label\": [\"No Risk\"],\n",
    "                \"unfavourable_label\": [\"Risk\"],\n",
    "            }\n",
    "        }}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241aeb4a",
   "metadata": {},
   "source": [
    "## 5. Compute Equality Metrics <a name=\"compute\"></a>\n",
    "\n",
    "calculate Equality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = client.ai_metrics.compute_metrics(spark=spark, configuration=measure_configuration, data_frame=spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ae8e7",
   "metadata": {},
   "source": [
    "show the result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(metrics.get(\"metrics_result\").get(\"fairness\").get(\"performance_measures\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892b80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
