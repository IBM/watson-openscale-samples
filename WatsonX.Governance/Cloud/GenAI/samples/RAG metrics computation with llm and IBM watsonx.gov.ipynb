{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e30227-4902-4500-a659-b79717befdb5",
   "metadata": {
    "id": "f7e28a78-d158-40c1-92de-56937f84ad7d"
   },
   "source": [
    "# Retrieval and Answer Quality Metrics computation using LLM as Judge in IBM watsonx.governance for RAG task\n",
    "\n",
    "This notebook demonstrates the creation of a Retrieval Augumented Generation (RAG) pattern using watsonx.ai and computations of reference-free Answer Quality metrics, such as **Faithfulness**, **Answer relevance**, reference based **Answer similarity** metric and Retrieval Quality Metrics such as **Context Relevance**, **Retrieval Precision**, **Average Precision**, **Reciprocal Rank**, **Hit Rate** and **Normalized Discounted Cumulative Gain** for the RAG task type. It also identifies the source attribution using watsonx.governance.\n",
    "\n",
    "- **Faithfulness** measures how faithful the model output or generated text is to the context sent to the LLM input. The faithfulness score is a value between 0 and 1. A value closer to 1 indicates that the output is more faithful - or grounded - and less hallucinated. A value closer to 0 indicates that the output is less faithful and more hallucinated.\n",
    "\n",
    "- **Answer relevance** measures how relevant the answer or generated text is to the question. This is one of the ways to determine the quality of your model. The answer relevance score is a value between 0 and 1. A value closer to 1 indicates that the answer is more relevant to the given question. A value closer to 0 indicates that the answer is less relevant to the question.\n",
    "\n",
    "- **Answer similarity** measures how similar the answer or generated text is to the ground truth or reference answer. This is one of the ways to determine the quality of your model. The answer similarity score is a value between 0 and 1. A value closer to 1 indicates that the answer is more similar to the reference value. A value closer to 0 indicates that the answer is less similar to the reference value.\n",
    "\n",
    "- **Context Relevance** assesses the degree to which the retrieved context is relevant to the question sent to the LLM. This is one of the ways to determine the quality of your retrieval system. The context relevance score is a value between 0 and 1. A value closer to 1 indicates that the context is more relevant to your question in the prompt. A value closer to 0 indicates that the context is less relevant to your question in the prompt.\n",
    "\n",
    "- **Retrieval Precision** measures the quantity of relevant contexts from the total contexts retrieved. The retrieval precision is a value between 0 and 1. A value of 1 indicates that all the retrieved contexts are relevant. A value of 0 indicates that none of the retrieved contexts are relevant.\n",
    "\n",
    "- **Average Precision** evaluates whether all the relevant contexts are ranked higher or not. It is the mean of the precision scores of relevant contexts. The average precision is a value between 0 and 1. A value of 1 indicates that all the relevant contexts are ranked higher. A value of 0 indicates that none of the retrieved contexts are relevant.\n",
    "\n",
    "- **Reciprocal Rank** is the reciprocal of the rank of the first relevant context. The retrieval reciprocal rank is a value between 0 and 1. A value of 1 indicates that the first relevant context is at first position. A value of 0 indicates that none of the relevant contexts are retrieved.\n",
    "\n",
    "- **Hit Rate** Hit Rate measures whether there is atleast one relevant context among the retrieved contexts. The hit rate value is either 0 or 1. A value of 1 indicates that there is at least one relevant context. A value of 0 indicates that there is no relevant context in the retrieved contexts.\n",
    "\n",
    "- **Normalized Discounted Cumulative Gain** Normalized Discounted Cumulative Gain or NDCG measures the ranking quality of the retrieved contexts. The ndcg is a value between 0 and 1. A value of 1 indicates that the retrieved contexts are ranked in the correct order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b45bee",
   "metadata": {
    "id": "79295da1-b715-4d17-8c55-2d036aaae159"
   },
   "source": [
    "## Learning goals\n",
    "\n",
    "- Read data into a vector database\n",
    "- Initialize foundation model\n",
    "- Generate RAG responses\n",
    "- Configure and compute Retrieval and Answer Quality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a5d37f",
   "metadata": {
    "id": "2582b1c0-d5ea-4c9d-b867-311bef09c968"
   },
   "source": [
    "## Contents\n",
    "\n",
    "- [Step 1 - Setup](#setup)\n",
    "- [Step 2 - Read data and store in vector db](#data)\n",
    "- [Step 3 - Initialize foundational model using watsonx.ai](#model)\n",
    "- [Step 4 - Generate the retrieval-augmented responses to questions](#predict)\n",
    "- [Step 5 - Configure the retrieval and answer quality metrics](#config)\n",
    "- [Step 6 - Compute the retrieval and answer quality metrics](#compute)\n",
    "- [Step 7 - Display the results](#results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48e55a5-6a38-4cce-a043-990da6cadb6e",
   "metadata": {
    "id": "c4ccd12e-958f-4bda-bed7-0fa870944848"
   },
   "source": [
    "## Step 1 - Setup <a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd0c957-b76c-4ab9-bba9-467cd78638e5",
   "metadata": {
    "id": "ea7f0768-01c7-4090-a8ae-027767b44fab"
   },
   "source": [
    "### Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a66f96",
   "metadata": {
    "id": "79c58c18-ac59-4cc9-9aa9-f355257b22b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.39.3 which is incompatible.\n",
      "langchain-huggingface 0.1.2 requires tokenizers>=0.19.1, but you have tokenizers 0.15.2 which is incompatible.\n",
      "caikit-nlp 0.4.9 requires sentence-transformers<2.4.0,>=2.3.1, but you have sentence-transformers 3.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.39.3\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from requests<3.0,>=2.0->ibm-watson-openscale) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from lomond->ibm_watsonx_ai) (1.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain==0.3.4) (3.0.0)\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ibm-metrics-plugin 3.0.11 requires transformers~=4.39.3, but you have transformers 4.46.3 which is incompatible.\n",
      "caikit-nlp 0.4.9 requires sentence-transformers<2.4.0,>=2.3.1, but you have sentence-transformers 3.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.20.3 transformers-4.46.3\n",
      "Requirement already satisfied: wget in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.13) (0.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from pydantic) (4.11.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.1.16->langchain-ibm) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed ibm_watsonx_ai-1.1.24\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain==0.3.4) (3.0.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "ibm-metrics-plugin 3.0.11 requires transformers~=4.39.3, but you have transformers 4.46.3 which is incompatible.\r\n",
      "caikit-nlp 0.4.9 requires sentence-transformers<2.4.0,>=2.3.1, but you have sentence-transformers 3.3.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed huggingface-hub-0.26.2 langchain-core-0.3.21 langchain-huggingface-0.1.2 sentence-transformers-3.3.1 tokenizers-0.20.3 transformers-4.46.3\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed wget-3.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.13) (0.1.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from pydantic) (4.11.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.1.14->langchain-ibm) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"ibm-metrics-plugin~=3.0.9\" | tail -n 1\n",
    "!pip install -U ibm-watson-openscale | tail -n 1\n",
    "!pip install -U ibm_watsonx_ai | tail -n 1\n",
    "!pip install langchain==0.3.4 | tail -n 1\n",
    "!pip install langchain-huggingface==0.1.2 | tail -n 1\n",
    "!pip install wget | tail -n 1\n",
    "!pip install sentence-transformers | tail -n 1\n",
    "!pip install chromadb==0.4.13 | tail -n 1\n",
    "!pip install pydantic | tail -n 1\n",
    "!pip install langchain-ibm | tail -n 1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d42b608-30ce-4ded-a806-7fc3905d53de",
   "metadata": {
    "id": "1538ff11-6c44-4468-b5f5-ab078b3dd679"
   },
   "source": [
    "**Note**: you may need to restart the kernel to use updated libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9266c40",
   "metadata": {
    "id": "da88ac4f-de52-40de-a6fb-da46541b5624"
   },
   "source": [
    "### Configure your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7036fa",
   "metadata": {
    "id": "73c01592-268c-4e5e-985c-89a10e491d89"
   },
   "outputs": [],
   "source": [
    "# Cloud credentials\n",
    "IAM_URL=\"https://iam.cloud.ibm.com\"\n",
    "DATAPLATFORM_URL = \"https://api.dataplatform.cloud.ibm.com\"\n",
    "SERVICE_URL = \"https://aiopenscale.cloud.ibm.com\"\n",
    "CLOUD_API_KEY = \"<EDIT THIS>\" # YOUR_CLOUD_API_KEY\n",
    "\n",
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": CLOUD_API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c181c4e-2b54-4bf0-9070-223bf7837c76",
   "metadata": {
    "id": "3130b766-e642-42ee-8c87-5dfc40baa57e"
   },
   "source": [
    "### Configure your project id\n",
    "Provide the project id to provide the context needed to run the inference against the watsonx.ai model.\n",
    "\n",
    "***Hint***: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be \"Projects / *project name* /\". Click on the \"*project name*\" link, then get the `project_id` from the project's \"Manage\" tab (\"Project -> Manage -> General -> Details\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23d9b2-fd37-454a-82d9-c0f37b2766ac",
   "metadata": {
    "id": "51e8c6f5-6cf2-40c9-a851-9e078b7bfe76"
   },
   "outputs": [],
   "source": [
    "project_id = \"<EDIT THIS>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150430a",
   "metadata": {
    "id": "393fdf8b-c8b0-40b8-ab81-e83e19d5f9f4"
   },
   "source": [
    "## Step 2 - Read and store data in a vector database <a id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec65a592-7608-45bb-bae2-bb4cf5fccc88",
   "metadata": {
    "id": "20d9ec92-0fc0-40d7-9c73-885a9d0b245e"
   },
   "source": [
    "### Read the data\n",
    "\n",
    "Download the sample \"State of the Union\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2ddc58-7909-4a03-8089-4261cba5876f",
   "metadata": {
    "id": "94cc66d6-02e7-42bc-bd80-9b6b7745a25b"
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "data = 'state_of_the_union.txt'\n",
    "url = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/foundation_models/state_of_the_union.txt'\n",
    "\n",
    "if not os.path.isfile(data):\n",
    "    wget.download(url, out=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb70d1af-2750-41de-85b0-815ad3758ee5",
   "metadata": {
    "id": "1be5c650-39e3-4834-85a9-55cffcb86261"
   },
   "source": [
    "### Prepare the data for the vector database\n",
    "\n",
    "Take the `state_of_the_union.txt` speech content data and split it into chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a64a21d-437e-421a-be84-ff605e02d142",
   "metadata": {
    "id": "0da3624d-5af6-45d1-b812-75afeed18296"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "loader = TextLoader(data)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030bbb37-7e24-43d5-821e-a1da1ac7c656",
   "metadata": {
    "id": "e05a1951-f9aa-4ed2-94b0-b68b380189ec"
   },
   "source": [
    "### Create an embedding function to store the data in a vector database\n",
    "\n",
    "Embed the chunked data using an open-source embedding model and load it into Chromadb, a vector database.\n",
    "\n",
    "**Note**: You can also provide a custom embedding function to be used by Chromadb; the performance of Chromadb may differ depending on the embedding model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efbbb44-57ca-4c19-949f-756b15a86c41",
   "metadata": {
    "id": "31866696-d7d5-43c1-9c83-a9f03f4f7e33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/envs/Python-RT24.1-Premium/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9197fe-53ba-4e29-b481-4811859e07ef",
   "metadata": {
    "id": "1a6fecf0-8bd9-4eee-8c1b-1eebb86eaec4"
   },
   "source": [
    "## Step 3 - Initialize a foundation model using `watsonx.ai`\n",
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f958a4e0-72e7-4683-a952-c769c62ed379",
   "metadata": {
    "id": "d5800d38-4c6e-4fc4-86a6-9b7368304022"
   },
   "source": [
    "IBM watsonx foundation models are among the <a href=\"https://python.langchain.com/docs/integrations/llms/watsonxllm\" target=\"_blank\" rel=\"noopener no referrer\">list of LLM models supported by Langchain</a>. This example shows how to communicate with <a href=\"https://newsroom.ibm.com/2023-09-28-IBM-Announces-Availability-of-watsonx-Granite-Model-Series,-Client-Protections-for-IBM-watsonx-Models\" target=\"_blank\" rel=\"noopener no referrer\">Granite Model Series</a> using <a href=\"https://python.langchain.com/docs/get_started/introduction\" target=\"_blank\" rel=\"noopener no referrer\">Langchain</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1fa6b-63b5-4d85-ae3d-1b6b275aa5a9",
   "metadata": {
    "id": "3c92b6d5-93ac-41c6-ab90-461beccf6064"
   },
   "source": [
    "### Define a model\n",
    "Specify a `model_id` that will be used for inferencing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c7cd4b-cd8f-40b8-be46-cce1a92c1e97",
   "metadata": {
    "id": "b22e4770-00bd-4ebd-9000-d0975512aee4"
   },
   "outputs": [],
   "source": [
    "model_id = \"ibm/granite-3-8b-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72840462-39cc-4d3a-a39e-acffe2fd8ee3",
   "metadata": {
    "id": "0e92cce9-8767-4424-b3d6-55a08c235cc1"
   },
   "source": [
    "### Define the model parameters\n",
    "Provide a set of model parameters that will influence the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c65c4db-49aa-493c-82ea-bdf224551f27",
   "metadata": {
    "id": "2d4757bb-b601-44d1-af5c-5787845854ad"
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 100,\n",
    "    GenParams.STOP_SEQUENCES: [\"<|endoftext|>\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600c734-37d0-47ef-9a5d-8291783d0e79",
   "metadata": {
    "id": "f3a44b4e-a121-4175-9e5e-5e956cf8a916"
   },
   "source": [
    "### Set LangChain custom LLM wrapper for watsonx model\n",
    "Initialize the `WatsonxLLM` class from LangChain with defined parameters, and using `ibm/granite-13b-chat-v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e1616d-9fce-40d2-a4a1-f2285f04eee3",
   "metadata": {
    "id": "a1224c39-17dd-492f-9290-a7bd1495f1e8"
   },
   "outputs": [],
   "source": [
    "from langchain_ibm import WatsonxLLM\n",
    "\n",
    "watsonx_llm = WatsonxLLM(\n",
    "    model_id=model_id,\n",
    "    url=credentials.get(\"url\"),\n",
    "    apikey=credentials.get(\"apikey\"),\n",
    "    project_id=project_id,\n",
    "    params=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e5c9e5-079f-44de-acb3-39c691b72114",
   "metadata": {
    "id": "ab7c19e9-15cf-47cf-b1c8-272808ff8284"
   },
   "source": [
    "## Step 4 - Generate retrieval-augmented responses to questions\n",
    "<a id=\"predict\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bbb5f0-001c-432d-b0ac-5938309b0259",
   "metadata": {
    "id": "00603f12-e323-4194-8d28-d7ac7d2eb839"
   },
   "source": [
    "### Build a `RetrievalQA` (question answering chain) to automate the RAG task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06aa4835-e5ec-460a-970f-7db358d20951",
   "metadata": {
    "id": "7f6c259e-6368-43f7-b2a2-757e476f5b67"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=watsonx_llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b21c62-6502-45d9-93cc-345dfc441ba2",
   "metadata": {
    "id": "73c86a18-cab5-4b9f-b075-6adc0064b059"
   },
   "outputs": [],
   "source": [
    "query1 = \"What is ARPA-H?\"\n",
    "query2 = \"What is the investment of Ford and GM to build electric vehicles?\"\n",
    "query3 = \"What is the proposed tax rate for corporations?\"\n",
    "query4 = \"What is Intel going to build?\"\n",
    "query5 = \"How many new manufacturing jobs are created last year?\"\n",
    "query6 = \"How many electric vehicle charging stations are built?\"\n",
    "\n",
    "questions = [query1 , query2, query3, query4, query5, query6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c509fc55-43a6-40d6-92fa-04afbe932697",
   "metadata": {
    "id": "e07bf116-053f-4e16-bd20-4123386b425f"
   },
   "source": [
    "### Generate retrieval-augmented responses to the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0acedda-0754-49bd-a811-099d375f932a",
   "metadata": {
    "id": "4402b098-0755-46e2-b7f0-76c54801451c"
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "contexts = []\n",
    "for query in questions:\n",
    "    #Retrive relevant context for each question from the vector db\n",
    "    docs = docsearch.as_retriever().invoke(query)\n",
    "\n",
    "    context = []\n",
    "    #Extract the needed information\n",
    "    for doc in docs:\n",
    "        context.append(doc.to_json()['kwargs']['page_content'])\n",
    "\n",
    "    #Capture the context\n",
    "    contexts.append(context)\n",
    "\n",
    "    #Run the prompt and get the response\n",
    "    response = qa.invoke(query)\n",
    "    responses.append(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb5e60dd-e5cf-4241-8f09-47c855313844",
   "metadata": {
    "id": "b93a26db-c99b-4984-a11b-8ff9d4e6adb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:What is ARPA-H?\n",
      " context:['Last month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror.', 'We’re also ready with anti-viral treatments. If you get COVID-19, the Pfizer pill reduces your chances of ending up in the hospital by 90%.  \\n\\nWe’ve ordered more of these pills than anyone in the world. And Pfizer is working overtime to get us 1 Million pills this month and more than double that next month.  \\n\\nAnd we’re launching the “Test to Treat” initiative so people can get tested at a pharmacy, and if they’re positive, receive antiviral pills on the spot at no cost.  \\n\\nIf you’re immunocompromised or have some other vulnerability, we have treatments and free high-quality masks. \\n\\nWe’re leaving no one behind or ignoring anyone’s needs as we move forward. \\n\\nAnd on testing, we have made hundreds of millions of tests available for you to order for free.   \\n\\nEven if you already ordered free tests tonight, I am announcing that you can order more from covidtests.gov starting next week.', 'For that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world.', 'If you travel 20 miles east of Columbus, Ohio, you’ll find 1,000 empty acres of land. \\n\\nIt won’t look like much, but if you stop and look closely, you’ll see a “Field of dreams,” the ground on which America’s future will be built. \\n\\nThis is where Intel, the American company that helped build Silicon Valley, is going to build its $20 billion semiconductor “mega site”. \\n\\nUp to eight state-of-the-art factories in one place. 10,000 new good-paying jobs. \\n\\nSome of the most sophisticated manufacturing in the world to make computer chips the size of a fingertip that power the world and our everyday lives. \\n\\nSmartphones. The Internet. Technology we have yet to invent. \\n\\nBut that’s just the beginning. \\n\\nIntel’s CEO, Pat Gelsinger, who is here tonight, told me they are ready to increase their investment from  \\n$20 billion to $100 billion. \\n\\nThat would be one of the biggest investments in manufacturing in American history. \\n\\nAnd all they’re waiting for is for you to pass this bill.']\n"
     ]
    }
   ],
   "source": [
    "#Print a sample context retrieved for a query \n",
    "print(f\"Question:{questions[0]}\\n context:{contexts[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "378b3bfe-ad64-4e6d-8b40-9939a2545800",
   "metadata": {
    "id": "7684359d-85f8-4611-bd8c-8073f0b6ccf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is ARPA-H? \n",
      " \n",
      "\n",
      "ARPA-H, or the Advanced Research Projects Agency for Health, is a proposed agency in the United States that would be dedicated to driving breakthroughs in cancer, Alzheimer's, diabetes, and other diseases. It is based on DARPA, the Defense Department project that led to the Internet, GPS, and other technologies. The agency would be funded by Congress as part of the Cancer Moonshot initiative, \n",
      "\n",
      "What is the investment of Ford and GM to build electric vehicles? \n",
      " \n",
      "\n",
      "Ford is investing $11 billion to build electric vehicles, creating 11,000 jobs across the country. GM is making the largest investment in its history—$7 billion to build electric vehicles, creating 4,000 jobs in Michigan. \n",
      "\n",
      "What is the proposed tax rate for corporations? \n",
      " \n",
      "\n",
      "The proposed tax rate for corporations is 15%. \n",
      "\n",
      "What is Intel going to build? \n",
      " \n",
      "\n",
      "Intel is going to build up to eight state-of-the-art factories in one place, which will be a $20 billion semiconductor \"mega site\". These factories will produce computer chips that power various technologies, including smartphones and the Internet. The company is also considering increasing its investment from $20 billion to $100 billion. \n",
      "\n",
      "How many new manufacturing jobs are created last year? \n",
      " \n",
      "\n",
      "369,000 new manufacturing jobs were created in America last year. \n",
      "\n",
      "How many electric vehicle charging stations are built? \n",
      " \n",
      "\n",
      "The text does not provide specific information on the number of electric vehicle charging stations built. It mentions the plan to build a national network of 500,000 electric vehicle charging stations, but it does not state how many have been built so far. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the result\n",
    "for query in questions:\n",
    "    print(f\"{query} \\n {responses[questions.index(query)]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbd5cc-8847-4b80-8ff7-54dd4938f957",
   "metadata": {
    "id": "661a1c8b-a4da-4c64-b448-884305ccda31"
   },
   "source": [
    "### Construct a dataframe with question, contexts and answer to be used for metrics computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42686499-4197-48f2-8164-34f5d2b1ce5a",
   "metadata": {
    "id": "9df1b6eb-0d56-4ac1-bf16-ca9d203e30bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context1</th>\n",
       "      <th>context2</th>\n",
       "      <th>context3</th>\n",
       "      <th>context4</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last month, I announced our plan to supercharg...</td>\n",
       "      <td>We’re also ready with anti-viral treatments. I...</td>\n",
       "      <td>For that purpose we’ve mobilized American grou...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>What is ARPA-H?</td>\n",
       "      <td>\\n\\nARPA-H, or the Advanced Research Projects ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>What is the investment of Ford and GM to build...</td>\n",
       "      <td>\\n\\nFord is investing $11 billion to build ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My plan will cut the cost in half for most fam...</td>\n",
       "      <td>We got more than 130 countries to agree on a g...</td>\n",
       "      <td>And unlike the $2 Trillion tax cut passed in t...</td>\n",
       "      <td>We’re going after the criminals who stole bill...</td>\n",
       "      <td>What is the proposed tax rate for corporations?</td>\n",
       "      <td>\\n\\nThe proposed tax rate for corporations is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>What is Intel going to build?</td>\n",
       "      <td>\\n\\nIntel is going to build up to eight state-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>As Ohio Senator Sherrod Brown says, “It’s time...</td>\n",
       "      <td>How many new manufacturing jobs are created la...</td>\n",
       "      <td>\\n\\n369,000 new manufacturing jobs were create...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>Vice President Harris and I ran for office wit...</td>\n",
       "      <td>How many electric vehicle charging stations ar...</td>\n",
       "      <td>\\n\\nThe text does not provide specific informa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            context1  \\\n",
       "0  Last month, I announced our plan to supercharg...   \n",
       "1  So let’s not wait any longer. Send it to my de...   \n",
       "2  My plan will cut the cost in half for most fam...   \n",
       "3  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "4  So let’s not wait any longer. Send it to my de...   \n",
       "5  So let’s not wait any longer. Send it to my de...   \n",
       "\n",
       "                                            context2  \\\n",
       "0  We’re also ready with anti-viral treatments. I...   \n",
       "1  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "2  We got more than 130 countries to agree on a g...   \n",
       "3  So let’s not wait any longer. Send it to my de...   \n",
       "4  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "5  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "\n",
       "                                            context3  \\\n",
       "0  For that purpose we’ve mobilized American grou...   \n",
       "1  When we use taxpayer dollars to rebuild Americ...   \n",
       "2  And unlike the $2 Trillion tax cut passed in t...   \n",
       "3  When we use taxpayer dollars to rebuild Americ...   \n",
       "4  When we use taxpayer dollars to rebuild Americ...   \n",
       "5  It is going to transform America and put us on...   \n",
       "\n",
       "                                            context4  \\\n",
       "0  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "1  It is going to transform America and put us on...   \n",
       "2  We’re going after the criminals who stole bill...   \n",
       "3  It is going to transform America and put us on...   \n",
       "4  As Ohio Senator Sherrod Brown says, “It’s time...   \n",
       "5  Vice President Harris and I ran for office wit...   \n",
       "\n",
       "                                            question  \\\n",
       "0                                    What is ARPA-H?   \n",
       "1  What is the investment of Ford and GM to build...   \n",
       "2    What is the proposed tax rate for corporations?   \n",
       "3                      What is Intel going to build?   \n",
       "4  How many new manufacturing jobs are created la...   \n",
       "5  How many electric vehicle charging stations ar...   \n",
       "\n",
       "                                              answer  \n",
       "0  \\n\\nARPA-H, or the Advanced Research Projects ...  \n",
       "1  \\n\\nFord is investing $11 billion to build ele...  \n",
       "2  \\n\\nThe proposed tax rate for corporations is ...  \n",
       "3  \\n\\nIntel is going to build up to eight state-...  \n",
       "4  \\n\\n369,000 new manufacturing jobs were create...  \n",
       "5  \\n\\nThe text does not provide specific informa...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(contexts, columns=[\"context1\", \"context2\", \"context3\", \"context4\"])\n",
    "data[\"question\"] = questions\n",
    "data[\"answer\"] = responses\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c6ecd",
   "metadata": {
    "id": "711cecf8-3ae8-4fdd-8e27-30357688b205"
   },
   "source": [
    "## Step 5 - Configure Retrieval and Answer Quality metrics\n",
    "<a id=\"config\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb3495",
   "metadata": {
    "id": "2c06609f-033f-4768-ac9d-152257783a4e"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842541f3-4518-4c5d-a2d9-b06fbe566c22",
   "metadata": {
    "id": "c835d87b-b188-42f6-9267-80f45b6d88af"
   },
   "source": [
    "#### Common parameters\n",
    "\n",
    "| Parameter | Description | Default Value | Possible Value(s) |\n",
    "|:-|:-|:-|:-|\n",
    "| context_columns | The list of context column names in the input data frame. |  |  |\n",
    "| question_column | the name of the question column in the input data frame. |  |  |\n",
    "| answer_column | The name of the answer column in the input data frame |  |  |\n",
    "| record_level [Optional] | The flag to return the record level metrics values. Set the flag under configuration to generate record level metrics for all the metrics. Set the flag under specific metric to generate record level metrics for that metric alone. | False | True, False |\n",
    "| scoring_fn | The scoring function which takes in the prompts input dataframe and score the LLM acting as Judge, return the output as a dataframe. The input data frame will have a single column \"prompt\" and the output data frame can either have a single column or if there are multiple columns, return the model output text in \"generated_text\" column. | | |\n",
    "| language_code[Optional] | The language specific prompt used for computing configured metrics in LLM as judge. | `en` | `en`, `ja` |\n",
    "\n",
    "### Metric parameters\n",
    "\n",
    "| Parameter | Description | Default Value | Possible Value(s) |\n",
    "|:-|:-|:-|:-|\n",
    "| record_level [Optional] | The flag to return the record level metrics values. Setting the flag under specific metric overrides the value provided at the configuration level. | False | True, False |\n",
    "| metric_prompt_template [Optional] | The prompt template used to compute the metric value. User can override the prompt template used by watsonx.governance to compute the metric using this parameter. The prompt template should use the variables {context}, {question}, {answer}, {reference_answer} as needed and these variable values will be filled with the actual data while calling the scoring function. The prompt response should return the metric value in the range 1-10 for the respective metric and in one of the formats [\"4\", \"7 star\", \"star: 8\", \"stars: 9\"] as answer. | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf2a7e7",
   "metadata": {
    "id": "b47ca363-0855-4c3e-a08c-6f3b1ced9ac6"
   },
   "source": [
    "### Verify client version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa0d7844-5c99-40dd-8c03-eb60a3790707",
   "metadata": {
    "id": "912ad02c-a7d6-4867-bd53-8b5cdda79472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.41\n"
     ]
    }
   ],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "\n",
    "authenticator = IAMAuthenticator(apikey=CLOUD_API_KEY, url=\"https://iam.cloud.ibm.com\")\n",
    "client = APIClient(authenticator=authenticator, service_url=\"https://aiopenscale.cloud.ibm.com\")\n",
    "\n",
    "print(client.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20ebd8",
   "metadata": {
    "id": "2a769355-bbfe-466b-9c43-18c02852bd71"
   },
   "source": [
    "### Define the scoring function to invoke the LLM acting as Judge while compute the metrics\n",
    "\n",
    "The scoring function is implemeted using model from watsonx.ai from cloud. The model FLAN_T5_XXL is used as the judge here. The other models which can be used from watsonx.ai are FLAN_UL2, FLAN_T5_XL, MIXTRAL_8X7B_INSTRUCT_V01_Q\n",
    "\n",
    "The function can be changed as needed to invoke external models as well. The quality of the retrieval and answer quality metrics can vary with the model used as judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d12a66b",
   "metadata": {
    "id": "ce42bbaa-d3c4-42a3-a63c-9d6c8f062983"
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "import pandas as pd\n",
    "\n",
    "generate_params = {\n",
    "    GenParams.MAX_NEW_TOKENS: 100,\n",
    "    GenParams.MIN_NEW_TOKENS: 10,\n",
    "    GenParams.TEMPERATURE: 0.0\n",
    "}\n",
    "\n",
    "model = ModelInference(\n",
    "    model_id=ModelTypes.FLAN_T5_XXL,\n",
    "    params=generate_params,\n",
    "    credentials={\n",
    "        \"apikey\": credentials.get(\"apikey\"),\n",
    "        \"url\": credentials.get(\"url\")\n",
    "    },\n",
    "    project_id=project_id\n",
    ")\n",
    "\n",
    "def scoring_fn(data):\n",
    "    results = []\n",
    "\n",
    "    for prompt_text in data.iloc[:, 0].values.tolist():\n",
    "        model_response = model.generate_text(prompt=prompt_text)\n",
    "        results.append(model_response)\n",
    "    return pd.DataFrame({\"generated_text\": results})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb7b684",
   "metadata": {
    "id": "feea8c38-7bd0-4b98-a12b-603f47bff9d7"
   },
   "source": [
    "### Configure context relevance, faithfulness, answer relevance and answer similarity parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35bbce5e",
   "metadata": {
    "id": "c6874bdb-b521-4497-a90d-7ccd864e69f1"
   },
   "outputs": [],
   "source": [
    "from ibm_metrics_plugin.metrics.llm.utils.constants import LLMTextMetricGroup, LLMCommonMetrics, LLMRAGMetrics, RetrievalQualityMetric\n",
    "\n",
    "# Edit below values based on the input data\n",
    "context_columns = [\"context1\", \"context2\", \"context3\", \"context4\"]\n",
    "question_column = \"question\"\n",
    "answer_column = \"answer\"\n",
    "\n",
    "config_json = {\n",
    "            \"configuration\": {\n",
    "                \"context_columns\": context_columns,\n",
    "                \"question_column\": question_column,\n",
    "                \"scoring_fn\": scoring_fn,\n",
    "                \"record_level\": True,\n",
    "                # Uncomment language_code parameter to use other language specific prompts\n",
    "                # \"language_code\": \"en\",\n",
    "                LLMTextMetricGroup.RAG.value: {\n",
    "                        LLMRAGMetrics.RETRIEVAL_QUALITY.value: {\n",
    "                            # RetrievalQualityMetric.CONTEXT_RELEVANCE.value: {\n",
    "                                #\"record_level\": True,\n",
    "                                #\"metric_prompt_template\": \"\"\n",
    "                            #}\n",
    "                            # RetrievalQualityMetric.RETRIEVAL_PRECISION.value: {},\n",
    "                            # RetrievalQualityMetric.AVERAGE_PRECISION.value: {},\n",
    "                            # RetrievalQualityMetric.RECIPROCAL_RANK.value: {},\n",
    "                            # RetrievalQualityMetric.HIT_RATE.value: {},\n",
    "                            # RetrievalQualityMetric.NDCG.value: {}\n",
    "                        },\n",
    "                        LLMCommonMetrics.FAITHFULNESS.value: {\n",
    "                            #\"record_level\": True,\n",
    "                            #\"metric_prompt_template\": \"\"\n",
    "                        },\n",
    "                        LLMCommonMetrics.ANSWER_RELEVANCE.value: {\n",
    "                            #\"record_level\": True,\n",
    "                            #\"metric_prompt_template\": \"\"\n",
    "                        },\n",
    "                        LLMCommonMetrics.ANSWER_SIMILARITY.value: {\n",
    "                            #\"record_level\": True,\n",
    "                            #\"metric_prompt_template\": \"\"\n",
    "                        }\n",
    "                }\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d2879",
   "metadata": {
    "id": "180bba35-afc7-40a2-ad38-c66fc5201e04"
   },
   "source": [
    "### Create the input, output and reference data frames and send them as input to compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "436c949c",
   "metadata": {
    "id": "ca083bc0-8b84-4f7f-ac0e-3a2d56b70a6b"
   },
   "outputs": [],
   "source": [
    "df_input = pd.DataFrame(data, columns=context_columns+[question_column])\n",
    "df_output = pd.DataFrame(data, columns=[answer_column])\n",
    "df_reference = pd.DataFrame(data, columns=[answer_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d126ea-7429-4f8e-961b-8ebabae26a2d",
   "metadata": {
    "id": "5dcdcba5-c8b8-47aa-9583-23cfde795796"
   },
   "source": [
    "## Step 6 - Compute Retrieval and Answer Quality metrics <a id=\"compute\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc2acad1",
   "metadata": {
    "id": "29392489-8e06-4447-9ebb-ceb8eed25c56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/wsuser/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer_relevance\": {\n",
      "    \"metric_value\": 0.7667,\n",
      "    \"mean\": 0.7667,\n",
      "    \"min\": 0.4,\n",
      "    \"max\": 1.0,\n",
      "    \"total_records\": 6,\n",
      "    \"record_level_metrics\": [\n",
      "      {\n",
      "        \"answer_relevance\": 0.8,\n",
      "        \"record_id\": \"f5a41bb9-3382-4c86-b3a8-0d8b58086bfd\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_relevance\": 0.8,\n",
      "        \"record_id\": \"d72b655a-54c8-4d72-bf47-7d3f0c80ea6c\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_relevance\": 0.8,\n",
      "        \"record_id\": \"572e693e-c538-4ff0-ac06-5c590dbf02aa\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_relevance\": 1.0,\n",
      "        \"record_id\": \"81af334a-a9d5-4bb7-8927-a18063018556\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_relevance\": 0.8,\n",
      "        \"record_id\": \"6798531e-bd16-41a0-bd07-73b04ace3eb5\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_relevance\": 0.4,\n",
      "        \"record_id\": \"476259c3-c8ac-4eb6-b595-4f5a1ab119e5\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"answer_similarity\": {\n",
      "    \"metric_value\": 0.9667,\n",
      "    \"mean\": 0.9667,\n",
      "    \"min\": 0.8,\n",
      "    \"max\": 1.0,\n",
      "    \"total_records\": 6,\n",
      "    \"record_level_metrics\": [\n",
      "      {\n",
      "        \"answer_similarity\": 1.0,\n",
      "        \"record_id\": \"f5a41bb9-3382-4c86-b3a8-0d8b58086bfd\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_similarity\": 1.0,\n",
      "        \"record_id\": \"d72b655a-54c8-4d72-bf47-7d3f0c80ea6c\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_similarity\": 1.0,\n",
      "        \"record_id\": \"572e693e-c538-4ff0-ac06-5c590dbf02aa\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_similarity\": 1.0,\n",
      "        \"record_id\": \"81af334a-a9d5-4bb7-8927-a18063018556\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_similarity\": 1.0,\n",
      "        \"record_id\": \"6798531e-bd16-41a0-bd07-73b04ace3eb5\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_similarity\": 0.8,\n",
      "        \"record_id\": \"476259c3-c8ac-4eb6-b595-4f5a1ab119e5\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"faithfulness\": {\n",
      "    \"metric_value\": 0.8333,\n",
      "    \"mean\": 0.8333,\n",
      "    \"min\": 0.4,\n",
      "    \"max\": 1.0,\n",
      "    \"total_records\": 6,\n",
      "    \"record_level_metrics\": [\n",
      "      {\n",
      "        \"record_id\": \"f5a41bb9-3382-4c86-b3a8-0d8b58086bfd\",\n",
      "        \"faithfulness\": 1.0,\n",
      "        \"faithfulness_attributions\": []\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"d72b655a-54c8-4d72-bf47-7d3f0c80ea6c\",\n",
      "        \"faithfulness\": 0.8,\n",
      "        \"faithfulness_attributions\": []\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"572e693e-c538-4ff0-ac06-5c590dbf02aa\",\n",
      "        \"faithfulness\": 0.8,\n",
      "        \"faithfulness_attributions\": []\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"81af334a-a9d5-4bb7-8927-a18063018556\",\n",
      "        \"faithfulness\": 1.0,\n",
      "        \"faithfulness_attributions\": []\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"6798531e-bd16-41a0-bd07-73b04ace3eb5\",\n",
      "        \"faithfulness\": 1.0,\n",
      "        \"faithfulness_attributions\": []\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"476259c3-c8ac-4eb6-b595-4f5a1ab119e5\",\n",
      "        \"faithfulness\": 0.4,\n",
      "        \"faithfulness_attributions\": []\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"retrieval_quality\": {\n",
      "    \"context_relevance\": {\n",
      "      \"metric_value\": 1.0,\n",
      "      \"mean\": 1.0,\n",
      "      \"min\": 1.0,\n",
      "      \"max\": 1.0,\n",
      "      \"total_records\": 6\n",
      "    },\n",
      "    \"reciprocal_rank\": {\n",
      "      \"metric_value\": 0.8889,\n",
      "      \"mean\": 0.8889,\n",
      "      \"min\": 0.3333,\n",
      "      \"max\": 1.0\n",
      "    },\n",
      "    \"retrieval_precision\": {\n",
      "      \"metric_value\": 0.25,\n",
      "      \"mean\": 0.25,\n",
      "      \"min\": 0.25,\n",
      "      \"max\": 0.25\n",
      "    },\n",
      "    \"average_precision\": {\n",
      "      \"metric_value\": 0.8833,\n",
      "      \"mean\": 0.8833,\n",
      "      \"min\": 0.3,\n",
      "      \"max\": 1.0\n",
      "    },\n",
      "    \"hit_rate\": {\n",
      "      \"metric_value\": 1.0,\n",
      "      \"mean\": 1.0,\n",
      "      \"min\": 1,\n",
      "      \"max\": 1\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "      \"metric_value\": 0.9513,\n",
      "      \"mean\": 0.9513,\n",
      "      \"min\": 0.7077,\n",
      "      \"max\": 1.0\n",
      "    },\n",
      "    \"record_level_metrics\": [\n",
      "      {\n",
      "        \"record_id\": \"f5a41bb9-3382-4c86-b3a8-0d8b58086bfd\",\n",
      "        \"context_relevance\": 1.0,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            1.0,\n",
      "            0.2,\n",
      "            0.2,\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.25,\n",
      "        \"average_precision\": 1.0,\n",
      "        \"reciprocal_rank\": 1.0,\n",
      "        \"hit_rate\": 1,\n",
      "        \"ndcg\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"d72b655a-54c8-4d72-bf47-7d3f0c80ea6c\",\n",
      "        \"context_relevance\": 1.0,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            1.0,\n",
      "            0.2,\n",
      "            0.2,\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.25,\n",
      "        \"average_precision\": 1.0,\n",
      "        \"reciprocal_rank\": 1.0,\n",
      "        \"hit_rate\": 1,\n",
      "        \"ndcg\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"572e693e-c538-4ff0-ac06-5c590dbf02aa\",\n",
      "        \"context_relevance\": 1.0,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            0.8,\n",
      "            0.2,\n",
      "            0.2,\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.25,\n",
      "        \"average_precision\": 1.0,\n",
      "        \"reciprocal_rank\": 1.0,\n",
      "        \"hit_rate\": 1,\n",
      "        \"ndcg\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"81af334a-a9d5-4bb7-8927-a18063018556\",\n",
      "        \"context_relevance\": 1.0,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            1.0,\n",
      "            0.2,\n",
      "            0.2,\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.25,\n",
      "        \"average_precision\": 1.0,\n",
      "        \"reciprocal_rank\": 1.0,\n",
      "        \"hit_rate\": 1,\n",
      "        \"ndcg\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"6798531e-bd16-41a0-bd07-73b04ace3eb5\",\n",
      "        \"context_relevance\": 1.0,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            1.0,\n",
      "            0.2,\n",
      "            0.2,\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.25,\n",
      "        \"average_precision\": 1.0,\n",
      "        \"reciprocal_rank\": 1.0,\n",
      "        \"hit_rate\": 1,\n",
      "        \"ndcg\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"476259c3-c8ac-4eb6-b595-4f5a1ab119e5\",\n",
      "        \"context_relevance\": 1.0,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            0.2,\n",
      "            0.2,\n",
      "            1.0,\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.25,\n",
      "        \"average_precision\": 0.3,\n",
      "        \"reciprocal_rank\": 0.3333333333333333,\n",
      "        \"hit_rate\": 1,\n",
      "        \"ndcg\": 0.7077\n",
      "      }\n",
      "    ],\n",
      "    \"total_records\": 6\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "metrics_result = client.llm_metrics.compute_metrics(config_json, \n",
    "                                                    sources=df_input, \n",
    "                                                    predictions=df_output,\n",
    "                                                    references=df_reference)\n",
    "\n",
    "print(json.dumps(metrics_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32268ba-56ec-43d6-a91d-97c9d59105b5",
   "metadata": {
    "id": "38487e91-cdac-490f-8ff7-ef1b4a33846a"
   },
   "source": [
    "## Step 7 - Display the results <a id=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dca741-bc78-4550-a5e7-cd33e068e562",
   "metadata": {
    "id": "17862037-3fd8-47d0-9617-32db81845ff3"
   },
   "source": [
    "### Get metric results for all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f551cc92",
   "metadata": {
    "id": "821a78b8-5124-47a2-b351-bcb08c3bfba6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context1</th>\n",
       "      <th>context2</th>\n",
       "      <th>context3</th>\n",
       "      <th>context4</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_similarity</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_relevance</th>\n",
       "      <th>retrieval_precision</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>reciprocal_rank</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last month, I announced our plan to supercharg...</td>\n",
       "      <td>We’re also ready with anti-viral treatments. I...</td>\n",
       "      <td>For that purpose we’ve mobilized American grou...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>What is ARPA-H?</td>\n",
       "      <td>\\n\\nARPA-H, or the Advanced Research Projects ...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>What is the investment of Ford and GM to build...</td>\n",
       "      <td>\\n\\nFord is investing $11 billion to build ele...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My plan will cut the cost in half for most fam...</td>\n",
       "      <td>We got more than 130 countries to agree on a g...</td>\n",
       "      <td>And unlike the $2 Trillion tax cut passed in t...</td>\n",
       "      <td>We’re going after the criminals who stole bill...</td>\n",
       "      <td>What is the proposed tax rate for corporations?</td>\n",
       "      <td>\\n\\nThe proposed tax rate for corporations is ...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>What is Intel going to build?</td>\n",
       "      <td>\\n\\nIntel is going to build up to eight state-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>As Ohio Senator Sherrod Brown says, “It’s time...</td>\n",
       "      <td>How many new manufacturing jobs are created la...</td>\n",
       "      <td>\\n\\n369,000 new manufacturing jobs were create...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>Vice President Harris and I ran for office wit...</td>\n",
       "      <td>How many electric vehicle charging stations ar...</td>\n",
       "      <td>\\n\\nThe text does not provide specific informa...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            context1  \\\n",
       "0  Last month, I announced our plan to supercharg...   \n",
       "1  So let’s not wait any longer. Send it to my de...   \n",
       "2  My plan will cut the cost in half for most fam...   \n",
       "3  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "4  So let’s not wait any longer. Send it to my de...   \n",
       "5  So let’s not wait any longer. Send it to my de...   \n",
       "\n",
       "                                            context2  \\\n",
       "0  We’re also ready with anti-viral treatments. I...   \n",
       "1  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "2  We got more than 130 countries to agree on a g...   \n",
       "3  So let’s not wait any longer. Send it to my de...   \n",
       "4  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "5  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "\n",
       "                                            context3  \\\n",
       "0  For that purpose we’ve mobilized American grou...   \n",
       "1  When we use taxpayer dollars to rebuild Americ...   \n",
       "2  And unlike the $2 Trillion tax cut passed in t...   \n",
       "3  When we use taxpayer dollars to rebuild Americ...   \n",
       "4  When we use taxpayer dollars to rebuild Americ...   \n",
       "5  It is going to transform America and put us on...   \n",
       "\n",
       "                                            context4  \\\n",
       "0  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "1  It is going to transform America and put us on...   \n",
       "2  We’re going after the criminals who stole bill...   \n",
       "3  It is going to transform America and put us on...   \n",
       "4  As Ohio Senator Sherrod Brown says, “It’s time...   \n",
       "5  Vice President Harris and I ran for office wit...   \n",
       "\n",
       "                                            question  \\\n",
       "0                                    What is ARPA-H?   \n",
       "1  What is the investment of Ford and GM to build...   \n",
       "2    What is the proposed tax rate for corporations?   \n",
       "3                      What is Intel going to build?   \n",
       "4  How many new manufacturing jobs are created la...   \n",
       "5  How many electric vehicle charging stations ar...   \n",
       "\n",
       "                                              answer  answer_relevance  \\\n",
       "0  \\n\\nARPA-H, or the Advanced Research Projects ...               0.8   \n",
       "1  \\n\\nFord is investing $11 billion to build ele...               0.8   \n",
       "2  \\n\\nThe proposed tax rate for corporations is ...               0.8   \n",
       "3  \\n\\nIntel is going to build up to eight state-...               1.0   \n",
       "4  \\n\\n369,000 new manufacturing jobs were create...               0.8   \n",
       "5  \\n\\nThe text does not provide specific informa...               0.4   \n",
       "\n",
       "   answer_similarity  faithfulness  context_relevance  retrieval_precision  \\\n",
       "0                1.0           1.0                1.0                 0.25   \n",
       "1                1.0           0.8                1.0                 0.25   \n",
       "2                1.0           0.8                1.0                 0.25   \n",
       "3                1.0           1.0                1.0                 0.25   \n",
       "4                1.0           1.0                1.0                 0.25   \n",
       "5                0.8           0.4                1.0                 0.25   \n",
       "\n",
       "   average_precision  reciprocal_rank  hit_rate    ndcg  \n",
       "0                1.0         1.000000         1  1.0000  \n",
       "1                1.0         1.000000         1  1.0000  \n",
       "2                1.0         1.000000         1  1.0000  \n",
       "3                1.0         1.000000         1  1.0000  \n",
       "4                1.0         1.000000         1  1.0000  \n",
       "5                0.3         0.333333         1  0.7077  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = data.copy()\n",
    "\n",
    "for metric_name, metric_data in metrics_result.items():\n",
    "    vals = {}\n",
    "    if \"record_level_metrics\" in metric_data:\n",
    "        for rm in metric_data[\"record_level_metrics\"]:\n",
    "            for m, mv in rm.items():\n",
    "                if m != \"record_id\" and m!= \"faithfulness_attributions\" and m!= \"context_relevances\":  # Excluding columns\n",
    "                    if m in vals:\n",
    "                        vals[m].append(mv)\n",
    "                    else:\n",
    "                        vals[m] = [mv]\n",
    "\n",
    "    if vals:\n",
    "        for k, v in vals.items():\n",
    "            results_df[k] = v\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a5d46-b78e-4945-878e-53dd4b5936ba",
   "metadata": {
    "id": "8eb86a0c-89b3-4643-985c-80d9ebfeb4eb"
   },
   "source": [
    "Author: <a href=\"mailto:pvemulam@in.ibm.com\">Pratap Kishore Varma V</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01751f16",
   "metadata": {
    "id": "749ea36d-6436-4eea-91a4-b6e0ec9c47a4"
   },
   "source": [
    "Copyright © 2024 IBM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
