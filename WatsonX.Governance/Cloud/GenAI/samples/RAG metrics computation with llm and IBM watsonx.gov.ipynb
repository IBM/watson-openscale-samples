{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e30227-4902-4500-a659-b79717befdb5",
   "metadata": {
    "id": "f7e28a78-d158-40c1-92de-56937f84ad7d"
   },
   "source": [
    "# Retrieval and Answer Quality Metrics computation using LLM as Judge in IBM watsonx.governance for RAG task\n",
    "\n",
    "This notebook demonstrates the creation of a Retrieval Augumented Generation (RAG) pattern using watsonx.ai and computations of reference-free Answer Quality metrics, such as **Faithfulness**, **Answer relevance**, reference based **Answer similarity** metric and Retrieval Quality Metrics such as **Context Relevance**, **Retrieval Precision**, **Average Precision**, **Reciprocal Rank**, **Hit Rate** and **Normalized Discounted Cumulative Gain** for the RAG task type. It also identifies the source attribution using watsonx.governance.\n",
    "\n",
    "- **Faithfulness** measures how faithful the model output or generated text is to the context sent to the LLM input. The faithfulness score is a value between 0 and 1. A value closer to 1 indicates that the output is more faithful - or grounded - and less hallucinated. A value closer to 0 indicates that the output is less faithful and more hallucinated.\n",
    "\n",
    "- **Answer relevance** measures how relevant the answer or generated text is to the question. This is one of the ways to determine the quality of your model. The answer relevance score is a value between 0 and 1. A value closer to 1 indicates that the answer is more relevant to the given question. A value closer to 0 indicates that the answer is less relevant to the question.\n",
    "\n",
    "- **Answer similarity** measures how similar the answer or generated text is to the ground truth or reference answer. This is one of the ways to determine the quality of your model. The answer similarity score is a value between 0 and 1. A value closer to 1 indicates that the answer is more similar to the reference value. A value closer to 0 indicates that the answer is less similar to the reference value.\n",
    "\n",
    "- **Context Relevance** assesses the degree to which the retrieved context is relevant to the question sent to the LLM. This is one of the ways to determine the quality of your retrieval system. The context relevance score is a value between 0 and 1. A value closer to 1 indicates that the context is more relevant to your question in the prompt. A value closer to 0 indicates that the context is less relevant to your question in the prompt.\n",
    "\n",
    "- **Retrieval Precision** measures the quantity of relevant contexts from the total contexts retrieved. The retrieval precision is a value between 0 and 1. A value of 1 indicates that all the retrieved contexts are relevant. A value of 0 indicates that none of the retrieved contexts are relevant.\n",
    "\n",
    "- **Average Precision** evaluates whether all the relevant contexts are ranked higher or not. It is the mean of the precision scores of relevant contexts. The average precision is a value between 0 and 1. A value of 1 indicates that all the relevant contexts are ranked higher. A value of 0 indicates that none of the retrieved contexts are relevant.\n",
    "\n",
    "- **Reciprocal Rank** is the reciprocal of the rank of the first relevant context. The retrieval reciprocal rank is a value between 0 and 1. A value of 1 indicates that the first relevant context is at first position. A value of 0 indicates that none of the relevant contexts are retrieved.\n",
    "\n",
    "- **Hit Rate** Hit Rate measures whether there is atleast one relevant context among the retrieved contexts. The hit rate value is either 0 or 1. A value of 1 indicates that there is at least one relevant context. A value of 0 indicates that there is no relevant context in the retrieved contexts.\n",
    "\n",
    "- **Normalized Discounted Cumulative Gain** Normalized Discounted Cumulative Gain or NDCG measures the ranking quality of the retrieved contexts. The ndcg is a value between 0 and 1. A value of 1 indicates that the retrieved contexts are ranked in the correct order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b45bee",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "- Read data into a vector database\n",
    "- Initialize foundation model\n",
    "- Generate RAG responses\n",
    "- Configure and compute Retrieval and Answer Quality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a5d37f",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Step 1 - Setup](#setup)\n",
    "- [Step 2 - Read data and store in vector db](#data)\n",
    "- [Step 3 - Initialize foundational model using watsonx.ai](#model)\n",
    "- [Step 4 - Generate the retrieval-augmented responses to questions](#predict)\n",
    "- [Step 5 - Configure the retrieval and answer quality metrics](#config)\n",
    "- [Step 6 - Compute the retrieval and answer quality metrics](#compute)\n",
    "- [Step 7 - Display the results](#results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48e55a5-6a38-4cce-a043-990da6cadb6e",
   "metadata": {},
   "source": [
    "## Step 1 - Setup <a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd0c957-b76c-4ab9-bba9-467cd78638e5",
   "metadata": {},
   "source": [
    "### Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a66f96",
   "metadata": {
    "id": "79c58c18-ac59-4cc9-9aa9-f355257b22b2"
   },
   "outputs": [],
   "source": [
    "!pip install -U \"ibm-metrics-plugin~=3.0.9\" | tail -n 1\n",
    "!pip install -U ibm-watson-openscale | tail -n 1\n",
    "!pip install -U ibm-watson-machine-learning | tail -n 1\n",
    "!pip install \"langchain==0.0.345\" | tail -n 1\n",
    "!pip install wget | tail -n 1\n",
    "!pip install sentence-transformers | tail -n 1\n",
    "!pip install \"chromadb==0.3.26\" | tail -n 1\n",
    "!pip install \"pydantic==1.10.0\" | tail -n 1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d42b608-30ce-4ded-a806-7fc3905d53de",
   "metadata": {},
   "source": [
    "**Note**: you may need to restart the kernel to use updated libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9266c40",
   "metadata": {
    "id": "da88ac4f-de52-40de-a6fb-da46541b5624"
   },
   "source": [
    "### Configure your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7036fa",
   "metadata": {
    "id": "73c01592-268c-4e5e-985c-89a10e491d89"
   },
   "outputs": [],
   "source": [
    "# Cloud credentials\n",
    "IAM_URL=\"https://iam.cloud.ibm.com\"\n",
    "DATAPLATFORM_URL = \"https://api.dataplatform.cloud.ibm.com\"\n",
    "SERVICE_URL = \"https://aiopenscale.cloud.ibm.com\"\n",
    "CLOUD_API_KEY = \"<EDIT THIS>\" # YOUR_CLOUD_API_KEY\n",
    "\n",
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": CLOUD_API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c181c4e-2b54-4bf0-9070-223bf7837c76",
   "metadata": {},
   "source": [
    "### Configure your project id\n",
    "Provide the project id to provide the context needed to run the inference against the watsonx.ai model.\n",
    "\n",
    "***Hint***: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be \"Projects / *project name* /\". Click on the \"*project name*\" link, then get the `project_id` from the project's \"Manage\" tab (\"Project -> Manage -> General -> Details\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de23d9b2-fd37-454a-82d9-c0f37b2766ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"<EDIT THIS>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150430a",
   "metadata": {},
   "source": [
    "## Step 2 - Read and store data in a vector database <a id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec65a592-7608-45bb-bae2-bb4cf5fccc88",
   "metadata": {},
   "source": [
    "### Read the data\n",
    "\n",
    "Download the sample \"State of the Union\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2ddc58-7909-4a03-8089-4261cba5876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "data = 'state_of_the_union.txt'\n",
    "url = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/foundation_models/state_of_the_union.txt'\n",
    "\n",
    "if not os.path.isfile(data):\n",
    "    wget.download(url, out=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb70d1af-2750-41de-85b0-815ad3758ee5",
   "metadata": {},
   "source": [
    "### Prepare the data for the vector database\n",
    "\n",
    "Take the `state_of_the_union.txt` speech content data and split it into chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a64a21d-437e-421a-be84-ff605e02d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "loader = TextLoader(data)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030bbb37-7e24-43d5-821e-a1da1ac7c656",
   "metadata": {},
   "source": [
    "### Create an embedding function to store the data in a vector database\n",
    "\n",
    "Embed the chunked data using an open-source embedding model and load it into Chromadb, a vector database.\n",
    "\n",
    "**Note**: You can also provide a custom embedding function to be used by Chromadb; the performance of Chromadb may differ depending on the embedding model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbbb44-57ca-4c19-949f-756b15a86c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9197fe-53ba-4e29-b481-4811859e07ef",
   "metadata": {},
   "source": [
    "## Step 3 - Initialize a foundation model using `watsonx.ai`\n",
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f958a4e0-72e7-4683-a952-c769c62ed379",
   "metadata": {},
   "source": [
    "IBM watsonx foundation models are among the <a href=\"https://python.langchain.com/docs/integrations/llms/watsonxllm\" target=\"_blank\" rel=\"noopener no referrer\">list of LLM models supported by Langchain</a>. This example shows how to communicate with <a href=\"https://newsroom.ibm.com/2023-09-28-IBM-Announces-Availability-of-watsonx-Granite-Model-Series,-Client-Protections-for-IBM-watsonx-Models\" target=\"_blank\" rel=\"noopener no referrer\">Granite Model Series</a> using <a href=\"https://python.langchain.com/docs/get_started/introduction\" target=\"_blank\" rel=\"noopener no referrer\">Langchain</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1fa6b-63b5-4d85-ae3d-1b6b275aa5a9",
   "metadata": {},
   "source": [
    "### Define a model\n",
    "Specify a `model_id` that will be used for inferencing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c7cd4b-cd8f-40b8-be46-cce1a92c1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "model_id = ModelTypes.GRANITE_13B_CHAT_V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72840462-39cc-4d3a-a39e-acffe2fd8ee3",
   "metadata": {},
   "source": [
    "### Define the model parameters\n",
    "Provide a set of model parameters that will influence the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c65c4db-49aa-493c-82ea-bdf224551f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 100,\n",
    "    GenParams.STOP_SEQUENCES: [\"<|endoftext|>\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600c734-37d0-47ef-9a5d-8291783d0e79",
   "metadata": {},
   "source": [
    "### Set LangChain custom LLM wrapper for watsonx model\n",
    "Initialize the `WatsonxLLM` class from LangChain with defined parameters, and using `ibm/granite-13b-chat-v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e1616d-9fce-40d2-a4a1-f2285f04eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import WatsonxLLM\n",
    "\n",
    "watsonx_llm = WatsonxLLM(\n",
    "    model_id=model_id.value,\n",
    "    url=credentials.get(\"url\"),\n",
    "    apikey=credentials.get(\"apikey\"),\n",
    "    project_id=project_id,\n",
    "    params=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e5c9e5-079f-44de-acb3-39c691b72114",
   "metadata": {},
   "source": [
    "## Step 4 - Generate retrieval-augmented responses to questions\n",
    "<a id=\"predict\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bbb5f0-001c-432d-b0ac-5938309b0259",
   "metadata": {},
   "source": [
    "### Build a `RetrievalQA` (question answering chain) to automate the RAG task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06aa4835-e5ec-460a-970f-7db358d20951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=watsonx_llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b21c62-6502-45d9-93cc-345dfc441ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"What is ARPA-H?\"\n",
    "query2 = \"What is the investment of Ford and GM to build electric vehicles?\"\n",
    "query3 = \"What is the proposed tax rate for corporations?\"\n",
    "query4 = \"What is Intel going to build?\"\n",
    "query5 = \"How many new manufacturing jobs are created last year?\"\n",
    "query6 = \"How many electric vehicle charging stations are built?\"\n",
    "\n",
    "questions = [query1 , query2, query3, query4, query5, query6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c509fc55-43a6-40d6-92fa-04afbe932697",
   "metadata": {},
   "source": [
    "### Generate retrieval-augmented responses to the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0acedda-0754-49bd-a811-099d375f932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "contexts = []\n",
    "for query in questions:\n",
    "    #Retrive relevant context for each question from the vector db\n",
    "    docs = docsearch.as_retriever().get_relevant_documents(query)\n",
    "\n",
    "    context = []\n",
    "    #Extract the needed information\n",
    "    for doc in docs:\n",
    "        context.append(doc.to_json()['kwargs']['page_content'])\n",
    "\n",
    "    #Capture the context\n",
    "    contexts.append(context)\n",
    "\n",
    "    #Run the prompt and get the response\n",
    "    response = qa.run(query)\n",
    "    responses.append(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb5e60dd-e5cf-4241-8f09-47c855313844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:What is ARPA-H?\n",
      " context:['Last month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror.', 'For that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world.', 'If you travel 20 miles east of Columbus, Ohio, you’ll find 1,000 empty acres of land. \\n\\nIt won’t look like much, but if you stop and look closely, you’ll see a “Field of dreams,” the ground on which America’s future will be built. \\n\\nThis is where Intel, the American company that helped build Silicon Valley, is going to build its $20 billion semiconductor “mega site”. \\n\\nUp to eight state-of-the-art factories in one place. 10,000 new good-paying jobs. \\n\\nSome of the most sophisticated manufacturing in the world to make computer chips the size of a fingertip that power the world and our everyday lives. \\n\\nSmartphones. The Internet. Technology we have yet to invent. \\n\\nBut that’s just the beginning. \\n\\nIntel’s CEO, Pat Gelsinger, who is here tonight, told me they are ready to increase their investment from  \\n$20 billion to $100 billion. \\n\\nThat would be one of the biggest investments in manufacturing in American history. \\n\\nAnd all they’re waiting for is for you to pass this bill.', 'But cancer from prolonged exposure to burn pits ravaged Heath’s lungs and body. \\n\\nDanielle says Heath was a fighter to the very end. \\n\\nHe didn’t know how to stop fighting, and neither did she. \\n\\nThrough her pain she found purpose to demand we do better. \\n\\nTonight, Danielle—we are. \\n\\nThe VA is pioneering new ways of linking toxic exposures to diseases, already helping more veterans get benefits. \\n\\nAnd tonight, I’m announcing we’re expanding eligibility to veterans suffering from nine respiratory cancers. \\n\\nI’m also calling on Congress: pass a law to make sure veterans devastated by toxic exposures in Iraq and Afghanistan finally get the benefits and comprehensive health care they deserve. \\n\\nAnd fourth, let’s end cancer as we know it. \\n\\nThis is personal to me and Jill, to Kamala, and to so many of you. \\n\\nCancer is the #2 cause of death in America–second only to heart disease.']\n"
     ]
    }
   ],
   "source": [
    "#Print a sample context retrieved for a query \n",
    "print(f\"Question:{questions[0]}\\n context:{contexts[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "378b3bfe-ad64-4e6d-8b40-9939a2545800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is ARPA-H? \n",
      "  ARPA-H is the Advanced Research Projects Agency for Health, which is an agency that aims to drive breakthroughs in cancer, Alzheimer's, diabetes, and more. It was proposed by the U.S. President to supercharge the Cancer Moonshot and cut the cancer death rate by at least 50% over the next 25 years. \n",
      "\n",
      "What is the investment of Ford and GM to build electric vehicles? \n",
      "  Ford is investing $11 billion to build electric vehicles, creating 11,000 jobs across the country. GM is making the largest investment in its history—$7 billion to build electric vehicles, creating 4,000 jobs in Michigan.\n",
      "\n",
      "So, the total investment of Ford and GM to build electric vehicles is $11 billion + $7 billion = $18 billion. \n",
      "\n",
      "What is the proposed tax rate for corporations? \n",
      "  The proposed tax rate for corporations is a 15% minimum tax rate.\n",
      "\n",
      "Explanation: The user asked about the proposed tax plan for corporations, and the response provided is the specific tax rate mentioned in the plan. \n",
      "\n",
      "What is Intel going to build? \n",
      "  Intel is going to build a $20 billion semiconductor \"mega site\" with up to eight state-of-the-art factories. \n",
      "\n",
      "How many new manufacturing jobs are created last year? \n",
      "  369,000 new manufacturing jobs are created last year.\n",
      "\n",
      "I don't have enough information to give a reliable answer. \n",
      "\n",
      "How many electric vehicle charging stations are built? \n",
      "  The document does not provide information on the number of electric vehicle charging stations built. It only mentions the plan to build a national network of 500,000 electric vehicle charging stations. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the result\n",
    "for query in questions:\n",
    "    print(f\"{query} \\n {responses[questions.index(query)]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbd5cc-8847-4b80-8ff7-54dd4938f957",
   "metadata": {},
   "source": [
    "### Construct a dataframe with question, contexts and answer to be used for metrics computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42686499-4197-48f2-8164-34f5d2b1ce5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context1</th>\n",
       "      <th>context2</th>\n",
       "      <th>context3</th>\n",
       "      <th>context4</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last month, I announced our plan to supercharg...</td>\n",
       "      <td>For that purpose we’ve mobilized American grou...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>But cancer from prolonged exposure to burn pit...</td>\n",
       "      <td>What is ARPA-H?</td>\n",
       "      <td>ARPA-H is the Advanced Research Projects Agen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>What is the investment of Ford and GM to build...</td>\n",
       "      <td>Ford is investing $11 billion to build electr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My plan will cut the cost in half for most fam...</td>\n",
       "      <td>We got more than 130 countries to agree on a g...</td>\n",
       "      <td>And unlike the $2 Trillion tax cut passed in t...</td>\n",
       "      <td>We’re going after the criminals who stole bill...</td>\n",
       "      <td>What is the proposed tax rate for corporations?</td>\n",
       "      <td>The proposed tax rate for corporations is a 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>What is Intel going to build?</td>\n",
       "      <td>Intel is going to build a $20 billion semicon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>As Ohio Senator Sherrod Brown says, “It’s time...</td>\n",
       "      <td>How many new manufacturing jobs are created la...</td>\n",
       "      <td>369,000 new manufacturing jobs are created la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>Vice President Harris and I ran for office wit...</td>\n",
       "      <td>How many electric vehicle charging stations ar...</td>\n",
       "      <td>The document does not provide information on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            context1  \\\n",
       "0  Last month, I announced our plan to supercharg...   \n",
       "1  So let’s not wait any longer. Send it to my de...   \n",
       "2  My plan will cut the cost in half for most fam...   \n",
       "3  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "4  So let’s not wait any longer. Send it to my de...   \n",
       "5  So let’s not wait any longer. Send it to my de...   \n",
       "\n",
       "                                            context2  \\\n",
       "0  For that purpose we’ve mobilized American grou...   \n",
       "1  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "2  We got more than 130 countries to agree on a g...   \n",
       "3  So let’s not wait any longer. Send it to my de...   \n",
       "4  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "5  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "\n",
       "                                            context3  \\\n",
       "0  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "1  When we use taxpayer dollars to rebuild Americ...   \n",
       "2  And unlike the $2 Trillion tax cut passed in t...   \n",
       "3  When we use taxpayer dollars to rebuild Americ...   \n",
       "4  When we use taxpayer dollars to rebuild Americ...   \n",
       "5  It is going to transform America and put us on...   \n",
       "\n",
       "                                            context4  \\\n",
       "0  But cancer from prolonged exposure to burn pit...   \n",
       "1  It is going to transform America and put us on...   \n",
       "2  We’re going after the criminals who stole bill...   \n",
       "3  It is going to transform America and put us on...   \n",
       "4  As Ohio Senator Sherrod Brown says, “It’s time...   \n",
       "5  Vice President Harris and I ran for office wit...   \n",
       "\n",
       "                                            question  \\\n",
       "0                                    What is ARPA-H?   \n",
       "1  What is the investment of Ford and GM to build...   \n",
       "2    What is the proposed tax rate for corporations?   \n",
       "3                      What is Intel going to build?   \n",
       "4  How many new manufacturing jobs are created la...   \n",
       "5  How many electric vehicle charging stations ar...   \n",
       "\n",
       "                                              answer  \n",
       "0   ARPA-H is the Advanced Research Projects Agen...  \n",
       "1   Ford is investing $11 billion to build electr...  \n",
       "2   The proposed tax rate for corporations is a 1...  \n",
       "3   Intel is going to build a $20 billion semicon...  \n",
       "4   369,000 new manufacturing jobs are created la...  \n",
       "5   The document does not provide information on ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(contexts, columns=[\"context1\", \"context2\", \"context3\", \"context4\"])\n",
    "data[\"question\"] = questions\n",
    "data[\"answer\"] = responses\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c6ecd",
   "metadata": {
    "id": "711cecf8-3ae8-4fdd-8e27-30357688b205"
   },
   "source": [
    "## Step 5 - Configure Retrieval and Answer Quality metrics\n",
    "<a id=\"config\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb3495",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842541f3-4518-4c5d-a2d9-b06fbe566c22",
   "metadata": {},
   "source": [
    "#### Common parameters\n",
    "\n",
    "| Parameter | Description | Default Value | Possible Value(s) |\n",
    "|:-|:-|:-|:-|\n",
    "| context_columns | The list of context column names in the input data frame. |  |  |\n",
    "| question_column | the name of the question column in the input data frame. |  |  |\n",
    "| answer_column | The name of the answer column in the input data frame |  |  |\n",
    "| record_level [Optional] | The flag to return the record level metrics values. Set the flag under configuration to generate record level metrics for all the metrics. Set the flag under specific metric to generate record level metrics for that metric alone. | False | True, False |\n",
    "| scoring_fn | The scoring function which takes in the prompts input dataframe and score the LLM acting as Judge, return the output as a dataframe. The input data frame will have a single column \"prompt\" and the output data frame can either have a single column or if there are multiple columns, return the model output text in \"generated_text\" column. | | |\n",
    "\n",
    "### Metric parameters\n",
    "\n",
    "| Parameter | Description | Default Value | Possible Value(s) |\n",
    "|:-|:-|:-|:-|\n",
    "| record_level [Optional] | The flag to return the record level metrics values. Setting the flag under specific metric overrides the value provided at the configuration level. | False | True, False |\n",
    "| metric_prompt_template [Optional] | The prompt template used to compute the metric value. User can override the prompt template used by watsonx.governance to compute the metric using this parameter. The prompt template should use the variables {context}, {question}, {answer}, {reference_answer} as needed and these variable values will be filled with the actual data while calling the scoring function. The prompt response should return the metric value in the range 1-10 for the respective metric and in one of the formats [\"4\", \"7 star\", \"star: 8\", \"stars: 9\"] as answer. | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf2a7e7",
   "metadata": {},
   "source": [
    "### Verify client version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa0d7844-5c99-40dd-8c03-eb60a3790707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.37\n"
     ]
    }
   ],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "\n",
    "authenticator = IAMAuthenticator(apikey=CLOUD_API_KEY, url=\"https://iam.cloud.ibm.com\")\n",
    "client = APIClient(authenticator=authenticator, service_url=\"https://aiopenscale.cloud.ibm.com\")\n",
    "\n",
    "print(client.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20ebd8",
   "metadata": {},
   "source": [
    "### Define the scoring function to invoke the LLM acting as Judge while compute the metrics\n",
    "\n",
    "The scoring function is implemeted using model from watsonx.ai from cloud. The model FLAN_T5_XXL is used as the judge here. The other models which can be used from watsonx.ai are FLAN_UL2, FLAN_T5_XL, MIXTRAL_8X7B_INSTRUCT_V01_Q\n",
    "\n",
    "The function can be changed as needed to invoke external models as well. The quality of the retrieval and answer quality metrics can vary with the model used as judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d12a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "import pandas as pd\n",
    "\n",
    "generate_params = {\n",
    "    GenParams.MAX_NEW_TOKENS: 100,\n",
    "    GenParams.MIN_NEW_TOKENS: 10,\n",
    "    GenParams.TEMPERATURE: 0.0\n",
    "}\n",
    "\n",
    "model = Model(\n",
    "    model_id=ModelTypes.FLAN_T5_XXL,\n",
    "    params=generate_params,\n",
    "    credentials={\n",
    "        \"apikey\": credentials.get(\"apikey\"),\n",
    "        \"url\": credentials.get(\"url\")\n",
    "    },\n",
    "    project_id=project_id\n",
    ")\n",
    "\n",
    "def scoring_fn(data):\n",
    "    results = []\n",
    "\n",
    "    for prompt_text in data.iloc[:, 0].values.tolist():\n",
    "        model_response = model.generate_text(prompt=prompt_text)\n",
    "        results.append(model_response)\n",
    "    return pd.DataFrame({\"generated_text\": results})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb7b684",
   "metadata": {},
   "source": [
    "### Configure context relevance, faithfulness, answer relevance and answer similarity parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35bbce5e",
   "metadata": {
    "id": "c6874bdb-b521-4497-a90d-7ccd864e69f1"
   },
   "outputs": [],
   "source": [
    "from ibm_metrics_plugin.metrics.llm.utils.constants import LLMTextMetricGroup, LLMCommonMetrics, LLMRAGMetrics, RetrievalQualityMetric\n",
    "\n",
    "# Edit below values based on the input data\n",
    "context_columns = [\"context1\", \"context2\", \"context3\", \"context4\"]\n",
    "question_column = \"question\"\n",
    "answer_column = \"answer\"\n",
    "\n",
    "config_json = {\n",
    "            \"configuration\": {\n",
    "                \"context_columns\": context_columns,\n",
    "                \"question_column\": question_column,\n",
    "                \"scoring_fn\": scoring_fn,\n",
    "                \"record_level\": True,\n",
    "                LLMTextMetricGroup.RAG.value: {\n",
    "                        LLMRAGMetrics.RETRIEVAL_QUALITY.value: {\n",
    "                            # RetrievalQualityMetric.CONTEXT_RELEVANCE.value: {\n",
    "                                #\"record_level\": True,\n",
    "                                #\"metric_prompt_template\": \"\"\n",
    "                            #}\n",
    "                            # RetrievalQualityMetric.RETRIEVAL_PRECISION.value: {},\n",
    "                            # RetrievalQualityMetric.AVERAGE_PRECISION.value: {},\n",
    "                            # RetrievalQualityMetric.RECIPROCAL_RANK.value: {},\n",
    "                            # RetrievalQualityMetric.HIT_RATE.value: {},\n",
    "                            # RetrievalQualityMetric.NDCG.value: {}\n",
    "                        },\n",
    "                        LLMCommonMetrics.FAITHFULNESS.value: {\n",
    "                            #\"record_level\": True,\n",
    "                            #\"metric_prompt_template\": \"\"\n",
    "                        },\n",
    "                        LLMCommonMetrics.ANSWER_RELEVANCE.value: {\n",
    "                            #\"record_level\": True,\n",
    "                            #\"metric_prompt_template\": \"\"\n",
    "                        },\n",
    "                        LLMCommonMetrics.ANSWER_SIMILARITY.value: {\n",
    "                            #\"record_level\": True,\n",
    "                            #\"metric_prompt_template\": \"\"\n",
    "                        }\n",
    "                }\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d2879",
   "metadata": {
    "id": "180bba35-afc7-40a2-ad38-c66fc5201e04"
   },
   "source": [
    "### Create the input, output and reference data frames and send them as input to compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "436c949c",
   "metadata": {
    "id": "ca083bc0-8b84-4f7f-ac0e-3a2d56b70a6b"
   },
   "outputs": [],
   "source": [
    "df_input = pd.DataFrame(data, columns=context_columns+[question_column])\n",
    "df_output = pd.DataFrame(data, columns=[answer_column])\n",
    "df_reference = pd.DataFrame(data, columns=[answer_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d126ea-7429-4f8e-961b-8ebabae26a2d",
   "metadata": {},
   "source": [
    "## Step 6 - Compute Retrieval and Answer Quality metrics <a id=\"compute\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2acad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer_relevance\": {\n",
      "    \"metric_value\": 0.7667,\n",
      "    \"mean\": 0.7667,\n",
      "    \"min\": 0.6,\n",
      "    \"max\": 1.0,\n",
      "    \"total_records\": 6,\n",
      "    \"record_level_metrics\": [\n",
      "      {\n",
      "        \"answer_relevance\": 0.8,\n",
      "        \"record_id\": \"98ff8481-3330-4e85-ba97-904084e7c6b9\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_relevance\": 0.8,\n",
      "        \"record_id\": \"5e75f578-7d83-46c3-a028-79d3b5ba7f7a\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_relevance\": 0.8,\n",
      "        \"record_id\": \"b5a19265-6ae1-4c86-a03d-43be150190a8\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_relevance\": 1.0,\n",
      "        \"record_id\": \"75b70936-72f8-4359-9ab9-c7023b5ab54d\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_relevance\": 0.6,\n",
      "        \"record_id\": \"5b688272-baaf-40a2-a273-1833aaaba1d9\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_relevance\": 0.6,\n",
      "        \"record_id\": \"5dafe740-5635-473a-9d7f-1bfc08fd1ca7\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"answer_similarity\": {\n",
      "    \"metric_value\": 0.8,\n",
      "    \"mean\": 0.8,\n",
      "    \"min\": 0.6,\n",
      "    \"max\": 1.0,\n",
      "    \"total_records\": 6,\n",
      "    \"record_level_metrics\": [\n",
      "      {\n",
      "        \"answer_similarity\": 1.0,\n",
      "        \"record_id\": \"98ff8481-3330-4e85-ba97-904084e7c6b9\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_similarity\": 0.6,\n",
      "        \"record_id\": \"5e75f578-7d83-46c3-a028-79d3b5ba7f7a\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_similarity\": 0.6,\n",
      "        \"record_id\": \"b5a19265-6ae1-4c86-a03d-43be150190a8\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_similarity\": 1.0,\n",
      "        \"record_id\": \"75b70936-72f8-4359-9ab9-c7023b5ab54d\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_similarity\": 0.6,\n",
      "        \"record_id\": \"5b688272-baaf-40a2-a273-1833aaaba1d9\"\n",
      "      },\n",
      "      {\n",
      "        \"answer_similarity\": 1.0,\n",
      "        \"record_id\": \"5dafe740-5635-473a-9d7f-1bfc08fd1ca7\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"faithfulness\": {\n",
      "    \"metric_value\": 0.8,\n",
      "    \"mean\": 0.8,\n",
      "    \"min\": 0.6,\n",
      "    \"max\": 1.0,\n",
      "    \"total_records\": 6,\n",
      "    \"record_level_metrics\": [\n",
      "      {\n",
      "        \"record_id\": \"98ff8481-3330-4e85-ba97-904084e7c6b9\",\n",
      "        \"faithfulness\": 1.0,\n",
      "        \"faithfulness_attributions\": []\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"5e75f578-7d83-46c3-a028-79d3b5ba7f7a\",\n",
      "        \"faithfulness\": 0.6,\n",
      "        \"faithfulness_attributions\": []\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"b5a19265-6ae1-4c86-a03d-43be150190a8\",\n",
      "        \"faithfulness\": 1.0,\n",
      "        \"faithfulness_attributions\": []\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"75b70936-72f8-4359-9ab9-c7023b5ab54d\",\n",
      "        \"faithfulness\": 1.0,\n",
      "        \"faithfulness_attributions\": []\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"5b688272-baaf-40a2-a273-1833aaaba1d9\",\n",
      "        \"faithfulness\": 0.6,\n",
      "        \"faithfulness_attributions\": []\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"5dafe740-5635-473a-9d7f-1bfc08fd1ca7\",\n",
      "        \"faithfulness\": 0.6,\n",
      "        \"faithfulness_attributions\": []\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"retrieval_quality\": {\n",
      "    \"context_relevance\": {\n",
      "      \"metric_value\": 0.2,\n",
      "      \"mean\": 0.2,\n",
      "      \"min\": 0.2,\n",
      "      \"max\": 0.2,\n",
      "      \"total_records\": 6\n",
      "    },\n",
      "    \"reciprocal_rank\": {\n",
      "      \"metric_value\": 0.0,\n",
      "      \"mean\": 0.0,\n",
      "      \"min\": 0,\n",
      "      \"max\": 0\n",
      "    },\n",
      "    \"retrieval_precision\": {\n",
      "      \"metric_value\": 0.0,\n",
      "      \"mean\": 0.0,\n",
      "      \"min\": 0.0,\n",
      "      \"max\": 0.0\n",
      "    },\n",
      "    \"average_precision\": {\n",
      "      \"metric_value\": 0.0,\n",
      "      \"mean\": 0.0,\n",
      "      \"min\": 0,\n",
      "      \"max\": 0\n",
      "    },\n",
      "    \"hit_rate\": {\n",
      "      \"metric_value\": 0.0,\n",
      "      \"mean\": 0.0,\n",
      "      \"min\": 0,\n",
      "      \"max\": 0\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "      \"metric_value\": 1.0,\n",
      "      \"mean\": 1.0,\n",
      "      \"min\": 1.0,\n",
      "      \"max\": 1.0\n",
      "    },\n",
      "    \"record_level_metrics\": [\n",
      "      {\n",
      "        \"record_id\": \"98ff8481-3330-4e85-ba97-904084e7c6b9\",\n",
      "        \"context_relevance\": 0.2,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.0,\n",
      "        \"average_precision\": 0,\n",
      "        \"reciprocal_rank\": 0,\n",
      "        \"hit_rate\": 0,\n",
      "        \"ndcg\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"5e75f578-7d83-46c3-a028-79d3b5ba7f7a\",\n",
      "        \"context_relevance\": 0.2,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.0,\n",
      "        \"average_precision\": 0,\n",
      "        \"reciprocal_rank\": 0,\n",
      "        \"hit_rate\": 0,\n",
      "        \"ndcg\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"b5a19265-6ae1-4c86-a03d-43be150190a8\",\n",
      "        \"context_relevance\": 0.2,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.0,\n",
      "        \"average_precision\": 0,\n",
      "        \"reciprocal_rank\": 0,\n",
      "        \"hit_rate\": 0,\n",
      "        \"ndcg\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"75b70936-72f8-4359-9ab9-c7023b5ab54d\",\n",
      "        \"context_relevance\": 0.2,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.0,\n",
      "        \"average_precision\": 0,\n",
      "        \"reciprocal_rank\": 0,\n",
      "        \"hit_rate\": 0,\n",
      "        \"ndcg\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"5b688272-baaf-40a2-a273-1833aaaba1d9\",\n",
      "        \"context_relevance\": 0.2,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.0,\n",
      "        \"average_precision\": 0,\n",
      "        \"reciprocal_rank\": 0,\n",
      "        \"hit_rate\": 0,\n",
      "        \"ndcg\": 1.0\n",
      "      },\n",
      "      {\n",
      "        \"record_id\": \"5dafe740-5635-473a-9d7f-1bfc08fd1ca7\",\n",
      "        \"context_relevance\": 0.2,\n",
      "        \"context_relevances\": {\n",
      "          \"context_columns\": [\n",
      "            \"context1\",\n",
      "            \"context2\",\n",
      "            \"context3\",\n",
      "            \"context4\"\n",
      "          ],\n",
      "          \"context_relevances\": [\n",
      "            0.2\n",
      "          ]\n",
      "        },\n",
      "        \"retrieval_precision\": 0.0,\n",
      "        \"average_precision\": 0,\n",
      "        \"reciprocal_rank\": 0,\n",
      "        \"hit_rate\": 0,\n",
      "        \"ndcg\": 1.0\n",
      "      }\n",
      "    ],\n",
      "    \"total_records\": 6\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "metrics_result = client.llm_metrics.compute_metrics(config_json, \n",
    "                                                    sources=df_input, \n",
    "                                                    predictions=df_output,\n",
    "                                                    references=df_reference)\n",
    "\n",
    "print(json.dumps(metrics_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32268ba-56ec-43d6-a91d-97c9d59105b5",
   "metadata": {},
   "source": [
    "## Step 7 - Display the results <a id=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dca741-bc78-4550-a5e7-cd33e068e562",
   "metadata": {},
   "source": [
    "### Get metric results for all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551cc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context1</th>\n",
       "      <th>context2</th>\n",
       "      <th>context3</th>\n",
       "      <th>context4</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_similarity</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_relevance</th>\n",
       "      <th>retrieval_precision</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>reciprocal_rank</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last month, I announced our plan to supercharg...</td>\n",
       "      <td>For that purpose we’ve mobilized American grou...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>But cancer from prolonged exposure to burn pit...</td>\n",
       "      <td>What is ARPA-H?</td>\n",
       "      <td>ARPA-H is the Advanced Research Projects Agen...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>What is the investment of Ford and GM to build...</td>\n",
       "      <td>Ford is investing $11 billion to build electr...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My plan will cut the cost in half for most fam...</td>\n",
       "      <td>We got more than 130 countries to agree on a g...</td>\n",
       "      <td>And unlike the $2 Trillion tax cut passed in t...</td>\n",
       "      <td>We’re going after the criminals who stole bill...</td>\n",
       "      <td>What is the proposed tax rate for corporations?</td>\n",
       "      <td>The proposed tax rate for corporations is a 1...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>What is Intel going to build?</td>\n",
       "      <td>Intel is going to build a $20 billion semicon...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>When we use taxpayer dollars to rebuild Americ...</td>\n",
       "      <td>As Ohio Senator Sherrod Brown says, “It’s time...</td>\n",
       "      <td>How many new manufacturing jobs are created la...</td>\n",
       "      <td>369,000 new manufacturing jobs are created la...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>So let’s not wait any longer. Send it to my de...</td>\n",
       "      <td>If you travel 20 miles east of Columbus, Ohio,...</td>\n",
       "      <td>It is going to transform America and put us on...</td>\n",
       "      <td>Vice President Harris and I ran for office wit...</td>\n",
       "      <td>How many electric vehicle charging stations ar...</td>\n",
       "      <td>The document does not provide information on ...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            context1  \\\n",
       "0  Last month, I announced our plan to supercharg...   \n",
       "1  So let’s not wait any longer. Send it to my de...   \n",
       "2  My plan will cut the cost in half for most fam...   \n",
       "3  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "4  So let’s not wait any longer. Send it to my de...   \n",
       "5  So let’s not wait any longer. Send it to my de...   \n",
       "\n",
       "                                            context2  \\\n",
       "0  For that purpose we’ve mobilized American grou...   \n",
       "1  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "2  We got more than 130 countries to agree on a g...   \n",
       "3  So let’s not wait any longer. Send it to my de...   \n",
       "4  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "5  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "\n",
       "                                            context3  \\\n",
       "0  If you travel 20 miles east of Columbus, Ohio,...   \n",
       "1  When we use taxpayer dollars to rebuild Americ...   \n",
       "2  And unlike the $2 Trillion tax cut passed in t...   \n",
       "3  When we use taxpayer dollars to rebuild Americ...   \n",
       "4  When we use taxpayer dollars to rebuild Americ...   \n",
       "5  It is going to transform America and put us on...   \n",
       "\n",
       "                                            context4  \\\n",
       "0  But cancer from prolonged exposure to burn pit...   \n",
       "1  It is going to transform America and put us on...   \n",
       "2  We’re going after the criminals who stole bill...   \n",
       "3  It is going to transform America and put us on...   \n",
       "4  As Ohio Senator Sherrod Brown says, “It’s time...   \n",
       "5  Vice President Harris and I ran for office wit...   \n",
       "\n",
       "                                            question  \\\n",
       "0                                    What is ARPA-H?   \n",
       "1  What is the investment of Ford and GM to build...   \n",
       "2    What is the proposed tax rate for corporations?   \n",
       "3                      What is Intel going to build?   \n",
       "4  How many new manufacturing jobs are created la...   \n",
       "5  How many electric vehicle charging stations ar...   \n",
       "\n",
       "                                              answer  answer_relevance  \\\n",
       "0   ARPA-H is the Advanced Research Projects Agen...               0.8   \n",
       "1   Ford is investing $11 billion to build electr...               0.8   \n",
       "2   The proposed tax rate for corporations is a 1...               0.8   \n",
       "3   Intel is going to build a $20 billion semicon...               1.0   \n",
       "4   369,000 new manufacturing jobs are created la...               0.6   \n",
       "5   The document does not provide information on ...               0.6   \n",
       "\n",
       "   answer_similarity  faithfulness  context_relevance  retrieval_precision  \\\n",
       "0                1.0           1.0                0.2                  0.0   \n",
       "1                0.6           0.6                0.2                  0.0   \n",
       "2                0.6           1.0                0.2                  0.0   \n",
       "3                1.0           1.0                0.2                  0.0   \n",
       "4                0.6           0.6                0.2                  0.0   \n",
       "5                1.0           0.6                0.2                  0.0   \n",
       "\n",
       "   average_precision  reciprocal_rank  hit_rate  ndcg  \n",
       "0                  0                0         0   1.0  \n",
       "1                  0                0         0   1.0  \n",
       "2                  0                0         0   1.0  \n",
       "3                  0                0         0   1.0  \n",
       "4                  0                0         0   1.0  \n",
       "5                  0                0         0   1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = data.copy()\n",
    "\n",
    "for metric_name, metric_data in metrics_result.items():\n",
    "    vals = {}\n",
    "    if \"record_level_metrics\" in metric_data:\n",
    "        for rm in metric_data[\"record_level_metrics\"]:\n",
    "            for m, mv in rm.items():\n",
    "                if m != \"record_id\" and m!= \"faithfulness_attributions\" and m!= \"context_relevances\":  # Excluding columns\n",
    "                    if m in vals:\n",
    "                        vals[m].append(mv)\n",
    "                    else:\n",
    "                        vals[m] = [mv]\n",
    "\n",
    "    if vals:\n",
    "        for k, v in vals.items():\n",
    "            results_df[k] = v\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a5d46-b78e-4945-878e-53dd4b5936ba",
   "metadata": {},
   "source": [
    "Author: <a href=\"mailto:pvemulam@in.ibm.com\">Pratap Kishore Varma V</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01751f16",
   "metadata": {},
   "source": [
    "Copyright © 2024 IBM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
