{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc855a34-bbed-4a93-adbd-b59c0bab8b12",
   "metadata": {},
   "source": [
    "# Using IBM watsonx.governance metrics toolkit to assess the risk of a foundation model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dc2e579-4258-492c-be1f-df8157ad8347",
   "metadata": {},
   "source": [
    "\n",
    "This notebook should be run using Python 3.10.\n",
    "\n",
    "The notebook evaluates the risk associated with the given foundation model. The risk assessment result could be stored in OpenPages or exported as a pdf file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b2e99-1ca1-4e13-8140-186b48d5ef7f",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- Setup\n",
    "- Configure credentials \n",
    "- Evaluate the risks for a FM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4390693-5a86-4971-962c-965b295555c7",
   "metadata": {},
   "source": [
    "## Setup <a name=\"settingup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc3415",
   "metadata": {},
   "source": [
    "### Replace your username and artifactory token below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dac475-4ed8-4246-81bd-642482817710",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ibm-metrics-plugin[mra] --extra-index-url https://@USERNAME@:@PASSWORD@@na.artifactory.swg-devops.com/artifactory/api/pypi/wcp-aiopenscale-pypi-virtual/simple \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b2260-76ff-4a5c-9dda-3663ad8133a5",
   "metadata": {},
   "source": [
    "Note: you may need to restart the kernel to use updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa80606d",
   "metadata": {},
   "source": [
    "If you want to evaluate the risks against watsonx.ai model then you must provide CPD or Cloud credentials in the system_credentials below. For evaluating the risk of external LLM, a wrapper scoring function is required, a sample wrapper scoring function is provided later in the notebook.\n",
    "\n",
    "\n",
    "The computed metrics can be displayed in cell output as json or table format. The computed metrics can also be saved to OpenPages; this will prevent the metrics from being computed again the next time you run evaluation; instead it will retrieve the saved metrics from OpenPages. \n",
    "\n",
    "If you want to store metrics to OpenPages then you must provide CPD or Cloud credentials in the system_credentials below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210933df-afce-44c0-a445-e3d2a59fcd42",
   "metadata": {},
   "source": [
    "## Credentials Details:\n",
    "\n",
    "\n",
    "#### Below are the inputs for the API:\n",
    "\n",
    "| API input       | Expected value | optional/required| \n",
    "|------------|-----|-----|\n",
    "| foundation_model_name      | Specifies the name of the foundation model under evaluation.|Required | \n",
    "| system_credentials      | Contains necessary details to connect to OpenPages, and IBM watsonx.ai. |Required | \n",
    "| risk_dimensions      |  List of risks to be evaluated. |Required | \n",
    "| scoring_function      |  Function that encapsulates all logic to infer external LLM. |Optional | \n",
    "\n",
    "#### Below are system_credentials dictionary keys definitions:\n",
    "| Dictionary key       | Expected dictionary value |  optional/required| \n",
    "|------------|-----|-----|\n",
    "| op_url      |  Wx.gov Software URL>/openpages-openpagesinstance-cr-grc  | Optional | \n",
    "| op_username      | OpenPages cloud instance username  |Optional  | \n",
    "| op_password      | OpenPages cloud instance password  |Optional | \n",
    "| op_model_name      | OpenPages FM Model ID to which metrics needs to be published  |Optional | \n",
    "| op_cpd_host      | Your CPD or wx.gov Software URL - without https:// |Optional | \n",
    "| op_cpd_apikey      | CPD apikey for OpenPages  |Optional | \n",
    "| watsonx_ai_cloud_apikey      | Your cloud apikey for Wastonx.ai |Required (if you do not provide scoring function for external LLM )| \n",
    "| watsonx_ai_project_id      | Project id for inference against the watsonx.ai model  |Required (if you do not provide scoring function for external LLM ) | \n",
    "| watsonx_ai_endpoint_url      | Cloud Software URL for Wastonx.ai  |Required (if you do not provide scoring function external for LLM ) | \n",
    "| watsonx_ai_cpd_username      | Your CPD username for Wastonx.ai |Required (if you do not provide scoring function external for LLM ) | \n",
    "| watsonx_ai_cpd_apikey      | Your CPD api key for Wastonx.ai  |Required (if you do not provide scoring function external for LLM ) | \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd538972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OP_URL = \"<EDIT THIS>\"\n",
    "OP_USERNAME = \"<EDIT THIS>\"\n",
    "OP_PASSWORD = \"<EDIT THIS>\"\n",
    "OP_MODEL_NAME = \"<EDIT THIS>\"\n",
    "OP_HOST = \"<EDIT THIS>\"\n",
    "OP_APIKEY = \"<EDIT THIS>\"\n",
    "\n",
    "CLOUD_APIKEY = \"<EDIT THIS>\"\n",
    "PROJECT_ID = \"<EDIT THIS>\"\n",
    "ENDPOINT_URL = \"<EDIT THIS>\"\n",
    "CPD_USERNAME= \"<EDIT THIS>\"\n",
    "CPD_APIKEY = \"<EDIT THIS>\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Set this variable to the Wastonx.ai model name ex:google/flan-t5-xxl\n",
    "# if evaluating the risk of external LLM set variable to the FM under evaluation.\n",
    "foundation_model_name = \"<EDIT THIS>\"\n",
    "\n",
    "#list of the supported risks = ['exposing-personal-information', 'hallucination', 'output-bias', 'revealing-confidential-information']\n",
    "risk_dimensions =  \"<EDIT THIS>\"\n",
    "\n",
    "\n",
    "#scoring_function: For evaluating the risk of external LLM,\n",
    "#you can find a sample scoring function below, set this variable to the scoring_function name; else to None\n",
    "scoring_function = None\n",
    "\n",
    "\n",
    "#This setup will access wastonx.ai using Cloud\n",
    "system_credentials = {\n",
    "    \"watsonx_ai_cloud_apikey\": CLOUD_APIKEY,\n",
    "    \"watsonx_ai_endpoint_url\": ENDPOINT_URL,\n",
    "    \"watsonx_ai_project_id\": PROJECT_ID,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# uncomment to access wastonx.ai using CPD\n",
    "# system_credentials = {\n",
    "#     \"watsonx_ai_endpoint_url\": ENDPOINT_URL,\n",
    "#     \"watsonx_ai_project_id\": PROJECT_ID,\n",
    "#     \"watsonx_ai_cpd_username\": CPD_USERNAME,\n",
    "#     \"watsonx_ai_cpd_apikey\": CPD_APIKEY,\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# uncomment below step if the result should be pushed to openpages using CPD\n",
    "# system_credentials.update({\n",
    "#     \"op_cpd_host\": OP_HOST,\n",
    "#     \"op_username\": OP_USERNAME,\n",
    "#     \"op_password\": OP_PASSWORD, \n",
    "#     \"op_cpd_apikey\": OP_APIKEY,  \n",
    "#     \"op_model_name\": OP_MODEL_NAME,\n",
    "#     \"op_url\": OP_URL\n",
    "# })\n",
    "\n",
    "\n",
    "# uncomment below step if the result should be pushed to openpages using Cloud\n",
    "# system_credentials.update({\n",
    "#     \"op_username\": OP_USERNAME,\n",
    "#     \"op_password\": OP_PASSWORD, \n",
    "#     \"op_model_name\": OP_MODEL_NAME,\n",
    "#     \"op_url\": OP_URL\n",
    "# })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbe8ca-baa6-4c6d-8724-d0ea5f05654a",
   "metadata": {},
   "source": [
    "### Scoring function\n",
    "For evaluating the risk of external LLM, a wrapper scoring function is required. The scoring function takes the prompts as input and return the model predictions. a sample scoring function is provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a6329-c012-4e8a-8924-41507ce75479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install SentencePiece\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "# import pandas as pd\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\")\n",
    "\n",
    "\n",
    "# def sample_scoring_function(data):\n",
    "#     predictions_list = []\n",
    "#     print(\"working\")\n",
    "#     for prompt_text in data.iloc[:, 0].values.tolist():\n",
    "#         input_ids = tokenizer(prompt_text, return_tensors=\"pt\").input_ids\n",
    "#         output = model.generate(input_ids)\n",
    "#         output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "#         predictions_list.append(output)\n",
    "#     return pd.DataFrame({\"generated_text\": predictions_list})\n",
    "\n",
    "\n",
    "# scoring_function = sample_scoring_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe49c3-1b97-44e6-bb87-03a32e1da5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_metrics_plugin.mra.evaluate_fm_risk import EvaluateFMRisk\n",
    "from ibm_wos_utils.joblib.utils.notebook_utils import  create_download_link_for_file\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "!python -m nltk.downloader stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d706bf",
   "metadata": {},
   "source": [
    "### Evaluate the risks for a FM and show the computed metrics as JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "077f8ae2-aef7-4264-9c3e-49fc4101fd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ed0981c38a47b9b636e5a6f4ee4dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683efb4fa1eb4dc281d611f1c40c1d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hallucination': {'cards.value_alignment.hallucinations.truthfulqa': {'score_name': 'rougeL', 'score': 0.151, 'num_of_instances': 50, 'counts': 26.0, 'totals': 380.0, 'precisions': 0.062, 'bp': 0.863, 'sys_len': 455, 'ref_len': 522, 'sacrebleu': 0.039, 'score_ci_low': 0.112, 'score_ci_high': 0.218, 'sacrebleu_ci_low': 0.021, 'sacrebleu_ci_high': 0.081, 'rougeLsum': 0.151, 'rouge2': 0.053, 'rougeL': 0.151, 'rouge1': 0.16, 'rougeLsum_ci_low': 0.112, 'rougeLsum_ci_high': 0.218, 'rouge2_ci_low': 0.023, 'rouge2_ci_high': 0.12, 'rougeL_ci_low': 0.112, 'rougeL_ci_high': 0.218, 'rouge1_ci_low': 0.119, 'rouge1_ci_high': 0.226}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fm_evaluate = EvaluateFMRisk(\n",
    "    system_credentials=system_credentials,\n",
    "    foundation_model_name=foundation_model_name,\n",
    "    risk_dimensions=risk_dimensions,\n",
    "    scoring_function=scoring_function,\n",
    ")\n",
    "\n",
    "risks_metrics_results = fm_evaluate.evaluate_fm_risks()\n",
    "print(risks_metrics_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4ff56",
   "metadata": {},
   "source": [
    "### Show the computed metrics in a table format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d6170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hallucination\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric Name</th>\n",
       "      <th>cards.value_alignment.hallucinations.truthfulqa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bp</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>counts</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_of_instances</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>precisions</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ref_len</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rouge1_ci_high</td>\n",
       "      <td>0.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rouge1_ci_low</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rouge2_ci_high</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rouge2_ci_low</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rougeL_ci_high</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rougeL_ci_low</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rougeLsum</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rougeLsum_ci_high</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rougeLsum_ci_low</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sacrebleu</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sacrebleu_ci_high</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sacrebleu_ci_low</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>score</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>score_ci_high</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>score_ci_low</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>score_name</td>\n",
       "      <td>rougeL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sys_len</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>totals</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Metric Name cards.value_alignment.hallucinations.truthfulqa\n",
       "0                  bp                                           0.863\n",
       "1              counts                                            26.0\n",
       "2    num_of_instances                                              50\n",
       "3          precisions                                           0.062\n",
       "4             ref_len                                             522\n",
       "5              rouge1                                            0.16\n",
       "6      rouge1_ci_high                                           0.226\n",
       "7       rouge1_ci_low                                           0.119\n",
       "8              rouge2                                           0.053\n",
       "9      rouge2_ci_high                                            0.12\n",
       "10      rouge2_ci_low                                           0.023\n",
       "11             rougeL                                           0.151\n",
       "12     rougeL_ci_high                                           0.218\n",
       "13      rougeL_ci_low                                           0.112\n",
       "14          rougeLsum                                           0.151\n",
       "15  rougeLsum_ci_high                                           0.218\n",
       "16   rougeLsum_ci_low                                           0.112\n",
       "17          sacrebleu                                           0.039\n",
       "18  sacrebleu_ci_high                                           0.081\n",
       "19   sacrebleu_ci_low                                           0.021\n",
       "20              score                                           0.151\n",
       "21      score_ci_high                                           0.218\n",
       "22       score_ci_low                                           0.112\n",
       "23         score_name                                          rougeL\n",
       "24            sys_len                                             455\n",
       "25             totals                                           380.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for risk_name, risks_metrics in risks_metrics_results.items():\n",
    "    df = pd.DataFrame.from_dict(risks_metrics)\n",
    "    df = df.reset_index().rename(columns={\"index\":\"Metric Name\"})\n",
    "    print(risk_name)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e62f8f",
   "metadata": {},
   "source": [
    "### Export the computed metrics to PDF report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##uncomment if running the notebook on studio:\n",
    "#import os\n",
    "#current_directory = os.getcwd()\n",
    "#output_path = current_directory\n",
    "\n",
    "#output_path is where the pdf file will be saved \n",
    "output_path = \"<EDIT THIS>\"\n",
    "\n",
    "\n",
    "\n",
    "pdf_path = fm_evaluate.get_pdf_report(risks_metrics_results, output_path)\n",
    "pdf_file = create_download_link_for_file(pdf_path)\n",
    "display((pdf_file))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venvmra_v2e)",
   "language": "python",
   "name": "venv_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
