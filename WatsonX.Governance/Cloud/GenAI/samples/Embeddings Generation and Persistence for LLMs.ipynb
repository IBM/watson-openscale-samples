{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Generation and Persistence for LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to generate embeddings for a given data.\n",
    "\n",
    "#### Contents\n",
    "\n",
    "**Contents:**\n",
    "1. [Setting up the environment](#setting-up-the-environment) - Pre-requisites: Install Libraries and required dependencies\n",
    "2. [Input Data](#Input-Data) - Read the training data as a pandas DataFrame\n",
    "3. [User Inputs Section](#user-inputs-section) - Provide Model Details, IBM watsonx.governance Services and their configuration\n",
    "4. [Generate Embeddings](#generate-embeddings)\n",
    "5. [Optional: Configure Drift v2](#optional-configure-drift-v2)\n",
    "6. [Optional: Store Runtime Records with Embeddings](#optional-store-runtime-records-with-embeddings)\n",
    "7. [Optional: Evaluate Drift v2 monitor](#optional-evaluate-drift-v2-monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n",
    "\n",
    "**Installing required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade \"ibm-metrics-plugin[notebook]~=3.0.0\" \"ibm-watson-openscale~=3.0.36\" \"ibm-watsonx-ai~=1.1.6\" | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------\n",
    "# IBM Confidential\n",
    "# OCO Source Materials\n",
    "# 5900-A3Q, 5737-H76\n",
    "# Copyright IBM Corp. 2024\n",
    "# The source code for this Notebook is not published or other-wise divested of its trade \n",
    "# secrets, irrespective of what has been deposited with the U.S.Copyright Office.\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "VERSION = \"1.0\"\n",
    "\n",
    "#Version History\n",
    "#1.0: Initial release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson_openscale import APIClient\n",
    "from ibm_watson_openscale.utils.embeddings_generation_utility import \\\n",
    "    EmbeddingsGenerationUtility\n",
    "from ibm_watson_openscale.utils.drift_v2_utility import DriftV2Utility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data\n",
    "\n",
    "The notebook supports two modes:\n",
    "1. Fetch dataset records from WatsonX.Governance.\n",
    "1. Read the input scored data as a pandas dataframe. Although the sample here reads a CSV file into a dataframe, this could be a table, etc.\n",
    "1. The input scored data should contain the following columns:\n",
    "    - The feature _aka_ prompt variable columns\n",
    "    - The model output/prediction _aka_ generated text column\n",
    "    - Optional: The meta columns\n",
    "    - Optional: The input token count column\n",
    "    - Optional: The output token count column\n",
    "    - Optional: The prediction probability column\n",
    "\n",
    "*Note: Pandas' read\\_csv method converts the columns to its data types. If you want the column type to not be interpreted, specify the dtype param to read_csv method in this cell. More on this method [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "\n",
    "# Uncomment these lines if you want to compute and store embeddings for local data\n",
    "# df = pd.read_csv(\"TO BE EDITED\")\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs Section\n",
    "\n",
    "##### _1. Provide watsonx.governance parameters_:\n",
    "\n",
    "Provide the watsonx.governance parameters - the api key, and the subscription id.\n",
    "\n",
    "##### _2. Provide an embedding function_\n",
    "\n",
    "The embedding function should adhere to the following guidelines.\n",
    "\n",
    "- The input of the embedding function should accept a `list`.\n",
    "- The output of the embedding function should return a `list` comprising of the embeddings for all the inputs.\n",
    "\n",
    "A few samples of the embedding function have been provided [here](https://github.com/IBM/watson-openscale-samples/wiki/Embedding-Function-Templates-for-unstructured-text-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUD_API_KEY = \"TO BE EDITED\"\n",
    "\n",
    "subscription_id = \"TO BE EDITED\"\n",
    "\n",
    "def embeddings_fn(inputs):\n",
    "    from ibm_watsonx_ai import Credentials, APIClient\n",
    "    from ibm_watsonx_ai.foundation_models import Embeddings\n",
    "    from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames \n",
    "    \n",
    "    # from time import time\n",
    "    # start_time = time()\n",
    "\n",
    "    API_KEY = \"TO BE EDITED\"\n",
    "    WX_URL = \"https://us-south.ml.cloud.ibm.com\"\n",
    "    PROJECT_ID = \"TO BE EDITED\"\n",
    "\n",
    "    credentials = Credentials(\n",
    "        url = WX_URL,\n",
    "        api_key = API_KEY\n",
    "    )\n",
    "\n",
    "    client = APIClient(credentials, project_id=PROJECT_ID)\n",
    "    # client.foundation_models.EmbeddingModels.show()\n",
    "    embedding = Embeddings(\n",
    "        model_id=client.foundation_models.EmbeddingModels.ALL_MINILM_L12_V2,\n",
    "        api_client=client,\n",
    "        params={\n",
    "            EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 128\n",
    "        }\n",
    "    )\n",
    "    result = embedding.embed_documents(texts=inputs)\n",
    "    # print(f\"Got embeddings of {len(inputs)} inputs in {time() - start_time}s.\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "\n",
    "authenticator = IAMAuthenticator(apikey=CLOUD_API_KEY, url=\"https://iam.cloud.ibm.com\")\n",
    "wos_client = APIClient(authenticator=authenticator, service_url=\"https://aiopenscale.cloud.ibm.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and persist embeddings\n",
    "\n",
    "Generate the embeddings and persist them in watsonx.governance. Use `embeddings_chunk_size` to control, how many records are sent to the `embeddings_fn` at a given time.\n",
    "\n",
    "The `compute_and_store_embeddings` method takes the following arguments:\n",
    "1. `embeddings_fn` : The embeddings function to generate embeddings\n",
    "2. `embeddings_chunk_size`: The maximum number of records with which to call the embeddings function.\n",
    "3. `scored_data`: The pandas dataframe containing the scored data with at least the prompt variables and the generated text. This is to be given, when a dataframe is to be uploaded along with embeddings\n",
    "4. `start`, `end`: The time interval which is used to read the payload records. \n",
    "5. `force`: If `force` is set to `True`, all the records between the above timestamps are read. If `force` is set to `False`, only the payload records, which do not contain embeddings are read.\n",
    "6. `limit`: The `limit` controls how many records will be read for generating embeddings in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381a50694d204c7b9b3ab7d6cd1c0860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading payload_logging records... :   0%|          | 0/1000 [00:00<?, ?records/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797230d9c5514ab7ad6d389b406dfdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing embeddings... :   0%|          | 0/7000 [00:00<?, ?values/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09fd02085b74326b28c80c83fc2318b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Storing embeddings... :   0%|          | 0/1000 [00:00<?, ?records/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_util = EmbeddingsGenerationUtility(client=wos_client, subscription_id=subscription_id)\n",
    "\n",
    "baseline_df = embedding_util.compute_and_store_embeddings(start=datetime(2024, 7, 23, 18, 1),\n",
    "                                            end=datetime(2024, 7, 25, 18, 2),\n",
    "                                            embeddings_fn=embeddings_fn,\n",
    "                                            embeddings_chunk_size=500,\n",
    "                                            limit=1000,\n",
    "                                            force=True)\n",
    "\n",
    "# Use this snippet, if the local data has been read in dataframe\n",
    "# baseline_df = embedding_util.compute_and_store_embeddings(scored_data=df,\n",
    "#                                             embeddings_fn=embeddings_fn,\n",
    "#                                             embeddings_chunk_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   question                                   1000 non-null   object \n",
      " 1   scoring_id                                 1000 non-null   object \n",
      " 2   scoring_timestamp                          1000 non-null   object \n",
      " 3   context_column_2                           1000 non-null   object \n",
      " 4   prediction_probability                     1000 non-null   float64\n",
      " 5   context_column_1                           1000 non-null   object \n",
      " 6   generated_text                             1000 non-null   object \n",
      " 7   context_column_3                           1000 non-null   object \n",
      " 8   input_token_count                          1000 non-null   int64  \n",
      " 9   type                                       1000 non-null   object \n",
      " 10  generated_token_count                      1000 non-null   int64  \n",
      " 11  level                                      1000 non-null   object \n",
      " 12  wos_feature_context_column_1_embeddings__  1000 non-null   object \n",
      " 13  wos_feature_context_column_2_embeddings__  1000 non-null   object \n",
      " 14  wos_feature_context_column_3_embeddings__  1000 non-null   object \n",
      " 15  wos_feature_question_embeddings__          1000 non-null   object \n",
      " 16  wos_input_embeddings__                     1000 non-null   object \n",
      " 17  wos_output_embeddings__                    1000 non-null   object \n",
      " 18  wos_context_embeddings__                   1000 non-null   object \n",
      "dtypes: float64(1), int64(2), object(16)\n",
      "memory usage: 148.6+ KB\n"
     ]
    }
   ],
   "source": [
    "baseline_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Configure Drift v2\n",
    "\n",
    "In the below cell, user can configure Drift v2 monitor by using the dataframe generated above with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subscription '64846065-a105-44f2-85ca-0510ca868056' has Drift v2 monitor configured with id 'f4d5eb97-c51c-4b3e-bf2e-2b5c4126f0b7'\n",
      "The utility will re-configure Drift v2.\n",
      "Generating Drift v2 Archive...\n",
      "{\"component_id\": \"metrics-plugin\", \"log_level\": \"WARNING\", \"message_details\": \"Disabling operations and insights for generated_text, Reason: The ratio of number of unique values [92] to the total count [100] is 0.92. Please adjust 'categorical_unique_threshold' [0.8] in advanced_controls.\", \"timestamp\": \"2024-07-25T03:29:15.724192Z\", \"logSourceCRN\": \"\", \"saveServiceCopy\": false, \"filename\": \"/usr/local/Cellar/python@3.11/3.11.9/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py\", \"method\": \"__step\", \"line_number\": \"277\", \"worker_id\": 8285, \"column\": \"generated_text\", \"drift_data_set_id\": \"c3496af4-171b-4b42-8d45-e8922c2cdfde\"}\n",
      "Baseline archive created at path:  /Users/prempiyush/work/code/notebooks/WatsonX.Governance/Cloud/GenAI/samples/baseline__c3496af4-171b-4b42-8d45-e8922c2cdfde.tar.gz\n",
      "Generated Drift v2 Archive in 0:00:04.688310...\n",
      "Uploading Drift v2 Archive...\n",
      "Uploaded Drift v2 Archive in 0:00:26.598470...\n",
      "Updating Drift v2 monitor...\n",
      "Updating Drift v2 monitor. state: active. Time elapsed: 0:00:01.888446...\n"
     ]
    }
   ],
   "source": [
    "drift_v2_utility = DriftV2Utility(client=wos_client, subscription_id=subscription_id)\n",
    "drift_v2_utility.configure(scored_data=baseline_df, embeddings_fn=embeddings_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Store Runtime Records with \n",
    "\n",
    "Read another scored data csv, to be persisted as runtime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   context_column_1        50 non-null     object \n",
      " 1   context_column_2        50 non-null     object \n",
      " 2   context_column_3        50 non-null     object \n",
      " 3   question                50 non-null     object \n",
      " 4   generated_text          50 non-null     object \n",
      " 5   prediction_probability  50 non-null     float64\n",
      " 6   input_token_count       50 non-null     int64  \n",
      " 7   generated_token_count   50 non-null     int64  \n",
      " 8   answer                  50 non-null     object \n",
      " 9   type                    50 non-null     object \n",
      " 10  level                   50 non-null     object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 4.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9bd6ef65574f98a1f4734738e6d901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Storing records... :   0%|          | 0/50 [00:00<?, ?records/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50dced866a41418f9b3a3ba31c8c0fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing embeddings... :   0%|          | 0/350 [00:00<?, ?values/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5324af584c82473ea4b674c1d80545a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Storing embeddings... :   0%|          | 0/50 [00:00<?, ?records/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runtime_df = pd.read_csv(\"TO BE EDITED\")\n",
    "print(runtime_df.info())\n",
    "\n",
    "embedding_util = EmbeddingsGenerationUtility(\n",
    "    client=wos_client, subscription_id=subscription_id)\n",
    "runtime_df = embedding_util.compute_and_store_embeddings(scored_data=runtime_df,\n",
    "                                                         embeddings_fn=embeddings_fn,\n",
    "                                                         embeddings_chunk_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Evaluate Drift v2 monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Drift v2 monitor...\n",
      "Running Drift v2 monitor. state: running. Time elapsed: 0:00:01.681804...\n",
      "Running Drift v2 monitor. state: running. Time elapsed: 0:00:12.594594...\n",
      "Running Drift v2 monitor. state: running. Time elapsed: 0:00:23.847397...\n",
      "Running Drift v2 monitor. state: running. Time elapsed: 0:00:34.770098...\n",
      "Running Drift v2 monitor. state: running. Time elapsed: 0:00:45.655135...\n",
      "Running Drift v2 monitor. state: running. Time elapsed: 0:00:56.578163...\n",
      "Running Drift v2 monitor. state: running. Time elapsed: 0:01:07.645539...\n",
      "Running Drift v2 monitor. state: running. Time elapsed: 0:01:18.518526...\n",
      "Running Drift v2 monitor. state: running. Time elapsed: 0:01:29.429359...\n",
      "Running Drift v2 monitor. state: running. Time elapsed: 0:01:40.339988...\n",
      "Running Drift v2 monitor. state: finished. Time elapsed: 0:01:51.278365...\n"
     ]
    }
   ],
   "source": [
    "drift_v2_utility = DriftV2Utility(client=wos_client, subscription_id=subscription_id)\n",
    "drift_v2_utility.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors\n",
    "Developed by [Prem Piyush Goyal](mailto:prempiyush@in.ibm.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
