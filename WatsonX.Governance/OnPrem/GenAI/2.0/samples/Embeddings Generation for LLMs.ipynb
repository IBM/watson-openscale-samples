{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Generation for LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to generate embeddings for a given data.\n",
    "\n",
    "#### Contents\n",
    "\n",
    "**Contents:**\n",
    "1. [Setting up the environment](#setting-up-the-environment)\n",
    "2. [Input Data](#Input-Data)\n",
    "3. [User Inputs Section](#user-inputs-section)\n",
    "4. [Generate Embeddings](#generate-embeddings)\n",
    "5. [Definitions](#definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n",
    "\n",
    "**Installing required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mdurl~=0.1 in /Users/soumyajyotibiswas/Desktop/Sample Notebooks/notebooks/notebooks_venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy~=3.7.4->ibm-metrics-plugin~=5.0.3->ibm-metrics-plugin[notebook]~=5.0.3) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade \"ibm-metrics-plugin[notebook]~=5.0.3\" \"sentence-transformers\" | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------\n",
    "# IBM Confidential\n",
    "# OCO Source Materials\n",
    "# 5900-A3Q, 5737-H76\n",
    "# Copyright IBM Corp. 2024\n",
    "# The source code for this Notebook is not published or other-wise divested of its trade \n",
    "# secrets, irrespective of what has been deposited with the U.S.Copyright Office.\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "VERSION = \"1.0\"\n",
    "\n",
    "#Version History\n",
    "#1.0: Initial release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from ibm_metrics_plugin.common.utils.embeddings_utils import compute_embeddings\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data\n",
    "\n",
    "Read the input data as a pandas dataframe. Although the sample here reads a CSV file into a dataframe, this could be a table, etc.\n",
    "\n",
    "*Note: Pandas' read\\_csv method converts the columns to its data types. If you want the column type to not be interpreted, specify the dtype param to read_csv method in this cell. More on this method [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110 entries, 0 to 109\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   original_text           110 non-null    object \n",
      " 1   reference_summary       110 non-null    object \n",
      " 2   generated_text          110 non-null    object \n",
      " 3   input_token_count       110 non-null    int64  \n",
      " 4   generated_token_count   110 non-null    int64  \n",
      " 5   prediction_probability  110 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 5.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"<EDIT THIS>\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs Section\n",
    "\n",
    "##### _1. Provide common parameters_:\n",
    "\n",
    "Provide the common parameters like the basic problem type, asset type, prompt variable columns, etc. Read more about these [here](#definitions). \n",
    "\n",
    "##### _2. Provide an embedding function_\n",
    "\n",
    "The embedding function should adhere to the following guidelines.\n",
    "\n",
    "- The input of the embedding function should accept a `list`.\n",
    "- The output of the embedding function should return a `list` comprising of the embeddings for all the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See 'Definitions' section to know more.\n",
    "\n",
    "problem_type = \"retrieval_augmented_generation\" \n",
    "# Supported problem types are classification, extraction, generation,\n",
    "#question_answering, summarization and retrieval_augmented_generation.\n",
    "asset_type = \"prompt\"\n",
    "input_data_type = \"unstructured_text\"\n",
    "feature_columns = [\"TO BE EDITED\", \"TO BE EDITED\", \"TO BE EDITED\"] #Mandatory parameter.\n",
    "context_columns = [\"TO BE EDITED\", \"TO BE EDITED\"]\n",
    "question_column = \"TO BE EDITED\"\n",
    "prediction_column = \"generated_text\"\n",
    "\n",
    "configuration = {\n",
    "    \"configuration\": {\n",
    "        \"asset_type\": asset_type,\n",
    "        \"problem_type\": problem_type,\n",
    "        \"input_data_type\": input_data_type,\n",
    "        \"feature_columns\": feature_columns,\n",
    "        \"prediction_column\": prediction_column,\n",
    "        \"context_columns\": context_columns,\n",
    "        \"question_column\": question_column,\n",
    "        \"drift_v2\": {\n",
    "            \"metrics_configuration\": {\n",
    "                \"advanced_controls\": {\n",
    "                    \"enable_embedding_drift\": True\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumyajyotibiswas/Desktop/Sample Notebooks/notebooks/notebooks_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L12-v2\")\n",
    "\n",
    " # 2. Calculate embeddings by calling model.encode()\n",
    "embeddings_fn = model.encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate embeddings\n",
    "\n",
    "Generate the embeddings and save the result as a CSV. Use `embeddings_chunk_size` to control, how many records are sent to the `embeddings_fn` at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfc9e8efefe4a8b80901f82133d8481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing embeddings... :   0%|          | 0/330 [00:00<?, ?values/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_df = compute_embeddings(configuration=configuration,\n",
    "                                   data=df,\n",
    "                                   embeddings_fn=embeddings_fn,\n",
    "                                   embeddings_chunk_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110 entries, 0 to 109\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   original_text                           110 non-null    object \n",
      " 1   reference_summary                       110 non-null    object \n",
      " 2   generated_text                          110 non-null    object \n",
      " 3   input_token_count                       110 non-null    int64  \n",
      " 4   generated_token_count                   110 non-null    int64  \n",
      " 5   prediction_probability                  110 non-null    float64\n",
      " 6   wos_feature_original_text_embeddings__  110 non-null    object \n",
      " 7   wos_input_embeddings__                  110 non-null    object \n",
      " 8   wos_output_embeddings__                 110 non-null    object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "embeddings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.to_csv(\"Data with embeddings.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the CSV in Watson Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_studio_lib import access_project_or_space\n",
    "wslib = access_project_or_space()\n",
    "wslib.upload_file(\"Data with embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "\n",
    "### Common Parameters\n",
    "\n",
    "| Parameter | Description | Default Value | Possible Value(s) |\n",
    "| :- | :- | :- | :- |\n",
    "| problem_type | One of the problem types. |  | classification, extraction, generation, question_answering, summarization, retrieval_augmented_generation|\n",
    "| asset_type | The asset type | prompt | prompt |\n",
    "| input_data_type | The type of input from the dataframe | unstructured_text | unstructured_text |\n",
    "| feature_columns | The names of all prompt variable columns | | |\n",
    "| context_columns | List of all the context columns. Mandatory if `problem_type` is `retrieval_augmented_generation` | | |\n",
    "| question_column | Optional parameter. The name of the question column|  | |\n",
    "| prediction_column | Optional parameter. | generated_text | |\n",
    "\n",
    "\n",
    "Example:\n",
    "```html\n",
    "problem_type = \"classification\"\n",
    "asset_type = \"prompt\"\n",
    "input_data_type = \"unstructured_text\"\n",
    "prompt_variable_columns = [\"text\"]\n",
    "prediction_column = \"prediction\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors\n",
    "Developed by [Prem Piyush Goyal](mailto:prempiyush@in.ibm.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
