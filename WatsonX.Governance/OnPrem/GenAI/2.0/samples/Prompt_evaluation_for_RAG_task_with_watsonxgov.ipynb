{"cells":[{"cell_type":"markdown","metadata":{"id":"43c19b29-f106-4111-ae53-f4c728a3ecb1"},"source":["# Working with Prompt Template Assets for a Retrieval-Augmented Generation task in watsonx.governance"]},{"cell_type":"markdown","metadata":{"id":"0d610206-9c2b-4b1a-a0f5-316fab3200c6"},"source":["This notebook will create a retrieval-augmented generation (RAG) prompt template asset (PTA) in a given project, configure watsonx.governance to monitor that PTA and evaluate generative quality metrics and model health metrics, and then promote the prompt template asset to a space and do the same evaluation.\n","\n","If you wish to execute this notebook for task types other than RAG, refer to [Evaluating prompt template asset of different task types](https://github.com/IBM/watson-openscale-samples/blob/main/IBM%20Cloud/WML/notebooks/watsonx/README.md) for guidance on evaluating prompt templates for other available task types.\n","\n","This notebook should be run using a Python 3.10 or greater runtime environment. If you are viewing this notebook in Watson Studio and do not see Python 3.10.x or higher in the upper right corner of your screen, please update the runtime now. \n","\n","**Note**: Run your notebook on a Cloud Pak for Data (CPD) cluster using version 5.0.0 or above."]},{"cell_type":"markdown","metadata":{},"source":["## Learning goals\n","\n","- Create a prompt template asset in a CPD project\n","- Configure watsonx.governance to monitor the created prompt template asset \n","- Evaluate generative quality metrics and model health metrics\n","- Promote the prompt template asset to a space\n","- Evaluate the prompt template asset in a space "]},{"cell_type":"markdown","metadata":{"id":"8b700c2f-a34b-4991-a615-977b9f56d386"},"source":["## Prerequisites"]},{"cell_type":"markdown","metadata":{"id":"9670db7c-0cb3-405b-b1c9-ac1a7e6ff7f3"},"source":["- Service credentials for IBM watsonx.governance are required\n","- Watson OpenScale (WOS) credentials are required\n","- Watson Machine Learning (WML) credentials are required\n","- A `.csv` file containing test data to be evaluated\n","- ID of the CPD project in which you want to create the PTA\n","- ID of the CPD space to which you want to promote the PTA"]},{"cell_type":"markdown","metadata":{"id":"3ed8c494-077d-43d9-935f-234d1720afe7"},"source":["## Contents\n","\n","[Evaluating a Prompt Template Asset from a project](#evaluateproject)\n","- [Step 1 - Setup](#settingup)\n","- [Step 2 - Create a Prompt template](#prompt)\n","- [Step 3 - Setup the prompt template](#ptatsetup)\n","- [Step 4 - Risk evaluations for the PTA subscription](#evaluate)\n","- [Step 5 - Display the Model Risk metrics](#mrmmetric)\n","- [Step 6 - Display the Generative AI Quality metrics](#genaimetrics)\n","- [Step 7 - Plot faithfulness and answer relevance metrics against records](#plotproject)\n","- [Step 8 - See factsheets information](#factsheetsspace)\n","\n","[Evaluating a Prompt Template Asset from a space](#evaluatespace)\n","- [Step 9 - Promote a PTA to a space](#promottospace)\n","- [Step 10 - Create a deployment for a PTA in a space](#ptadeployment)\n","- [Step 11 - Set up the PTA in a space for evaluation with supported monitor parameters](#ptaspace)\n","- [Step 12 - Score the model and configure monitors](#score)\n","- [Step 13 - Display the source attributions for a record](#attributions)\n","- [Step 14 - Plot faithfulness and answer relevance metrics against records](#plotspace)\n","- [Step 15 - See factsheets information from a space](#factsheetsproject)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluating a Prompt Template Asset from a project <a name=\"evaluateproject\"></a>\n","\n","In the first section of this notebook, you will learn how to:\n","\n","1. Create a PTA in a project\n","2. Create a `development`-type subscription for a PTA in OpenScale\n","3. Configure monitors supported by OpenScale for the subscription\n","4. Perform risk evaluations against the PTA subscription with a sample set of test data\n","5. Display the metrics generated with the risk evaluation\n","6. Display the factsheets information for the subscription"]},{"cell_type":"markdown","metadata":{"id":"1afb655f-03dd-4da1-a4c9-ccbfa542a645"},"source":["## Step 1 - Setup <a name=\"settingup\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### Install the necessary packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1075d4fc-cf23-4c75-b6cf-c97080b52846"},"outputs":[],"source":["!pip install -U ibm-watson-openscale | tail -n 1\n","!pip install --upgrade ibm-watson-machine-learning | tail -n 1\n","!pip install matplotlib"]},{"cell_type":"markdown","metadata":{"id":"af0e39fc-d20f-4412-81bb-ef3439a6f6a1"},"source":["**Note**: you may need to restart the kernel to use updated packages."]},{"cell_type":"markdown","metadata":{"id":"85780b74-1d39-4089-815f-2d63585a744f"},"source":["### Configure your credentials"]},{"cell_type":"markdown","metadata":{"id":"a6037265-6ef9-4e4f-97a0-dfdcabb4c3b0"},"source":["Run your notebook on a CPD cluster using version 5.0.0 or above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfccb394-160f-4a9d-b8e9-74f032ad9841"},"outputs":[],"source":["WOS_CREDENTIALS = {\n","     \"url\": \"<PLATFORM_URL>\",\n","     \"username\": \"<YOUR_USERNAME>\",\n","     \"password\": \"<YOUR_PASSWORD>\"\n","}\n","\n","WML_CREDENTIALS = {\n","     \"url\": \"<PLATFORM_URL>\",\n","     \"username\": \"<YOUR_USERNAME>\",\n","     \"password\" : \"<YOUR_PASSWORD>\",\n","     \"instance_id\": \"wml_local\",\n","     \"apikey\": \"<YOUR_APIKEY>\",\n","     \"version\" : \"4.8\"\n","}"]},{"cell_type":"markdown","metadata":{},"source":["**Note**: Replace the `WOS_CREDENTIALS` with your Watson OpenScale credentials, and the `WML_CREDENTIALS` with your Watson Machine Learning credentials."]},{"cell_type":"markdown","metadata":{"id":"e2b0a52f-f12f-4c93-bfc7-a809c3f676fa"},"source":["### Configure your project ID"]},{"cell_type":"markdown","metadata":{"id":"d33b6752-b344-4b68-b241-7ad9880ecf70"},"source":["To set up a development-type subscription in Watson OpenScale, the PTA must be within a CPD project. Supply the project ID where the PTA needs to be created."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12e6ee05-7bea-4f37-8585-4e2fd596a877"},"outputs":[],"source":["project_id = \"<YOUR_PROJECT_ID>\""]},{"cell_type":"markdown","metadata":{"id":"bd294986-76ce-4a8e-9889-8207142e2e25"},"source":["### Configure your space ID"]},{"cell_type":"markdown","metadata":{"id":"ae375639-26b7-4f22-87f8-3859b6100b0f"},"source":["You can use an existing space, or you can create a new space to promote the model."]},{"cell_type":"markdown","metadata":{"id":"7f429284-4d30-44dd-b609-99f6a5482ace"},"source":["#### (Optional) If you choose an existing space"]},{"cell_type":"markdown","metadata":{},"source":["Set variable for an existing space:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["use_existing_space = True # Set as False to create a new space"]},{"cell_type":"markdown","metadata":{},"source":["Import WML client:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json\n","from ibm_watson_machine_learning import APIClient\n","\n","wml_client = APIClient(WML_CREDENTIALS)\n","wml_client.version"]},{"cell_type":"markdown","metadata":{},"source":["List the available spaces:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6faba96b-bb6f-4fe2-be52-f4511625d5da"},"outputs":[],"source":["wml_client.spaces.list()"]},{"cell_type":"markdown","metadata":{},"source":["Add the existing space name to the following cell:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1df45f98-f690-440d-9044-56a53723f579"},"outputs":[],"source":["existing_space_id = \"<YOUR_SPACE_ID_NAME>\""]},{"cell_type":"markdown","metadata":{"id":"dad6003a-43f9-47a5-a4fc-c73b784968fe"},"source":["#### (Optional) If you choose to create a new space"]},{"cell_type":"markdown","metadata":{},"source":["Set variable for a new space:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["use_existing_space = False # Set as True to use an existing space"]},{"cell_type":"markdown","metadata":{},"source":["Create a name for your new space:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"419ff60b-9299-4255-8fcf-c1a97f342c11"},"outputs":[],"source":["space_name = \"<YOUR_NEW_SPACE_NAME>\""]},{"cell_type":"markdown","metadata":{"id":"6cb9de8e-ba5e-465a-96e4-c218fa303fc7"},"source":["Set up your new space:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"afaa0fda-222f-429a-8c22-a613d57d88fe"},"outputs":[],"source":["if use_existing_space == True:\n","    space_id = existing_space_id\n","else:\n","    space_meta_data = {\n","        wml_client.spaces.ConfigurationMetaNames.NAME : space_name,\n","        wml_client.spaces.ConfigurationMetaNames.DESCRIPTION : 'tutorial_space'\n","    }\n","\n","    space_id = wml_client.spaces.store(\n","        meta_props=space_meta_data)[\"metadata\"][\"id\"]\n","wml_client.set.default_space(space_id)\n","print(space_id)"]},{"cell_type":"markdown","metadata":{"id":"29433504-f5cf-4286-a88b-341fc71e7315"},"source":["### Create an access token"]},{"cell_type":"markdown","metadata":{"id":"28728a6e-b049-41d3-a7fc-fc3380a02057"},"source":["The following function generates an IAM access token using the provided credentials. The API calls for creating and scoring prompt template assets utilize the token generated by this function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0c8a41eb-d3b8-403d-9d57-72473d6e30c6"},"outputs":[],"source":["import requests, json\n","def generate_access_token():\n","    headers={}\n","    headers[\"Content-Type\"] = \"application/json\"\n","    headers[\"Accept\"] = \"application/json\"\n","    data = {\n","        \"username\":WOS_CREDENTIALS[\"username\"],\n","        \"password\":WOS_CREDENTIALS[\"password\"]\n","    }\n","    data = json.dumps(data).encode(\"utf-8\")\n","    url = WOS_CREDENTIALS[\"url\"] + \"/icp4d-api/v1/authorize\"\n","    response = requests.post(url=url, data=data, headers=headers,verify=False)\n","    json_data = response.json()\n","    iam_access_token = json_data['token']      \n","        \n","    return iam_access_token\n","\n","iam_access_token = generate_access_token()"]},{"cell_type":"markdown","metadata":{"id":"ae8b73e9-fddb-45d3-85cc-43520152193a"},"source":["## Step 2 - Create a Prompt template <a name=\"prompt\"></a>"]},{"cell_type":"markdown","metadata":{"id":"7ec97493-3260-427a-a903-f6bf0b61578a"},"source":["Create a prompt template for a RAG task:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20e84bc4-10ca-4edf-a283-6e127d446cba"},"outputs":[],"source":["credentials={\n","     \"apikey\": WML_CREDENTIALS[\"apikey\"],\n","     \"url\": WML_CREDENTIALS[\"url\"],\n","     \"instance_id\": \"openshift\",\n","     \"username\": WML_CREDENTIALS[\"username\"]\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55c03b62-9714-413f-8d47-322d9153cd8d"},"outputs":[],"source":["from ibm_watson_machine_learning.foundation_models.prompts import PromptTemplate, PromptTemplateManager\n","from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n","\n","prompt_mgr = PromptTemplateManager(\n","                credentials = credentials,\n","                project_id = project_id\n","                )\n","\n","prompt_template = PromptTemplate(name=\"RAG QA\",\n","                                 model_id=ModelTypes.GRANITE_13B_CHAT_V2,\n","                                 task_ids=[\"retrieval_augmented_generation\"],\n","                                 input_prefix=\"\",\n","                                 output_prefix=\"\",\n","                                 input_text=\"Answer the below question from the given context only and do not use the knowledge outside the context.\\n\\nContext: {context1} {context2} {context3} {context4}\\nQuestion: {question}\\nAnswer:\",\n","                                 input_variables=[\"context1\", \"context2\", \"context3\", \"context4\", \"question\"])\n","\n","stored_prompt_template = prompt_mgr.store_prompt(prompt_template)\n","project_pta_id = stored_prompt_template.prompt_id\n","project_pta_id"]},{"cell_type":"markdown","metadata":{"id":"f5fbcaaf-f1be-449a-8073-377fe4d78dc0"},"source":["## Step 3 - Set up the Prompt template <a name=\"ptatsetup\"></a>"]},{"cell_type":"markdown","metadata":{"id":"f0e48b71-2c5a-47cd-8035-d2651b675e29"},"source":["### Configure OpenScale"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ea98f094-6d20-4d31-ab5f-fe5e804d3f7b"},"outputs":[],"source":["from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n","\n","from ibm_watson_openscale import *\n","from ibm_watson_openscale.supporting_classes.enums import *\n","from ibm_watson_openscale.supporting_classes import *\n","\n","\n","authenticator = CloudPakForDataAuthenticator(\n","        url=WOS_CREDENTIALS['url'],\n","        username=WOS_CREDENTIALS['username'],\n","        password=WOS_CREDENTIALS['password'],\n","        disable_ssl_verification=True\n","    )\n","\n","wos_client = APIClient(service_url=WOS_CREDENTIALS['url'],authenticator=authenticator)\n","print(wos_client.version)"]},{"cell_type":"markdown","metadata":{"id":"7d83c21b-1119-4095-80e1-edc218a2ab4d"},"source":["### List available OpenScale datamarts and configure the datamart ID"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0c65b9d8-3fc4-4bd7-864b-dbee42eb5fab"},"outputs":[],"source":["wos_client.data_marts.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bd037955-4022-4d73-be4b-9b682d989243"},"outputs":[],"source":["data_mart_id = \"<YOUR_DATAMART_ID>\""]},{"cell_type":"markdown","metadata":{"id":"dadcb0fa-f862-4e5a-85ef-1b47073724c7"},"source":["### Map the project ID to an Openscale instance"]},{"cell_type":"markdown","metadata":{"id":"f6ba1b0d-904c-4ab6-a6c2-9029843ace7e"},"source":["When authentication is on CPD, you must take the additional step of mapping the project_id and space_id to an OpenScale instance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08ebce3f-f49d-451c-8937-479ba26c8a95"},"outputs":[],"source":["wos_client.wos.add_instance_mapping(                \n","            service_instance_id=data_mart_id,\n","            project_id=project_id\n","         )\n","wos_client.wos.add_instance_mapping(                \n","            service_instance_id=data_mart_id,\n","            space_id=space_id\n","         )"]},{"cell_type":"markdown","metadata":{"id":"24b3c38f-4072-4e98-a0ee-eba8160b5140"},"source":["### Set up the PTA in the project for evaluation with supported monitor parameters"]},{"cell_type":"markdown","metadata":{"id":"50492433-2be4-403a-8247-cab5c69e8140"},"source":["The PTAs from a project are only supported with a `development`-type operational space ID. Running the following cell will create a `development`-type subscription from the PTA created within your project.\n","\n","The available parameters that can be passed for the `execute_prompt_setup` function are:\n","\n"," * `prompt_template_asset_id`: ID of the PTA for which a subscription needs to be created\n"," * `label_column`: The name of the column containing the ground truth or actual labels\n"," * `project_id`: The ID of the project\n"," * `space_id`: The ID of the space\n"," * `deployment_id`: (optional) The ID of the deployment\n"," * `operational_space_id`: The rank of the environment in which the monitoring is happening. Accepted values are `development`, `pre_production`, `production`\n"," * `problem_type`: (optional) The task type to monitor for the given PTA\n"," * `classification_type`: The classification type (`binary`/`multiclass`) applicable only for the `classification` problem (task) type\n"," * `input_data_type`: The input data type\n"," * `supporting_monitors`: Monitor configuration for the subscription to be created\n"," * `background_mode`: When `True`, the prompt setup operation will be executed in the background\n","\n"," #### Faithfulness parameters\n","| Parameter | Description | Default Value |\n","|:-|:-|:-|\n","| `attributions_count` [Optional]| Source attributions are computed for each sentence in the generated answer. Source attribution for a sentence is the set of sentences in the context which contributed to the LLM generating that sentence in the answer.  The `attributions_count` parameter specifies the number of sentences in the context which need to be identified for attributions. , if the value is set to 2, then we will find the top 2 sentences from the context as source attributions. | `3` |\n","| `ngrams` [Optional]| The number of sentences to be grouped from the context when computing faithfulness score. These grouped sentences will be shown in the attributions. Having a very high value of ngrams might lead to having lower faithfulness scores due to dispersion of data and inclusion of unrelated sentences in the attributions. Having a very low value might lead to increase in metric computation time and attributions not capturing the all the aspects of the answer. | `2` |\n","\n","#### Unsuccessful requests parameters\n","| Parameter | Description | Default Value |\n","|:-|:-|:-|\n","| `unsuccessful_phrases` [Optional]| The list of phrases to be used for comparing the model output to determine whether the request is unsuccessful or not. | `[\"i don't know\", \"i do not know\", \"i'm not sure\", \"i am not sure\", \"i'm unsure\", \"i am unsure\", \"i'm uncertain\", \"i am uncertain\", \"i'm not certain\", \"i am not certain\", \"i can't fulfill\", \"i cannot fulfill\"]` |"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00d6b96d-08e0-46d6-9088-815791447d0c"},"outputs":[],"source":["# Update the label_column, context_fields, question_field values based on the prompt and test data used\n","label_column = \"answer\"\n","context_fields = [\"context1\", \"context2\", \"context3\", \"context4\"]\n","question_field = \"question\"\n","\n","operational_space_id = \"development\"\n","problem_type= \"retrieval_augmented_generation\"\n","input_data_type= \"unstructured_text\"\n","\n","\n","monitors = {\n","    \"generative_ai_quality\": {\n","        \"parameters\": {\n","            \"min_sample_size\": 5,\n","            \"metrics_configuration\":{\n","                \"faithfulness\": {\n","                    #\"attributions_count\": 3,\n","                    #\"ngrams\": 2,\n","                },\n","                \"answer_relevance\": {},\n","                \"rouge_score\": {},\n","                \"exact_match\": {},\n","                \"bleu\": {},\n","                \"unsuccessful_requests\": {\n","                    #\"unsuccessful_phrases\": []\n","                },\n","                \"hap_input_score\": {},\n","                \"hap_score\": {},\n","                \"pii\": {},\n","                \"pii_input\": {}\n","            }\n","        }\n","    }\n","}\n","\n","response = wos_client.wos.execute_prompt_setup(prompt_template_asset_id = project_pta_id, \n","                                               project_id = project_id,\n","                                               context_fields = context_fields,\n","                                               question_field = question_field,\n","                                               label_column = label_column,\n","                                               operational_space_id = operational_space_id, \n","                                               problem_type = problem_type,\n","                                               input_data_type = input_data_type, \n","                                               supporting_monitors = monitors, \n","                                               background_mode = False)\n","\n","result = response.result\n","result._to_dict()"]},{"cell_type":"markdown","metadata":{"id":"bcdaa0d3-0c0f-49cb-a14c-9cf57716d817"},"source":["With the following cell, you can read the prompt setup task and check its status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"642cd908-0d3c-4ac2-988f-192b6228e9b4"},"outputs":[],"source":["response = wos_client.wos.get_prompt_setup(prompt_template_asset_id = project_pta_id,\n","                                                             project_id = project_id)\n","\n","result = response.result\n","result_json = result._to_dict()\n","\n","if result_json[\"status\"][\"state\"] == \"FINISHED\":\n","    print(\"Finished prompt setup : The response is {}\".format(result_json))\n","else:\n","    print(\"prompt setup failed The response is {}\".format(result_json))"]},{"cell_type":"markdown","metadata":{"id":"0dccbb06-ea2f-4004-9eea-e8fba8ba9278"},"source":["### Read the `subscription_id` from the prompt setup"]},{"cell_type":"markdown","metadata":{"id":"645fa0b3-2f59-49eb-ae7e-d6e704e375f3"},"source":["Once the prompt setup status is `FINISHED`, read the subscription ID:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56a66cdd-3c4b-4cf5-acc6-cc1eda258eec"},"outputs":[],"source":["dev_subscription_id = result_json[\"subscription_id\"]\n","dev_subscription_id"]},{"cell_type":"markdown","metadata":{"id":"f6ce33aa-5959-41f6-a433-bcc5e7235b7e"},"source":["### Show all monitor instances in the development subscription\n","The following cell lists the monitors present in the development subscription, along with their respective statuses and other details. Please wait for all the monitors to be in an active state before proceeding further."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e98875e2-9b71-4fda-b1f7-018eaf2ccdd5"},"outputs":[],"source":["wos_client.monitor_instances.show(target_target_id = dev_subscription_id)"]},{"cell_type":"markdown","metadata":{"id":"0013c9fc-e78f-4953-924e-bf9440e46392"},"source":["## Step 4 - Risk evaluations for the PTA subscription <a name=\"evaluate\"></a>"]},{"cell_type":"markdown","metadata":{"id":"5a483fcc-946c-456a-bcac-c1dbb76e2e3d"},"source":["### Evaluate the prompt template subscription\n","\n","For risk assessment of a `development`-type subscription, you must have an evaluation dataset. The risk assessment function takes the evaluation dataset path as a parameter when evaluating the configured metrics. If there is a discrepancy between the feature columns in the subscription and the column names in the uploading `.CSV` file, you have the option to supply a mapping JSON file to associate the `.CSV` column names with the feature column names in the subscription.\n","\n","**Note**: If you are running this notebook from Watson Studio, you may first need to upload your test data to Watson Studio, then run the code snippet below to download the feedback data file from the project to a local directory."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ad18ca0-2be2-4cd5-b11b-3249f4a800cf"},"outputs":[],"source":["# Download rag data\n","!rm rag_state_union.csv\n","!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/watsonx/rag_state_union.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7dd5d2d5-9ec8-49ee-a5df-0fb8fb26493d"},"outputs":[],"source":["test_data_path = \"rag_state_union.csv\"\n","body = None # Please update your mapping file path here if needed\n","\n","# Download data from project to local directory\n","# Run the below code snippet only if you are running the notebook via Watson Studio\n","from ibm_watson_studio_lib import access_project_or_space\n","wslib = access_project_or_space()\n","wslib.download_file(test_data_path)\n","if body:\n","    wslib.download_file(body)"]},{"cell_type":"markdown","metadata":{"id":"a2583f03-c1d7-4498-af66-14211a286de1"},"source":["### Read the Model Risk metrics `instance_id` from OpenScale\n","\n","Evaluating test data against the prompt template subscription requires the monitor instance ID for your OpenScale Model Risk metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8f0bcdb1-12da-4645-8ab6-e4edf740d1a6"},"outputs":[],"source":["monitor_definition_id = \"mrm\"\n","target_target_id = dev_subscription_id\n","result = wos_client.monitor_instances.list(data_mart_id=data_mart_id,\n","                                           monitor_definition_id=monitor_definition_id,\n","                                           target_target_id=target_target_id,\n","                                           project_id=project_id).result\n","result_json = result._to_dict()\n","mrm_monitor_id = result_json[\"monitor_instances\"][0][\"metadata\"][\"id\"]\n","mrm_monitor_id"]},{"cell_type":"markdown","metadata":{"id":"9e38c223-d453-4449-ab95-18058d5cfc27"},"source":["The following cell will assess the test data with the subscription of the PTA and produce relevant measurements for the configured monitor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bc0f1887-4d02-4da5-864a-9601ba7dae9c"},"outputs":[],"source":["test_data_set_name = \"data\"\n","content_type = \"multipart/form-data\"\n","\n","response  = wos_client.monitor_instances.mrm.evaluate_risk(monitor_instance_id=mrm_monitor_id, \n","                                                    test_data_set_name = test_data_set_name, \n","                                                    test_data_path = test_data_path,\n","                                                    content_type = content_type,\n","                                                    body = body,\n","                                                    project_id = project_id,\n","                                                    background_mode = False)"]},{"cell_type":"markdown","metadata":{"id":"f2acbed4-3179-4904-a391-e567d101956d"},"source":["### Read the risk evaluation response\n","\n","After initiating the risk evaluation, the evaluation results are available for review:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03f6b2ae-ff88-42d8-94b8-f10ee3620a59"},"outputs":[],"source":["response  = wos_client.monitor_instances.mrm.get_risk_evaluation(mrm_monitor_id, project_id = project_id)\n","response.result.to_dict()"]},{"cell_type":"markdown","metadata":{"id":"3d49fe1b-8b2c-4de2-b184-3dd779bed933"},"source":["## Step 5 - Display the Model Risk metrics <a name=\"mrmmetric\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["Having calculated the measurements for the Foundation Model subscription, the Model Risk metrics generated for this subscription are available for your review:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"524985f7-5339-4107-83b3-4ca740fc33eb"},"outputs":[],"source":["wos_client.monitor_instances.show_metrics(monitor_instance_id=mrm_monitor_id, project_id=project_id)"]},{"cell_type":"markdown","metadata":{"id":"76ebe4e0-b17b-4176-88ab-e0e87ca8f554"},"source":["## Step 6 - Display the Generative AI quality metrics <a name=\"genaimetrics\"></a>"]},{"cell_type":"markdown","metadata":{"id":"e03ff555-5522-4f2e-814d-bae9a7a92fe7"},"source":["The monitor instance ID is required for reading the Generative AI quality metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0f56e775-7811-4b13-9dbf-ecf0d03d6e9c"},"outputs":[],"source":["monitor_definition_id = \"generative_ai_quality\"\n","result = wos_client.monitor_instances.list(data_mart_id = data_mart_id,\n","                                           monitor_definition_id = monitor_definition_id,\n","                                           target_target_id = target_target_id,\n","                                           project_id = project_id).result\n","result_json = result._to_dict()\n","genaiquality_monitor_id = result_json[\"monitor_instances\"][0][\"metadata\"][\"id\"]\n","genaiquality_monitor_id"]},{"cell_type":"markdown","metadata":{"id":"8d5a1e82-da67-4f19-9dc3-138ce73f0110"},"source":["Display the Generative AI quality monitor metrics generated through the risk evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"411d7bf4-fa76-4681-8821-3efae4c7f610"},"outputs":[],"source":["wos_client.monitor_instances.show_metrics(monitor_instance_id=genaiquality_monitor_id, project_id=project_id)"]},{"cell_type":"markdown","metadata":{"id":"0eaf589a-3a23-4e29-be51-7aba4df22023"},"source":["### Display record level metrics for Generative AI quality "]},{"cell_type":"markdown","metadata":{"id":"493aa938-30a3-4dbb-8a40-cb2550b5d491"},"source":["Get the dataset ID for the Generative AI quality dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f09ad225-6d99-4a78-87b4-a3d588f23cd8"},"outputs":[],"source":["result = wos_client.data_sets.list(target_target_id = dev_subscription_id,\n","                                target_target_type = \"subscription\",\n","                                type = \"gen_ai_quality_metrics\").result\n","\n","genaiq_dataset_id = result.data_sets[0].metadata.id\n","genaiq_dataset_id"]},{"cell_type":"markdown","metadata":{"id":"b09e557a-8a85-4f78-9fa9-c304756a7f60"},"source":["Display record level metrics for Generative AI quality:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"deb667cf-536c-4015-8a68-14760b95f389"},"outputs":[],"source":["wos_client.data_sets.show_records(data_set_id = genaiq_dataset_id)"]},{"cell_type":"markdown","metadata":{"id":"d29060a6-a36a-4b39-9199-e393f03d5980"},"source":["## Step 7 - Plot faithfulness and answer relevance metrics against records <a name=\"plotproject\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["Retrieve a list of records and extract the record IDs, faithfulness values, and answer relevance values:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f1e84fd1-645b-4cf5-8208-5d1f042c24bd"},"outputs":[],"source":["result = wos_client.data_sets.get_list_of_records(data_set_id = genaiq_dataset_id).result\n","result[\"records\"]\n","x = []\n","y_faithfulness = []\n","y_answer_relevance = []\n","for each in result[\"records\"]:\n","    x.append(each[\"metadata\"][\"id\"][-5:]) # Reading only last 5 characters to fit in the display\n","    y_faithfulness.append(each[\"entity\"][\"values\"][\"faithfulness\"])\n","    y_answer_relevance.append(each[\"entity\"][\"values\"][\"answer_relevance\"])"]},{"cell_type":"markdown","metadata":{"id":"f67e8473-ceb3-46fb-8970-35db64f388cd"},"source":["Plot faithfulness metrics against the records"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4a0a03eb-308e-4626-b6ee-25c7b829f5e9"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.scatter(x, y_faithfulness, marker='o')\n","\n","# Adding labels and title\n","plt.xlabel('X-axis - Record id (last 5 characters)')\n","plt.ylabel('Y-axis - Faithfulness')\n","plt.title('faithfulness vs record id')\n","\n","# Display the graph\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"c3a22aa3-a052-4c20-9216-17b7f60b8667"},"source":["Plot answer relevance metrics against the records"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e299616a-c660-432e-a410-5fe16e55f12e"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.scatter(x, y_answer_relevance, marker='o')\n","\n","# Adding labels and title\n","plt.xlabel('X-axis - Record id (last 5 characters)')\n","plt.ylabel('Y-axis - Answer relevance')\n","plt.title('answer_relevance vs record id')\n","\n","# Display the graph\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"e7d36530-c817-4633-a7a6-55cefbad3f36"},"source":["## Step 8 - See factsheets information <a name=\"factsheetsspace\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0c0491e5-43ff-457a-ba2a-029cc4e4cf9b"},"outputs":[],"source":["factsheets_url = factsheets_url = \"{}/wx/prompt-details/{}/factsheet?context=wx&project_id={}\".format(WML_CREDENTIALS[\"url\"],project_pta_id, project_id)\n","print(\"User can navigate to the published facts in project {}\".format(factsheets_url))"]},{"cell_type":"markdown","metadata":{"id":"7a9a4f40-bead-4621-8b6c-9782428ae4fa"},"source":["## Evaluating a Prompt Template Asset from a space <a name=\"evaluatespace\"></a>\n","\n","So far, you have performed the following tasks:\n","\n","1. Created a PTA in a project\n","2. Created a `development`-type subscription for a PTA in OpenScale\n","3. Configured monitors supported by OpenScale for the subscription\n","4. Performed risk evaluations against the PTA subscription with a sample set of test data\n","5. Displayed the metrics generated with the risk evaluation\n","6. Displayed the factsheets information for the subscription\n","\n","Now, you will promote the created PTA to a space and perform similar actions."]},{"cell_type":"markdown","metadata":{"id":"6899b33c-4a94-4325-b16d-be2acc656b38"},"source":["## Step 9 - Promote a PTA to a space <a name=\"promottospace\"></a> "]},{"cell_type":"markdown","metadata":{"id":"b232b9cb-6a1d-4926-a02b-dd2ef15995bb"},"source":["The following cell promotes the prompt template asset from your project to your space."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4c1d355b-c9a8-40f9-bed5-ed0d880f8b67"},"outputs":[],"source":["headers={}\n","headers[\"Content-Type\"] = \"application/json\"\n","headers[\"Accept\"] = \"*/*\"\n","headers[\"Authorization\"] = \"Bearer {}\".format(iam_access_token)\n","verify = True\n","\n","DATAPLATFORM_URL = WOS_CREDENTIALS[\"url\"]\n","verify = False\n","url = \"{}/v2/assets/{}/promote\".format(DATAPLATFORM_URL ,project_pta_id)\n","\n","params = {\n","    \"project_id\":project_id\n","}\n","\n","payload = {\n","    \"space_id\": space_id\n","}\n","response = requests.post(url, json=payload, headers=headers, params = params, verify = verify)\n","json_data = response.json()\n","json_data\n","space_pta_id = json_data[\"metadata\"][\"asset_id\"]\n","space_pta_id"]},{"cell_type":"markdown","metadata":{"id":"a60b55bb-a9e5-4c81-a99a-e7faef30313d"},"source":["## Step 10 - Create a deployment for a PTA in a space <a name=\"ptadeployment\"></a>"]},{"cell_type":"markdown","metadata":{"id":"2e70a2f9-45af-41b0-8121-92d168aa4e2b"},"source":["To create a subscription from a space, it is necessary to create a deployment for a PTA in a space."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3d6b1b76-3201-476b-9801-71e361931333"},"outputs":[],"source":["DEPLOYMENTS_URL = WML_CREDENTIALS[\"url\"] + \"/ml/v4/deployments\"\n","\n","serving_name = \"rag_qa_deployment\" # eg: summary_deployment\n","\n","payload = {\n","    \"prompt_template\": {\n","      \"id\": space_pta_id\n","    },\n","    \"online\": {\n","       \"parameters\": {\n","         \"serving_name\": serving_name\n","       }\n","    },\n","    \"base_model_id\": \"ibm/granite-13b-chat-v2\",\n","    \"description\": \"rag qa deployment\",\n","    \"name\": \"rag qa deployment\",\n","    \"space_id\": space_id\n","}\n","\n","version = \"2024-05-05\" # The version date for the API of the form YYYY-MM-DD. Example : 2023-07-07\n","params = {\n","    \"version\":version,\n","    \"space_id\":space_id\n","}\n","\n","response = requests.post(DEPLOYMENTS_URL, json=payload, headers=headers, params = params, verify = verify)\n","json_data = response.json()\n","\n","\n","if \"metadata\" in json_data:\n","    deployment_id = json_data[\"metadata\"][\"id\"]\n","    print(deployment_id)\n","else:\n","    print(json_data)"]},{"cell_type":"markdown","metadata":{"id":"083c1035-6220-4304-8aa4-4cc0a3b57963"},"source":["## Step 11 - Set up the PTA in a space for evaluation with supported monitor parameters <a name=\"ptaspace\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["Use of a PTA in a space is only supported with `pre_production` and `production` operational space IDs. Running the following cell will create a `production`-type subscription from the PTA promoted to the space. The `problem_type` value should depend on the task type specified in the PTA."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eb953cc-7547-431c-bb8d-3f48f519833d"},"outputs":[],"source":["label_column = \"answer\"\n","context_fields = [\"context1\", \"context2\", \"context3\", \"context4\"]\n","question_field = \"question\"\n","operational_space_id = \"production\"\n","problem_type= \"retrieval_augmented_generation\"\n","input_data_type= \"unstructured_text\"\n","\n","monitors = {\n","    \"generative_ai_quality\": {\n","        \"parameters\": {\n","            \"min_sample_size\": 5,\n","            \"metrics_configuration\":{\n","                \"faithfulness\": {\n","                    #\"attributions_count\": 3,\n","                    #\"ngrams\": 2,\n","                },\n","                \"answer_relevance\": {},\n","                \"rouge_score\": {},\n","                \"exact_match\": {},\n","                \"bleu\": {},\n","                \"unsuccessful_requests\": {\n","                    #\"unsuccessful_phrases\": []\n","                },\n","                \"hap_input_score\": {},\n","                \"hap_score\": {},\n","                \"pii\": {},\n","                \"pii_input\": {}\n","            }\n","        }\n","    },\n","    \"drift_v2\": {\n","        \"thresholds\": [\n","            {\n","                \"metric_id\": \"confidence_drift_score\",\n","                \"type\": \"upper_limit\",\n","                \"value\": 0.05\n","            },\n","            {\n","                \"metric_id\": \"prediction_drift_score\",\n","                \"type\": \"upper_limit\",\n","                \"value\": 0.05\n","            },\n","            {\n","                \"metric_id\": \"input_metadata_drift_score\",\n","                \"specific_values\": [\n","                    {\n","                        \"applies_to\": [\n","                            {\n","                                \"type\": \"tag\",\n","                                \"value\": \"subscription\",\n","                                \"key\": \"field_type\"\n","                            }\n","                        ],\n","                        \"value\": 0.05\n","                    }\n","                ],\n","                \"type\": \"upper_limit\"\n","            },\n","            {\n","                \"metric_id\": \"output_metadata_drift_score\",\n","                \"specific_values\": [\n","                    {\n","                        \"applies_to\": [\n","                            {\n","                                \"type\": \"tag\",\n","                                \"value\": \"subscription\",\n","                                \"key\": \"field_type\"\n","                            }\n","                        ],\n","                        \"value\": 0.05\n","                    }\n","                ],\n","                \"type\": \"upper_limit\"\n","            }\n","        ],\n","        \"parameters\": {\n","            \"min_samples\": 10,\n","            \"train_archive\": True\n","        }\n","    }\n","}\n","\n","\n","response = wos_client.wos.execute_prompt_setup(prompt_template_asset_id = space_pta_id, \n","                                               space_id = space_id,\n","                                               deployment_id = deployment_id,\n","                                               context_fields=context_fields,\n","                                               question_field = question_field,\n","                                               label_column = label_column, \n","                                               operational_space_id = operational_space_id, \n","                                               problem_type = problem_type,\n","                                               input_data_type = input_data_type, \n","                                               supporting_monitors = monitors, \n","                                               background_mode = False)\n","\n","result = response.result\n","result._to_dict()"]},{"cell_type":"markdown","metadata":{"id":"e4226f80-77df-4f75-9258-bc656d9867e9"},"source":["With the following cell, you can read the prompt setup task and check its status:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9b47b8ef-6cd1-4fab-81e4-c31f6ad14ac7"},"outputs":[],"source":["response = wos_client.wos.get_prompt_setup(prompt_template_asset_id = space_pta_id,\n","                                                             deployment_id = deployment_id,\n","                                                             space_id = space_id)\n","\n","result = response.result\n","result_json = result._to_dict()\n","result_json"]},{"cell_type":"markdown","metadata":{"id":"a55c36bf-bfc6-4369-8e0a-fd60df39cf62"},"source":["### Read the subscription ID from the prompt setup\n","\n","Once the prompt setup status is `finished`, get the subscription ID:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34836d85-664b-4938-bcc6-e9d9aa39a296"},"outputs":[],"source":["prod_subscription_id = result_json[\"subscription_id\"]\n","prod_subscription_id"]},{"cell_type":"markdown","metadata":{"id":"ede830f8-7fd7-4aad-9bfe-0e897e139db2"},"source":["### Score the PTA deployment"]},{"cell_type":"markdown","metadata":{"id":"2d5fc68a-347a-4422-8ce6-68ee4215d4c2"},"source":["Retrieve the scoring URL of the deployment from the subscription details."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93a56cf4-14ee-4c06-84c5-fe96e61d1b44"},"outputs":[],"source":["sub_details = wos_client.subscriptions.get(prod_subscription_id).result\n","sub_details = sub_details._to_dict()\n","scoring_url = sub_details[\"entity\"][\"deployment\"][\"url\"]\n","if not scoring_url.find(\"?version=\") != -1:\n","    scoring_url = scoring_url.strip() + \"?version=2024-05-05\"\n","\n","scoring_url = WML_CREDENTIALS[\"url\"] + \"/ml/v1/deployments/\"+ deployment_id +\"/text/generation?version=2024-05-05\"\n","print(scoring_url)"]},{"cell_type":"markdown","metadata":{"id":"e3aed560-6141-435e-bd74-e39c316d92bb"},"source":["## Step 12 - Score the model and configure monitors <a name=\"score\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["Once the WML service has been bound and the subscription has been created, you must score the PTA. Generate the test data content in JSON format from the previously-downloaded `.CSV` file. This is used to construct the payload for scoring the deployment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53efcdbd-5a2d-43e8-ae90-3ae38f1c9b44"},"outputs":[],"source":["test_data_path = \"rag_state_union.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7ef4670-0a90-4b5c-bfdf-73aa587c0066"},"outputs":[],"source":["import csv\n","\n","feature_fields = context_fields + [question_field]\n","prediction = \"generated_text\"\n","\n","headers={}\n","headers[\"Content-Type\"] = \"application/json\"\n","headers[\"Accept\"] = \"*/*\"\n","headers[\"Authorization\"] = \"Bearer {}\".format(iam_access_token)\n","\n","pl_data = []\n","prediction_list = []\n","with open(test_data_path, 'r') as csv_file:\n","    csv_reader = csv.DictReader(csv_file)\n","    for row in csv_reader:\n","        request = {\n","            \"parameters\": {\n","                \"template_variables\": {\n","                }\n","            }\n","        }\n","        for each in feature_fields:\n","            request[\"parameters\"][\"template_variables\"][each] = str(row[each])\n","\n","        response = requests.post(scoring_url, json=request, headers=headers, verify=False).json()\n","        predicted_val = response[\"results\"][0][prediction]\n","        prediction_list.append(predicted_val)\n","        record = {\"request\":request, \"response\":response}\n","        pl_data.append(record)\n","    \n","pl_data"]},{"cell_type":"markdown","metadata":{"id":"ffb73e13-7a03-4f05-9b94-bf7f23ff0eac"},"source":["### Generate additional payload data to enable drift"]},{"cell_type":"markdown","metadata":{"id":"5e942518-bdca-4f20-b45e-d2eff82ed625"},"source":["To enable drift, there should be a minimum of 100 records in the payload table. The following cell duplicates the scored records and creates another 100 records for adding to the payload table:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5451d2e-f07f-424e-943b-38955cc44533"},"outputs":[],"source":["import copy\n","\n","additional_pl_data = copy.copy(pl_data)\n","additional_pl_data *= 20\n","print(\"Generated {} additional payload data\".format(len(additional_pl_data)))"]},{"cell_type":"markdown","metadata":{"id":"e58e046b-81ee-4c3a-a7c0-49eba5f5f160"},"source":["### Add payload data\n","\n","The following cell reads the payload data set ID from the subscription:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7d9d2d6a-af01-42b0-83fb-4b9628729ead"},"outputs":[],"source":["import time\n","from ibm_watson_openscale.supporting_classes.enums import *\n","\n","time.sleep(5)\n","payload_data_set_id = None\n","payload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n","                                                target_target_id=prod_subscription_id, \n","                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n","if payload_data_set_id is None:\n","    print(\"Payload data set not found. Please check subscription status.\")\n","else:\n","    print(\"Payload data set id: \", payload_data_set_id)"]},{"cell_type":"markdown","metadata":{"id":"db48e816-631a-43f7-acd0-dbb2e67f087b"},"source":["Add additional payload data to enable drift V2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0701f20-fc1b-4746-9679-176b58f98645"},"outputs":[],"source":["wos_client.data_sets.store_records(data_set_id=payload_data_set_id, request_body=additional_pl_data,background_mode=False)\n","time.sleep(5)\n","pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n","print(\"Number of records in the payload logging table: {}\".format(pl_records_count))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80b97587-19a5-4bcc-9d9f-cdf9cc697a7e"},"outputs":[],"source":["wos_client.data_sets.get_records_count(payload_data_set_id)"]},{"cell_type":"markdown","metadata":{"id":"8819eed2-99e7-4a0e-8e08-a55c2ffa241f"},"source":["A total of 105 records should be available within the payload table. If auto payload logging fails to transmit the scored records to the payload logging table, the following code can be used to manually add payload data to the table:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ae9fe1a-9df4-49cd-a8c6-c650d56a8e53"},"outputs":[],"source":["import uuid\n","from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n","time.sleep(5)\n","pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n","print(\"Number of records in the payload logging table: {}\".format(pl_records_count))\n","if pl_records_count < 105:\n","    print(\"Payload logging did not happen, performing explicit payload logging.\")\n","    wos_client.data_sets.store_records(data_set_id=payload_data_set_id, request_body=pl_data,background_mode=False)\n","    time.sleep(5)\n","    pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n","    print(\"Number of records in the payload logging table: {}\".format(pl_records_count))"]},{"cell_type":"markdown","metadata":{"id":"199af421-230d-4b52-8723-99cde8b8f382"},"source":["### Add feedback data\n","\n","The following cell reads the feedback dataset ID from the subscription:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5ed8346-0066-45a5-88fb-7c2ee097dd4b"},"outputs":[],"source":["import time\n","from ibm_watson_openscale.supporting_classes.enums import *\n","\n","time.sleep(5)\n","feedback_data_set_id = None\n","feedback_data_set_id = wos_client.data_sets.list(type=DataSetTypes.FEEDBACK, \n","                                                target_target_id=prod_subscription_id, \n","                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n","if feedback_data_set_id is None:\n","    print(\"Feedback data set not found. Please check subscription status.\")\n","else:\n","    print(\"Feedback data set id: \", feedback_data_set_id)"]},{"cell_type":"markdown","metadata":{"id":"3615876d-941b-4cbc-802f-5b9ae202a8e7"},"source":["The provided code generates feedback data based on the downloaded `.CSV` file and the scored response."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6bab3ac3-766d-4cf7-bec7-cf6a0bf41e7f"},"outputs":[],"source":["import csv\n","\n","test_data_content = []\n","csv_file_path = \"rag_state_union.csv\"\n","\n","with open(csv_file_path, 'r') as csv_file:\n","    csv_reader = csv.DictReader(csv_file)\n","    for row, prediction_val in zip(csv_reader, prediction_list):\n","\n","        # Read each row from the CSV and add label and prediction values\n","        result_row = []\n","        result_row = [row[key] for key in feature_fields if key in row]\n","        result_row.append(row[label_column])\n","        result_row.append(prediction_val)\n","\n","        test_data_content.append(result_row)\n","if len(test_data_content) == 5: # 10 records are there in the downloaded CSV\n","    print(\"generated feedback data from CSV\")\n","else:\n","    print(\"Failed to generated feedback data from CSV, Kindly verify the CSV file content\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c69f8605-1273-47dc-8529-bafaa1e78e76"},"outputs":[],"source":["fields = feature_fields\n","fields.append(label_column)\n","fields.append(\"_original_prediction\")\n","feedback_data = [\n","    {\n","        \"fields\": fields,\n","        \"values\": test_data_content\n","    }\n","]\n","feedback_data"]},{"cell_type":"markdown","metadata":{"id":"202c461d-af94-483f-bb9e-f43e4c61f0f2"},"source":["The following code can be used to manually add feedback data to the table."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a455958d-1fc9-4e8e-a17c-35b40eacd248"},"outputs":[],"source":["wos_client.data_sets.store_records(data_set_id=feedback_data_set_id, request_body=feedback_data,background_mode=False)\n","time.sleep(5)\n","fb_records_count = wos_client.data_sets.get_records_count(feedback_data_set_id)\n","# Adding time delay to enable drift\n","time.sleep(10)\n","print(\"Number of records in the feedback logging table: {}\".format(fb_records_count))"]},{"cell_type":"markdown","metadata":{"id":"eed70425-e23e-408e-9f07-c717c837996b"},"source":["### Show all the monitor instances in the production subscription\n","The following cell lists the monitors present in the production subscription, along with their respective statuses and other details. Please wait for all the monitors to be in an active state before proceeding further:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2c33d97c-e7df-4950-87f1-2a5da5d8d68d"},"outputs":[],"source":["wos_client.monitor_instances.show(target_target_id = prod_subscription_id)"]},{"cell_type":"markdown","metadata":{"id":"b7b72260-7183-417c-b035-fdc5893cac2c"},"source":["### Read the Model Risk Metrics monitor instance ID of a PTA subscription deployed in a space\n","\n","Evaluating the test data against the prompt template subscription requires the monitor instance ID of the Model Risk Metrics monitor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0d37975-d4b0-47bf-b21f-389b01c739a8"},"outputs":[],"source":["monitor_definition_id = \"mrm\"\n","target_target_id = prod_subscription_id\n","result = wos_client.monitor_instances.list(data_mart_id=data_mart_id,\n","                                           monitor_definition_id=monitor_definition_id,\n","                                           target_target_id=target_target_id,\n","                                           space_id=space_id).result\n","result_json = result._to_dict()\n","mrm_monitor_id = result_json[\"monitor_instances\"][0][\"metadata\"][\"id\"]\n","mrm_monitor_id"]},{"cell_type":"markdown","metadata":{"id":"248e6b81-e6d9-4091-8db5-261f86bdb17b"},"source":["### Evaluate the prompt template subscription from a space\n","\n","The following cell will assess subscription of the prompt template asset and produce relevant measurements for the configured monitor. The data to be evaluated are already uploaded to payload and feedback table."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fb4af7e-635a-44db-9098-f43218c14de5"},"outputs":[],"source":["response  = wos_client.monitor_instances.mrm.evaluate_risk(monitor_instance_id=mrm_monitor_id, \n","                                                    body = body,\n","                                                    space_id = space_id,\n","                                                    evaluation_tests = [\"model_health\", \"drift_v2\", \"generative_ai_quality\"],\n","                                                    background_mode = False)"]},{"cell_type":"markdown","metadata":{"id":"8334e3a6-7df5-415a-8a61-47404ab1e996"},"source":["### Read the risk evaluation response\n","\n","After initiating the risk evaluation, the evaluation results of the PTA from your space are now available for review:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c61bfbdf-f1dc-4126-b424-c599ae9f6468"},"outputs":[],"source":["response  = wos_client.monitor_instances.mrm.get_risk_evaluation(mrm_monitor_id, space_id = space_id)\n","response.result.to_dict()"]},{"cell_type":"markdown","metadata":{"id":"ef4d80bd-cc41-40d4-810e-1049414626e5"},"source":["### Display the Model Risk metrics\n","\n","Having calculated the measurements for the Foundation Model subscription, the MModel Risk metrics generated for this subscription are now available for your review:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8e98561-89af-433d-9d1f-4352c1311395"},"outputs":[],"source":["wos_client.monitor_instances.show_metrics(monitor_instance_id=mrm_monitor_id, space_id=space_id)"]},{"cell_type":"markdown","metadata":{"id":"a60675ad-b3eb-47d9-89d3-8a559d2579af"},"source":["### Display the Generative AI quality metrics"]},{"cell_type":"markdown","metadata":{},"source":["The monitor instance ID for the Generative AI quality metrics is required for reading its metrics:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62035a68-6f66-44b9-9553-cb566afa0451"},"outputs":[],"source":["monitor_definition_id = \"generative_ai_quality\"\n","result = wos_client.monitor_instances.list(data_mart_id = data_mart_id,\n","                                           monitor_definition_id = monitor_definition_id,\n","                                           target_target_id = target_target_id,\n","                                           space_id = space_id).result\n","result_json = result._to_dict()\n","genaiquality_monitor_id = result_json[\"monitor_instances\"][0][\"metadata\"][\"id\"]\n","genaiquality_monitor_id"]},{"cell_type":"markdown","metadata":{"id":"9885cbe6-1083-4ccb-9d57-b8e8f009a0bc"},"source":["Display the monitor metrics of the Generative AI quality metrics generated through the risk evaluation:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"789ad789-f8c7-4927-bf1b-485b0addfc2b"},"outputs":[],"source":["wos_client.monitor_instances.show_metrics(monitor_instance_id=genaiquality_monitor_id, space_id=space_id)"]},{"cell_type":"markdown","metadata":{"id":"fb3ccd8a-4ea0-4736-b509-727dfa90abea"},"source":["## Step 13 - Display the source attribution for a record"]},{"cell_type":"markdown","metadata":{"id":"4859d909-0be1-47bf-a522-db2a17700f46"},"source":["Read the dataset ID for the Generative AI quality dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"86b51317-3848-4bd8-b87a-d2f5506c1145"},"outputs":[],"source":["result = wos_client.data_sets.list(target_target_id = prod_subscription_id,\n","                                target_target_type = \"subscription\",\n","                                type = \"gen_ai_quality_metrics\").result\n","\n","genaiq_dataset_id = result.data_sets[0].metadata.id\n","genaiq_dataset_id"]},{"cell_type":"markdown","metadata":{"id":"8e32d064-6bd0-4eb6-b268-0ca6326606e3"},"source":["Display record level metrics for Generative AI quality:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7200552c-43e2-4855-a346-3b4306146f3a"},"outputs":[],"source":["wos_client.data_sets.show_records(data_set_id = genaiq_dataset_id)"]},{"cell_type":"markdown","metadata":{},"source":["### Display source attributions for a record from payload or feedback data <a name=\"attributions\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["Get a record from payload table. The below method can also be used to get the record from feedback table by providing the feedback dataset id"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["result = wos_client.data_sets.get_list_of_records(data_set_id = payload_data_set_id, limit=1).result\n","record = result[\"records\"][0][\"entity\"][\"values\"]\n","scoring_id = record.get(\"scoring_id\")\n","scoring_id"]},{"cell_type":"markdown","metadata":{},"source":["Get the source attributions from generative ai quality dataset for the scoring id"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","metrics_result = wos_client.data_sets.get_list_of_records(data_set_id = genaiq_dataset_id, filter=\"scoring_id:eq:{}\".format(scoring_id)).result\n","record_metrics = metrics_result[\"records\"][0][\"entity\"][\"values\"]\n","attributions, attribution_scores = [], []\n","for i in record_metrics.get(\"faithfulness_attributions\")[\"faithfulness_attributions\"]:\n","    for attr in i[\"attributions\"]:\n","        attributions.extend(attr.get(\"feature_values\"))\n","        attribution_scores.extend(attr.get(\"faithfulness_scores\"))\n","\n","attributions_df = pd.DataFrame({\"faithfulness attribution\": attributions, \"attribution score\": attribution_scores})\n","pd.set_option(\"display.max_colwidth\", 0)\n","attributions_df.sort_values(by=[\"attribution score\"], inplace=True, ascending=False)\n","print(\"Question: {}\".format(record.get(\"question\")))\n","print(\"Answer: {}\".format(record.get(\"generated_text\")))\n","print(\"Attributions: \")\n","attributions_df"]},{"cell_type":"markdown","metadata":{"id":"1a72b14a-849e-45b1-a0e2-03feb5865f95"},"source":["## Step 14 - Plot faithfulness and answer relevance metrics against records <a name=\"plotspace\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["Retrieve a list of records and extract the record IDs, faithfulness values, and answer relevance values:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73221592-5f4c-4b46-a3e1-7fc35665cad4"},"outputs":[],"source":["result = wos_client.data_sets.get_list_of_records(data_set_id = genaiq_dataset_id).result\n","result[\"records\"]\n","x = []\n","y_faithfulness = []\n","y_answer_relevance = []\n","for each in result[\"records\"]:\n","    x.append(each[\"metadata\"][\"id\"][-5:]) # Reading only last 5 characters to fit in the display\n","    y_faithfulness.append(each[\"entity\"][\"values\"][\"faithfulness\"])\n","    y_answer_relevance.append(each[\"entity\"][\"values\"][\"answer_relevance\"])"]},{"cell_type":"markdown","metadata":{"id":"da1026ca-ef39-46da-b54e-a4ba729358b5"},"source":["Plot faithfulness metrics against the records"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e21d678e-5e62-415d-aeb9-656a5123b010"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.scatter(x, y_faithfulness, marker='o')\n","\n","# Adding labels and title\n","plt.xlabel('X-axis - Record id (last 5 characters)')\n","plt.ylabel('Y-axis - Faithfulness')\n","plt.title('faithfulness vs record id')\n","\n","# Display the graph\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"1cd8f2d3-d7ed-4e61-9e3e-b82fa5e2e2e6"},"source":["Plot answer_relevance metrics against the records"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"06b113eb-0958-428a-b083-503c46fa1589"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.scatter(x, y_answer_relevance, marker='o')\n","\n","# Adding labels and title\n","plt.xlabel('X-axis - Record id (last 5 characters)')\n","plt.ylabel('Y-axis - Answer relevance')\n","plt.title('answer_relevance vs record id')\n","\n","# Display the graph\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"caa95616-b2a2-4688-8bf5-d3567cd04b41"},"source":["### Display the Drift V2 metrics"]},{"cell_type":"markdown","metadata":{"id":"ef312cde-213f-419e-81a1-a56667d6b92e"},"source":["### Read the Drift V2 monitor instance id\n","\n","The monitor instance ID of Drift V2 metrics is required for reading its metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9abc6430-9923-4183-88b3-5a3c5539eb90"},"outputs":[],"source":["monitor_definition_id = \"drift_v2\"\n","result = wos_client.monitor_instances.list(data_mart_id = data_mart_id,\n","                                           monitor_definition_id = monitor_definition_id,\n","                                           target_target_id = target_target_id,\n","                                           space_id = space_id).result\n","result_json = result._to_dict()\n","drift_monitor_id = result_json[\"monitor_instances\"][0][\"metadata\"][\"id\"]\n","drift_monitor_id"]},{"cell_type":"markdown","metadata":{"id":"2fd2935e-7f4b-494b-bcba-bc48c5f0e027"},"source":["Display the monitor metrics of Drift V2 generated through the risk evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6ac6d80-13ba-4a87-89cb-f9f2081dcc86"},"outputs":[],"source":["wos_client.monitor_instances.show_metrics(monitor_instance_id=drift_monitor_id, space_id=space_id)"]},{"cell_type":"markdown","metadata":{"id":"e67f354c-44e8-4304-bb3a-441257e256fb"},"source":["## Step 15 - See factsheets information from a space <a name=\"factsheetsproject\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11153994-83ac-45df-adec-004fb9e98ba1"},"outputs":[],"source":["factsheets_url = \"{}/ml-runtime/deployments/{}/details?space_id={}&context=wx&flush=true\".format(WML_CREDENTIALS[\"url\"], deployment_id, space_id)\n","    \n","print(\"User can navigate to the published facts in space {}\".format(factsheets_url))"]},{"cell_type":"markdown","metadata":{"id":"27f9c379-5abb-40f9-b256-92c35a6be183"},"source":["## Congratulations!\n","\n","You have completed this notebook. You can now navigate to the prompt template asset in your OpenScale project / space and click on the `Evaluate` tab to visualize the results in the UI."]},{"cell_type":"markdown","metadata":{},"source":["watsonx.governance"]},{"cell_type":"markdown","metadata":{},"source":["Copyright  2024 IBM."]}],"metadata":{"kernelspec":{"display_name":"Python 3.11","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
