{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af3fa5a9-d008-46db-8f13-d61fcd8cc6d3"
   },
   "source": [
    "# Design time notebook for Multi Lingual support of Generative AI Quality summarization metrics for IBM WatsonX.governance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26b7d8e1-db3f-4160-a6ee-3ed530642f15"
   },
   "source": [
    "This notebook demonstrates the metric results of the Generative AI Quality monitors for a prompt in Japanese. The various metrics computed across the particular task types are :\n",
    "- Summarization:\n",
    "    - Rouge Score\n",
    "    - Cosine Similarity\n",
    "\t- Jaccard Similarity\n",
    "    - Normalized Precision\n",
    "    - Normalized Recall\n",
    "    - Normalized F1 Score\n",
    "\t- Sari\n",
    "\t- Meteor\n",
    "    - HAP Score\n",
    "    - PII\n",
    "- Generation:\n",
    "    - Rouge Score\n",
    "    - Normalized Precision\n",
    "    - Normalized Recall\n",
    "    - Normalized F1 Score\n",
    "\t- Meteor\n",
    "    - HAP Score\n",
    "    - PII\n",
    "- Extraction:\n",
    "    - Rouge Score\n",
    "    - HAP Score\n",
    "    - PII\n",
    "- Question Answering(QA):\n",
    "    - Rouge Score\n",
    "    - HAP Score\n",
    "    - PII\n",
    "\n",
    "The notebook aims to show the Japanese metric values using a tokenizer in 2 different scenarios:\n",
    "- Scenario 1 : When `language_code` is passed in the configuration to use the in-built tokenizer for a particular language\n",
    "- Scenario 2 : When the user passes a custom tokenizer present on their system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "164a6bcd-cd14-4bb5-9f06-d07d20385222"
   },
   "source": [
    "**Note** : \n",
    "- The below given example is specific to the Japanese language.\n",
    "- HAP Score and PII do not support a custom tokenizer\n",
    "\n",
    "List of supported languages and the language code associated to these language:    \n",
    "- English : en\n",
    "- Japanese : ja\n",
    "- German : de\n",
    "- French : fr\n",
    "- Spanish : es\n",
    "- Arabic : ar\n",
    "- Italian : it\n",
    "- Portugese : pt\n",
    "- Korean : ko\n",
    "- Danish : da\n",
    "\n",
    "Requirements to run in another language: A dataset consisting of source(input) and reference columns. The predictions(output) column is also needed, but if not present then a suitable Hugging Face model can be used to generate the predictions for the above given inputs\n",
    "\n",
    "Changes to be made to run the cells in another language:\n",
    "- Replace the filename and url to fetch the dataset in [Step 2](#data)\n",
    "- If the predictions column is not present, replace the model id in [Step 3](#model) with that of a suitable Hugging Face model and run [Step 4](#predict)\n",
    "- Change the language code [here](#language_code) and run the cells in [Scenario 1](#scenario-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7622088-c7d1-468a-8d27-5780459c4cc0"
   },
   "source": [
    "## Contents\n",
    "\n",
    "- [Step 1 - Setup](#setup)\n",
    "- [Step 2 - Read data and store in dataframes](#data-1)\n",
    "- [Step 3 - Initialize Hugging Face model](#model)\n",
    "- [Step 4 - Generate the predictions for sample input](#predict)\n",
    "- [Step 5 - Set the language code](#language_code)\n",
    "\n",
    "- [Scenario 1 - Metrics with language code which uses the in-built WatsonNLP tokenizer](#scenario-1)\n",
    "    - [Summarization metrics](#summarization-1)\n",
    "        - [Step 1 - Configure the summarization metrics](#config-1.1.a)\n",
    "        - [Step 2 - Compute the summarization metrics](#compute-1.1.b)\n",
    "        - [Step 3 - Display the results](#results-1.1.c)\n",
    "    - [Generation metrics](#generation-1)\n",
    "        - [Step 1 - Read data and store in dataframes](#data-2)\n",
    "        - [Step 2 - Configure the generation metrics](#config-1.2.a)\n",
    "        - [Step 3 - Compute the generation metrics](#compute-1.2.b)\n",
    "        - [Step 4 - Display the results](#results-1.2.c)\n",
    "    - [Extraction metrics](#extraction-1)\n",
    "        - [Step 1 - Read data and store in dataframes](#data-3)\n",
    "        - [Step 2 - Configure the extraction metrics](#config-1.3.a)\n",
    "        - [Step 3 - Compute the extraction metrics](#compute-1.3.b)\n",
    "        - [Step 4 - Display the results](#results-1.3.c)\n",
    "    - [Question Answering(QA) metrics](#qa-1)\n",
    "        - [Step 1 - Read data and store in dataframes](#data-4)\n",
    "        - [Step 2 - Configure the question answering(qa) metrics](#config-1.4.a)\n",
    "        - [Step 3 - Compute the question answering(qa) metrics](#compute-1.4.b)\n",
    "        - [Step 4 - Display the results](#results-1.4.c)\n",
    "- [Scenario 2 - Metrics with custom tokenizer](#scenario-2)\n",
    "    - [Step 1 - Create a custom tokenizer](#custom_tokenizer)\n",
    "    - [Summarization metrics](#summarization-2)\n",
    "        - [Step 1 - Configure the summarization metrics](#config-2.1.a)\n",
    "        - [Step 2 - Compute the summarization metrics](#compute-2.1.b)\n",
    "        - [Step 3 - Display the results](#results-2.1.c)\n",
    "    - [Generation metrics](#generation-2)\n",
    "        - [Step 2 - Configure the generation metrics](#config-2.2.a)\n",
    "        - [Step 3 - Compute the generation metrics](#compute-2.2.b)\n",
    "        - [Step 4 - Display the results](#results-2.2.c)\n",
    "    - [Extraction metrics](#extraction-2)\n",
    "        - [Step 2 - Configure the extraction metrics](#config-2.3.a)\n",
    "        - [Step 3 - Compute the extraction metrics](#compute-2.3.b)\n",
    "        - [Step 4 - Display the results](#results-2.3.c)\n",
    "    - [Question Answering(QA) metrics](#qa-2)\n",
    "        - [Step 2 - Configure the question answering(qa) metrics](#config-2.4.a)\n",
    "        - [Step 3 - Compute the question answering(qa) metrics](#compute-2.4.b)\n",
    "        - [Step 4 - Display the results](#results-2.4.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67e4cb09-de1c-4bc6-bd2f-b2ff066d1ca0"
   },
   "source": [
    "## Step 1 - Setup <a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97c5f0ac-a081-4d41-a94e-63b6165f3661"
   },
   "source": [
    "### Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "794c2a16-d9d4-44a0-9e35-19e8e971613b"
   },
   "outputs": [],
   "source": [
    "!pip install -U ibm_watson_openscale | tail -n 1\n",
    "!pip install -U \"ibm-metrics-plugin[generative-ai-quality]~=3.0.11\" | tail -n 1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3ab4501-553b-4ba3-a932-7410c56bd6f6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "spacy.cli.download(\"ja_core_news_sm\")\n",
    "!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22f3adee-0684-4b8c-bdcb-fd4b9b71b34b"
   },
   "source": [
    "**Note**: you may need to restart the kernel to use updated libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f669847-1446-429d-96bf-0d9958cbb4d4"
   },
   "source": [
    "### Configure your credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9ccb571-e08d-4254-9796-4ce683ad6a51"
   },
   "source": [
    "#### Provision services and configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8158f13-3808-4aaf-8d2a-5ca62fe4c2cd"
   },
   "source": [
    "If you have not already, provision an instance of IBM Watson OpenScale using the [OpenScale link in the Cloud catalog](https://cloud.ibm.com/catalog/services/watson-openscale).\n",
    "Your Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below.\n",
    "**NOTE:** You can also get OpenScale `API_KEY` using IBM CLOUD CLI.\n",
    "\n",
    "How to install IBM Cloud (bluemix) console: [instruction](https://console.bluemix.net/docs/cli/reference/ibmcloud/download_cli.html#install_use)\n",
    "\n",
    "How to get api key using console:\n",
    "```\n",
    "bx login --sso\n",
    "bx iam api-key-create 'my_key'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3a11f13b-b737-4e7a-862e-57f1ac4c2ddc"
   },
   "outputs": [],
   "source": [
    "use_cpd = False\n",
    "CLOUD_API_KEY = \"****\"\n",
    "IAM_URL=\"https://iam.cloud.ibm.com\"\n",
    "SERVICE_URL=\"https://aiopenscale.cloud.ibm.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bb21fff-a6a3-41af-bd71-ad1ed0acf413"
   },
   "source": [
    "Uncomment the code and run the below cell only if you are running your notebook on a CPD cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7bf34a25-4077-4310-bd23-72444d809b3e"
   },
   "outputs": [],
   "source": [
    "# use_cpd = True\n",
    "# WOS_CREDENTIALS = {\n",
    "#     \"url\": \"xxxxx\",\n",
    "#     \"username\": \"xxxxx\",\n",
    "#     \"password\": \"xxxxx\",\n",
    "#     \"apikey\": \"xxxxx\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11f51bc0-4bc7-4fc6-9a2d-5a7336edb9f7"
   },
   "source": [
    "## Step 2 - Read and store data in individual pandas dataframes <a id=\"data-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b7bb384-9a29-41f3-87ff-5f9622adeefa"
   },
   "source": [
    "### Read the data\n",
    "\n",
    "Download the sample \"llm_content_summarization_ja\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8549da81-d788-406b-ab5d-f7dd52b655a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-21 06:17:55--  https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_summarization_ja.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26758 (26K) [text/plain]\n",
      "Saving to: ‘llm_content_summarization_ja.csv’\n",
      "\n",
      "llm_content_summari 100%[===================>]  26.13K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-11-21 06:17:56 (47.0 MB/s) - ‘llm_content_summarization_ja.csv’ saved [26758/26758]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename_summarization = \"llm_content_summarization_ja.csv\"\n",
    "!rm -fr \"llm_content_summarization_ja.csv\"\n",
    "!wget \"https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_summarization_ja.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce77a2b5-9ace-43b6-881d-b90d918f0eba"
   },
   "source": [
    "### Converting the data into pandas dataframe\n",
    "\n",
    "Extracting the columns and creating individual data frames for `input`, `prediction` and `reference` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3dfab1eb-0f5f-40f6-9bbe-5223a46dfae8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "llm_data_ja_summarization = pd.read_csv(filename_summarization)\n",
    "df_input_ja_summarization = llm_data_ja_summarization[['input_text']].copy()\n",
    "df_reference_ja_summarization = llm_data_ja_summarization[['reference_summary']].copy()\n",
    "df_generated_ja_summarization = llm_data_ja_summarization[['generated_predictions']].copy() # Comment if using loacl LLM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9126971f-ba10-44dd-96e2-600d73a9a2a6"
   },
   "source": [
    "## Step 3 - Initialize a foundation model from Hugging Face\n",
    "<a id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba0a5385-ca22-4ddc-b7c7-6bac871e4472"
   },
   "source": [
    "Uncomment the following cells to create a Hugging face model and generate the predictions for Japanese\n",
    "\n",
    "Model used - p1atdev/mt5-base-xlsum-ja-v1.1 : Japanese summarization model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The below given example is specific to the summarization task type. The other task types mentioned will need to be run with the suitable models and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "15dc81bb-cbb2-4df9-b557-678915fa81b3"
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# def summarize_fn_ja(input_text):\n",
    "#     seq2seq = pipeline(\"summarization\", model=\"p1atdev/mt5-base-xlsum-ja-v1.1\")\n",
    "#     result = seq2seq(input_text)\n",
    "#     return result[0]['summary_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c5f6aff-17d1-4f78-937f-8468bd8a9c02"
   },
   "source": [
    "## Step 4 - Generate predictions for sample input\n",
    "<a id=\"predict\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a50a6d4a-db08-461d-87a7-11851a055598"
   },
   "source": [
    "Creating an empty list and storing the generated predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bcba9968-09ed-458c-89a6-04d91ec48290"
   },
   "outputs": [],
   "source": [
    "# generated_predictions_ja = []\n",
    "# for input in df_input_ja_summarization[\"input_text\"]:\n",
    "#     generated_predictions_ja.append(summarize_fn_ja(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e3f73a7-3abd-4c59-8ea1-3d10413c01fc"
   },
   "source": [
    "Converting the list to an individual dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c32df374-2521-448a-9eec-32c16520d6ad"
   },
   "outputs": [],
   "source": [
    "# df_generated_ja_summarization = pd.DataFrame(columns=[\"generated_predictions\"])\n",
    "# df_generated_ja_summarization['generated_predictions'] = generated_predictions_ja\n",
    "# print(df_generated_ja_summarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "043e5879-7f5e-48b0-aba2-b3001f956eb7"
   },
   "source": [
    "### Setting the language code <a id=\"language_code\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "27401942-804c-4e80-b5a2-0f815ba603db"
   },
   "outputs": [],
   "source": [
    "language_code = \"ja\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94ac6115-a810-4204-931c-ccf14447c863"
   },
   "source": [
    "## Scenario 1 - Metrics with `language_code` which uses the in-built WatsonNLP tokenizer <a id=\"scenario-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c22b1c72-167d-47f8-b518-1bce7b6fce87"
   },
   "source": [
    "### IBM watsonx.governance authentication and verifying client version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7c94290b-d300-4ad0-9612-75d03951d601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.41\n"
     ]
    }
   ],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator,BearerTokenAuthenticator,CloudPakForDataAuthenticator\n",
    "\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "\n",
    "if use_cpd:\n",
    "    authenticator = CloudPakForDataAuthenticator(\n",
    "            url=WOS_CREDENTIALS['url'],\n",
    "            username=WOS_CREDENTIALS['username'],\n",
    "            apikey=WOS_CREDENTIALS['apikey'],\n",
    "            disable_ssl_verification=True,\n",
    "        )\n",
    "    \n",
    "    client = APIClient(service_url=WOS_CREDENTIALS['url'],authenticator=authenticator)\n",
    "    print(client.version)\n",
    "else:\n",
    "    authenticator = IAMAuthenticator(apikey=CLOUD_API_KEY, url=IAM_URL)\n",
    "    client = APIClient(authenticator=authenticator)\n",
    "    print(client.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dc08be32-a77c-4f0b-a977-e00fec73a442"
   },
   "outputs": [],
   "source": [
    "from ibm_metrics_plugin.metrics.llm.utils.constants import LLMTextMetricGroup\n",
    "from ibm_metrics_plugin.metrics.llm.utils.constants import LLMSummarizationMetrics\n",
    "from ibm_metrics_plugin.metrics.llm.utils.constants import LLMCommonMetrics\n",
    "from ibm_metrics_plugin.metrics.llm.utils.constants import LLMGenerationMetrics\n",
    "from ibm_metrics_plugin.metrics.llm.utils.constants import LLMExtractionMetrics\n",
    "from ibm_metrics_plugin.metrics.llm.utils.constants import LLMQAMetrics\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization metrics<a id=\"summarization-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30a12c5b-2be5-4a81-be35-12afb165e7c6"
   },
   "source": [
    "#### Step 1 - Configure summarization metrics<a id=\"config-1.1.a\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ac7106e7-f9af-45b8-ae8c-273dfe1cdd9b"
   },
   "outputs": [],
   "source": [
    "metric_config_1_summarization = {   \n",
    "    \"configuration\": {\n",
    "        LLMTextMetricGroup.SUMMARIZATION.value: {\n",
    "            LLMSummarizationMetrics.ROUGE_SCORE.value: {},\n",
    "            LLMSummarizationMetrics.COSINE_SIMILARITY.value: {},\n",
    "            LLMSummarizationMetrics.JACCARD_SIMILARITY.value: {},\n",
    "            LLMSummarizationMetrics.NORMALIZED_PRECISION.value: {},\n",
    "            LLMSummarizationMetrics.NORMALIZED_RECALL.value: {},\n",
    "            LLMSummarizationMetrics.NORMALIZED_F1_SCORE.value: {},\n",
    "            LLMSummarizationMetrics.SARI.value: {},\n",
    "            LLMSummarizationMetrics.METEOR.value: {},\n",
    "            LLMCommonMetrics.HAP_SCORE.value: {},\n",
    "            LLMCommonMetrics.PII_DETECTION.value: {\n",
    "                \"language_code\" : language_code\n",
    "            }\n",
    "        },\n",
    "        \"language_code\" : language_code\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ac36b3cf-30fc-4252-9f95-597b35a1f8b0"
   },
   "source": [
    "#### Step 2 - Compute the summarization metrics<a id=\"compute-1.1.b\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6016025b-80e8-411e-8f77-02b7c91f03fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/wsuser/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "result_ja_1_summarization = client.llm_metrics.compute_metrics(metric_config_1_summarization,\n",
    "                                                sources = df_input_ja_summarization, \n",
    "                                                predictions = df_generated_ja_summarization, \n",
    "                                                references = df_reference_ja_summarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f9b69d1-a4c4-45d2-80c4-d93f62cb1baf"
   },
   "source": [
    "#### Step 3 - Display the results<a id=\"results-1.1.c\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "474465a6-9050-4205-924a-271f38297c1f"
   },
   "source": [
    "Fetching the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "012ab200-9470-4f29-867c-ca8568262763"
   },
   "outputs": [],
   "source": [
    "final_results_ja_1_summarization = client.llm_metrics.get_metrics_result(configuration=metric_config_1_summarization, \n",
    "                                                           metrics_result=result_ja_1_summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2d8609c9-8464-40f4-a250-257135d15009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"cosine_similarity\": {\n",
      "    \"total_records\": 20,\n",
      "    \"max\": 0.4972134156783251,\n",
      "    \"mean\": 0.3267,\n",
      "    \"metric_value\": 0.3267,\n",
      "    \"min\": 0.20829453553574567\n",
      "  },\n",
      "  \"hap_score\": {\n",
      "    \"total_records\": 20,\n",
      "    \"max\": 0.10210397094488144,\n",
      "    \"mean\": 0.0553,\n",
      "    \"metric_value\": 0.0553,\n",
      "    \"min\": 0.02366599254310131\n",
      "  },\n",
      "  \"jaccard_similarity\": {\n",
      "    \"total_records\": 20,\n",
      "    \"max\": 0.40476190476190477,\n",
      "    \"mean\": 0.2605,\n",
      "    \"metric_value\": 0.2605,\n",
      "    \"min\": 0.14754098360655737\n",
      "  },\n",
      "  \"meteor\": {\n",
      "    \"metric_value\": 0.3211,\n",
      "    \"total_records\": 20\n",
      "  },\n",
      "  \"normalized_f1\": {\n",
      "    \"total_records\": 20,\n",
      "    \"max\": 0.5454545454545455,\n",
      "    \"mean\": 0.3755,\n",
      "    \"metric_value\": 0.3755,\n",
      "    \"min\": 0.22988505747126436\n",
      "  },\n",
      "  \"normalized_precision\": {\n",
      "    \"total_records\": 20,\n",
      "    \"max\": 0.72,\n",
      "    \"mean\": 0.4214,\n",
      "    \"metric_value\": 0.4214,\n",
      "    \"min\": 0.23529411764705882\n",
      "  },\n",
      "  \"normalized_recall\": {\n",
      "    \"total_records\": 20,\n",
      "    \"max\": 0.8,\n",
      "    \"mean\": 0.4073,\n",
      "    \"metric_value\": 0.4073,\n",
      "    \"min\": 0.16129032258064516\n",
      "  },\n",
      "  \"pii\": {\n",
      "    \"total_records\": 20,\n",
      "    \"max\": 0,\n",
      "    \"mean\": 0.0,\n",
      "    \"metric_value\": 0.0,\n",
      "    \"min\": 0\n",
      "  },\n",
      "  \"rouge_score\": {\n",
      "    \"rouge1\": 0.3755,\n",
      "    \"rouge1_recall\": 0.4073,\n",
      "    \"rouge2\": 0.1853,\n",
      "    \"rouge2_recall\": 0.1955,\n",
      "    \"rougeL\": 0.2903,\n",
      "    \"rougeL_recall\": 0.3115,\n",
      "    \"rougeLsum\": 0.2903,\n",
      "    \"rougeLsum_recall\": 0.3115,\n",
      "    \"total_records\": 20\n",
      "  },\n",
      "  \"sari\": {\n",
      "    \"metric_value\": 36.5078,\n",
      "    \"total_records\": 20\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(final_results_ja_1_summarization,indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3377870e-30d6-4431-9ed0-b7d0e05fedbe"
   },
   "source": [
    "**Note:** If the above results display with a \"state\": \"in_progress\" status, you can re-run the above cells as the computation of the metrics is still in progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation metrics<a id=\"generation-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Read data and store in dataframes<a id=\"data-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data\n",
    "\n",
    "Download the sample \"llm_content_generation_ja\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "16b291da-dc80-4639-ad50-ceeccbdf36fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-21 06:22:42--  https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_generation_ja.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14183 (14K) [text/plain]\n",
      "Saving to: ‘llm_content_generation_ja.csv’\n",
      "\n",
      "llm_content_generat 100%[===================>]  13.85K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-11-21 06:22:42 (44.1 MB/s) - ‘llm_content_generation_ja.csv’ saved [14183/14183]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename_generation = \"llm_content_generation_ja.csv\"\n",
    "!rm -fr \"llm_content_generation_ja.csv\"\n",
    "!wget \"https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_generation_ja.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data into pandas dataframe\n",
    "\n",
    "Extracting the columns and creating individual data frames for `input`, `prediction` and `reference` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ed337d61-69dd-4f1c-b5df-ee1a0a030489"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "llm_data_ja_generation = pd.read_csv(filename_generation)\n",
    "df_input_ja_generation = llm_data_ja_generation[['question']].copy()\n",
    "df_reference_ja_generation = llm_data_ja_generation[['reference_text']].copy()\n",
    "df_generated_ja_generation = llm_data_ja_generation[['generated_text']].copy() # Comment if using loacl LLM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Configure generation metrics<a id=\"config-1.2.a\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "628cfcb1-51a9-4398-be6f-439850388e43"
   },
   "outputs": [],
   "source": [
    "metric_config_1_generation = {   \n",
    "    \"configuration\": {\n",
    "        LLMTextMetricGroup.GENERATION.value: {\n",
    "            LLMGenerationMetrics.ROUGE_SCORE.value: {},\n",
    "            LLMGenerationMetrics.NORMALIZED_PRECISION.value: {},\n",
    "            LLMGenerationMetrics.NORMALIZED_RECALL.value: {},\n",
    "            LLMGenerationMetrics.NORMALIZED_F1_SCORE.value: {},\n",
    "            LLMGenerationMetrics.METEOR.value: {},\n",
    "            LLMCommonMetrics.HAP_SCORE.value: {},\n",
    "            LLMCommonMetrics.PII_DETECTION.value: {\n",
    "                \"language_code\" : language_code\n",
    "            }\n",
    "        },\n",
    "        \"language_code\" : language_code\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Compute the generation metrics<a id=\"compute-1.2.b\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6bcd7c61-1d9c-4ca9-b7ce-74847db5eb62"
   },
   "outputs": [],
   "source": [
    "result_ja_1_generation = client.llm_metrics.compute_metrics(metric_config_1_generation,\n",
    "                                                sources = df_input_ja_generation, \n",
    "                                                predictions = df_generated_ja_generation, \n",
    "                                                references = df_reference_ja_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Display the results<a id=\"results-1.2.c\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "4b918fc8-339c-467b-9029-b3fa298c9074"
   },
   "outputs": [],
   "source": [
    "final_results_ja_1_generation = client.llm_metrics.get_metrics_result(configuration=metric_config_1_generation, \n",
    "                                                           metrics_result=result_ja_1_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "84666aa8-daf2-4220-810d-44b53cfba9b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"hap_score\": {\n",
      "    \"total_records\": 23,\n",
      "    \"max\": 0.12608997523784637,\n",
      "    \"mean\": 0.0141,\n",
      "    \"metric_value\": 0.0141,\n",
      "    \"min\": 0.0021147574298083782\n",
      "  },\n",
      "  \"meteor\": {\n",
      "    \"metric_value\": 0.6902,\n",
      "    \"total_records\": 23\n",
      "  },\n",
      "  \"normalized_f1\": {\n",
      "    \"total_records\": 23,\n",
      "    \"max\": 0.9481481481481482,\n",
      "    \"mean\": 0.8329,\n",
      "    \"metric_value\": 0.8329,\n",
      "    \"min\": 0.6399999999999999\n",
      "  },\n",
      "  \"normalized_precision\": {\n",
      "    \"total_records\": 23,\n",
      "    \"max\": 1.0,\n",
      "    \"mean\": 0.9981,\n",
      "    \"metric_value\": 0.9981,\n",
      "    \"min\": 0.9722222222222222\n",
      "  },\n",
      "  \"normalized_recall\": {\n",
      "    \"total_records\": 23,\n",
      "    \"max\": 0.9142857142857143,\n",
      "    \"mean\": 0.7201,\n",
      "    \"metric_value\": 0.7201,\n",
      "    \"min\": 0.47058823529411764\n",
      "  },\n",
      "  \"pii\": {\n",
      "    \"total_records\": 23,\n",
      "    \"max\": 0,\n",
      "    \"mean\": 0.0,\n",
      "    \"metric_value\": 0.0,\n",
      "    \"min\": 0\n",
      "  },\n",
      "  \"rouge_score\": {\n",
      "    \"rouge1\": 0.8328,\n",
      "    \"rouge1_recall\": 0.7202,\n",
      "    \"rouge2\": 0.8257,\n",
      "    \"rouge2_recall\": 0.7118,\n",
      "    \"rougeL\": 0.8328,\n",
      "    \"rougeL_recall\": 0.7202,\n",
      "    \"rougeLsum\": 0.8328,\n",
      "    \"rougeLsum_recall\": 0.7202,\n",
      "    \"total_records\": 23\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(final_results_ja_1_generation,indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction metrics<a id=\"extraction-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Read data and store in dataframes<a id=\"data-3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data\n",
    "\n",
    "Download the sample \"llm_content_extraction_ja\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "be3e1eb9-c45a-4662-9dc3-a06aa2e05bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-21 06:24:11--  https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_extraction_ja.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2478 (2.4K) [text/plain]\n",
      "Saving to: ‘llm_content_extraction_ja.csv’\n",
      "\n",
      "llm_content_extract 100%[===================>]   2.42K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-11-21 06:24:11 (21.4 MB/s) - ‘llm_content_extraction_ja.csv’ saved [2478/2478]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename_extraction = \"llm_content_extraction_ja.csv\"\n",
    "!rm -fr \"llm_content_extraction_ja.csv\"\n",
    "!wget \"https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_extraction_ja.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data into pandas dataframe\n",
    "\n",
    "Extracting the columns and creating individual data frames for `input`, `prediction` and `reference` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "e01a8c84-d9fe-4602-a5b7-f19ae177c1d6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "llm_data_ja_extraction = pd.read_csv(filename_extraction)\n",
    "df_input_ja_extraction = llm_data_ja_extraction[['input_text']].copy()\n",
    "df_reference_ja_extraction = llm_data_ja_extraction[['reference_text']].copy()\n",
    "df_generated_ja_extraction = llm_data_ja_extraction[['generated_text']].copy() # Comment if using loacl LLM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Configure extraction metrics<a id=\"config-1.3.a\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "014f0e34-5e74-4b9e-b0d6-7747f21b61d2"
   },
   "outputs": [],
   "source": [
    "metric_config_1_extraction = {   \n",
    "    \"configuration\": {\n",
    "        LLMTextMetricGroup.EXTRACTION.value: {\n",
    "            LLMExtractionMetrics.ROUGE_SCORE.value: {},\n",
    "            LLMCommonMetrics.HAP_SCORE.value: {},\n",
    "            LLMCommonMetrics.PII_DETECTION.value: {\n",
    "                \"language_code\" : language_code\n",
    "            }\n",
    "        },\n",
    "        \"language_code\" : language_code\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Compute the extraction metrics<a id=\"compute-1.3.b\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "eeccf93d-e6d3-4a34-8918-d632c3d3273b"
   },
   "outputs": [],
   "source": [
    "result_ja_1_extraction = client.llm_metrics.compute_metrics(metric_config_1_extraction,\n",
    "                                                sources = df_input_ja_extraction, \n",
    "                                                predictions = df_generated_ja_extraction, \n",
    "                                                references = df_reference_ja_extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Display the results<a id=\"results-1.3.c\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "e941ccbe-0cb7-4a87-9b50-69a031e24e89"
   },
   "outputs": [],
   "source": [
    "final_results_ja_1_extraction = client.llm_metrics.get_metrics_result(configuration=metric_config_1_extraction, \n",
    "                                                           metrics_result=result_ja_1_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0810ace7-1bf3-4e37-ab9f-ddb00d3c1b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"hap_score\": {\n",
      "    \"total_records\": 10,\n",
      "    \"max\": 0.1282653957605362,\n",
      "    \"mean\": 0.0241,\n",
      "    \"metric_value\": 0.0241,\n",
      "    \"min\": 0.0043441494926810265\n",
      "  },\n",
      "  \"pii\": {\n",
      "    \"total_records\": 10,\n",
      "    \"max\": 0.8,\n",
      "    \"mean\": 0.56,\n",
      "    \"metric_value\": 0.56,\n",
      "    \"min\": 0.0\n",
      "  },\n",
      "  \"rouge_score\": {\n",
      "    \"rouge1\": 0.9,\n",
      "    \"rouge1_recall\": 0.9,\n",
      "    \"rouge2\": 0.8,\n",
      "    \"rouge2_recall\": 0.8,\n",
      "    \"rougeL\": 0.9,\n",
      "    \"rougeL_recall\": 0.9,\n",
      "    \"rougeLsum\": 0.9,\n",
      "    \"rougeLsum_recall\": 0.9,\n",
      "    \"total_records\": 10\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(final_results_ja_1_extraction,indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering(QA) metrics<a id=\"qa-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Read data and store in dataframes<a id=\"data-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data\n",
    "\n",
    "Download the sample \"llm_content_qa_ja\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "e454ea6b-f53c-419c-aedb-1ea885761e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-21 06:25:24--  https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_qa_ja.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4407 (4.3K) [text/plain]\n",
      "Saving to: ‘llm_content_qa_ja.csv’\n",
      "\n",
      "llm_content_qa_ja.c 100%[===================>]   4.30K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-11-21 06:25:24 (34.8 MB/s) - ‘llm_content_qa_ja.csv’ saved [4407/4407]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename_qa = \"llm_content_qa_ja.csv\"\n",
    "!rm -fr \"llm_content_qa_ja.csv\"\n",
    "!wget \"https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_qa_ja.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data into pandas dataframe\n",
    "\n",
    "Extracting the columns and creating individual data frames for `input`, `prediction` and `reference` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "5bdbbeba-3e0d-4992-aeaf-64de778c142c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "llm_data_ja_qa = pd.read_csv(filename_qa)\n",
    "df_input_ja_qa = llm_data_ja_qa[['question']].copy()\n",
    "df_reference_ja_qa = llm_data_ja_qa[['answers']].copy()\n",
    "df_generated_ja_qa = llm_data_ja_qa[['answers']].copy() # Comment if using loacl LLM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Configure question answering metrics<a id=\"config-1.4.a\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "7daf6daa-cd5a-4f4b-a2f3-a2860027ded6"
   },
   "outputs": [],
   "source": [
    "metric_config_1_qa = {   \n",
    "    \"configuration\": {\n",
    "        LLMTextMetricGroup.QA.value: {\n",
    "            LLMQAMetrics.ROUGE_SCORE.value: {},\n",
    "            LLMCommonMetrics.HAP_SCORE.value: {},\n",
    "            LLMCommonMetrics.PII_DETECTION.value: {\n",
    "                \"language_code\" : language_code\n",
    "            }\n",
    "        },\n",
    "        \"language_code\" : language_code\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Compute the question answering(qa) metrics<a id=\"compute-1.4.b\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "01298e9f-d536-486c-ac46-ba9e9b1f1794"
   },
   "outputs": [],
   "source": [
    "result_ja_1_qa = client.llm_metrics.compute_metrics(metric_config_1_qa,\n",
    "                                                sources = df_input_ja_qa, \n",
    "                                                predictions = df_generated_ja_qa,\n",
    "                                                references=df_reference_ja_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Display the results<a id=\"results-1.4.c\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "01bcafb6-7d88-4d79-94c1-181b7954fb98"
   },
   "outputs": [],
   "source": [
    "final_results_ja_1_qa = client.llm_metrics.get_metrics_result(configuration=metric_config_1_qa, \n",
    "                                                           metrics_result=result_ja_1_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "226f0882-ab69-4713-b16b-8a1380ea3095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"hap_score\": {\n",
      "    \"total_records\": 50,\n",
      "    \"max\": 0.9634731411933899,\n",
      "    \"mean\": 0.0748,\n",
      "    \"metric_value\": 0.0748,\n",
      "    \"min\": 0.001772725721821189\n",
      "  },\n",
      "  \"pii\": {\n",
      "    \"total_records\": 50,\n",
      "    \"max\": 0,\n",
      "    \"mean\": 0.0,\n",
      "    \"metric_value\": 0.0,\n",
      "    \"min\": 0\n",
      "  },\n",
      "  \"rouge_score\": {\n",
      "    \"rouge1\": 1.0,\n",
      "    \"rouge1_recall\": 1.0,\n",
      "    \"rouge2\": 0.72,\n",
      "    \"rouge2_recall\": 0.72,\n",
      "    \"rougeL\": 1.0,\n",
      "    \"rougeL_recall\": 1.0,\n",
      "    \"rougeLsum\": 1.0,\n",
      "    \"rougeLsum_recall\": 1.0,\n",
      "    \"total_records\": 50\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(final_results_ja_1_qa,indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2f7e4e0-dfab-40e3-8de7-80abd85dca7f"
   },
   "source": [
    "## Scenario 2 - Metrics with custom tokenizer <a id=\"scenario-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1465041-309a-4a4c-8c41-67c23cc455b0"
   },
   "source": [
    "### Creating a custom tokenizer using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "716101c2-dcc2-4704-9994-8d01c2d2d5c3"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "265bf670-2ba5-4769-aaa9-fdd090c04a76"
   },
   "outputs": [],
   "source": [
    "def get_language_model_sp(language='en'):\n",
    "    nlp = None\n",
    "    if language=='en':\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    if language=='ja':\n",
    "        nlp = spacy.load(\"ja_core_news_sm\")\n",
    "    return nlp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "b1fc48cb-0868-4ef5-b634-4b4ff1b15ed5"
   },
   "outputs": [],
   "source": [
    "class MyCustomTokenizer():    \n",
    "    def __init__(self, language = 'en'):\n",
    "        self.language = language\n",
    "        self.tokenizer = None\n",
    "    \n",
    "    def tokenize(self, input_text):\n",
    "        tokens = []\n",
    "        nlp = get_language_model_sp(self.language)        \n",
    "        doc = nlp(input_text)\n",
    "        for token in doc:\n",
    "            tokens.append(str(token))\n",
    "        return tokens\n",
    "    \n",
    "    def __call__(self, input_text):\n",
    "        return self.tokenize(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "65ee1739-1699-4bf4-a625-b2a18339df22"
   },
   "outputs": [],
   "source": [
    "my_custom_tokenizer_ja = MyCustomTokenizer(language_code).tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization Metrics<a id=\"summarization-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "266b5b53-26fb-4f12-974c-7c29163e42f2"
   },
   "source": [
    "### Step 1 - Configure summarization metrics<a id=\"config-2.1.a\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "b51855fc-34f6-4ff2-96e2-5abdf723c8c4"
   },
   "outputs": [],
   "source": [
    "metric_config_2_summarization = {   \n",
    "    \"configuration\": {\n",
    "        LLMTextMetricGroup.SUMMARIZATION.value: {\n",
    "            LLMSummarizationMetrics.ROUGE_SCORE.value: {},\n",
    "            LLMSummarizationMetrics.COSINE_SIMILARITY.value: {},\n",
    "            LLMSummarizationMetrics.JACCARD_SIMILARITY.value: {},\n",
    "            LLMSummarizationMetrics.NORMALIZED_PRECISION.value: {},\n",
    "            LLMSummarizationMetrics.NORMALIZED_RECALL.value: {},\n",
    "            LLMSummarizationMetrics.NORMALIZED_F1_SCORE.value: {},\n",
    "            LLMSummarizationMetrics.SARI.value: {},\n",
    "            LLMSummarizationMetrics.METEOR.value: {}\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a671fd6d-79d3-4e10-973c-4494c314a131"
   },
   "source": [
    "### Step 2 - Compute the summarization metrics<a id=\"compute-2.1.b\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "1df9086a-1395-4c55-bda9-c231e272d148"
   },
   "outputs": [],
   "source": [
    "result_ja_2_summarization = client.llm_metrics.compute_metrics(metric_config_2_summarization, \n",
    "                                                sources = df_input_ja_summarization, \n",
    "                                                predictions = df_generated_ja_summarization, \n",
    "                                                references = df_reference_ja_summarization, \n",
    "                                                tokenizer = my_custom_tokenizer_ja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "811b4eab-014d-4dbd-99e2-b58166598c57"
   },
   "source": [
    "### Step 3 - Display the results<a id=\"results-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "c80bc239-eefa-4ab4-a94c-6ab3d1c6ae66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"normalized_precision\": {\n",
      "    \"metric_value\": 0.4330320512820512,\n",
      "    \"mean\": 0.4330320512820512,\n",
      "    \"min\": 0.20512820512820512,\n",
      "    \"max\": 0.7083333333333334,\n",
      "    \"std\": 0.1250694049511426,\n",
      "    \"total_records\": 20\n",
      "  },\n",
      "  \"sari\": {\n",
      "    \"metric_value\": 37.189037853372184,\n",
      "    \"total_records\": 20\n",
      "  },\n",
      "  \"rouge_score\": {\n",
      "    \"rouge1\": 0.3899,\n",
      "    \"rouge1_recall\": 0.4272,\n",
      "    \"rouge2\": 0.2031,\n",
      "    \"rouge2_recall\": 0.2203,\n",
      "    \"rougeL\": 0.2986,\n",
      "    \"rougeL_recall\": 0.3229,\n",
      "    \"rougeLsum\": 0.2986,\n",
      "    \"rougeLsum_recall\": 0.3229,\n",
      "    \"total_records\": 20\n",
      "  },\n",
      "  \"jaccard_similarity\": {\n",
      "    \"metric_value\": 0.2758702031822637,\n",
      "    \"mean\": 0.2758702031822637,\n",
      "    \"min\": 0.16666666666666666,\n",
      "    \"max\": 0.38095238095238093,\n",
      "    \"std\": 0.07698297898073732,\n",
      "    \"total_records\": 20\n",
      "  },\n",
      "  \"normalized_recall\": {\n",
      "    \"metric_value\": 0.4271739649831853,\n",
      "    \"mean\": 0.4271739649831853,\n",
      "    \"min\": 0.16176470588235295,\n",
      "    \"max\": 0.8125,\n",
      "    \"std\": 0.1994148081880162,\n",
      "    \"total_records\": 20\n",
      "  },\n",
      "  \"meteor\": {\n",
      "    \"metric_value\": 0.3368134932013981,\n",
      "    \"total_records\": 20\n",
      "  },\n",
      "  \"cosine_similarity\": {\n",
      "    \"metric_value\": 0.340025654430554,\n",
      "    \"mean\": 0.340025654430554,\n",
      "    \"min\": 0.19468993337739407,\n",
      "    \"max\": 0.4863954385551848,\n",
      "    \"std\": 0.08588403829894321,\n",
      "    \"total_records\": 20\n",
      "  },\n",
      "  \"normalized_f1\": {\n",
      "    \"metric_value\": 0.38993368875948925,\n",
      "    \"mean\": 0.38993368875948925,\n",
      "    \"min\": 0.2391304347826087,\n",
      "    \"max\": 0.5306122448979591,\n",
      "    \"std\": 0.0987514928187935,\n",
      "    \"total_records\": 20\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result_ja_2_summarization,indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation metrics<a id=\"generation-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Configure generation metrics<a id=\"config-2.2.a\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "d27e802e-6642-451d-aca4-d994df681bef"
   },
   "outputs": [],
   "source": [
    "metric_config_2_generation = {   \n",
    "    \"configuration\": {\n",
    "        LLMTextMetricGroup.GENERATION.value: {\n",
    "            LLMGenerationMetrics.ROUGE_SCORE.value: {},\n",
    "            LLMGenerationMetrics.NORMALIZED_PRECISION.value: {},\n",
    "            LLMGenerationMetrics.NORMALIZED_RECALL.value: {},\n",
    "            LLMGenerationMetrics.NORMALIZED_F1_SCORE.value: {},\n",
    "            LLMGenerationMetrics.METEOR.value: {}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Compute the generation metrics<a id=\"compute-2.2.b\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "78a4dc78-ac15-4307-8a47-b0311f157e90"
   },
   "outputs": [],
   "source": [
    "result_ja_2_generation = client.llm_metrics.compute_metrics(metric_config_2_generation,\n",
    "                                                sources = df_input_ja_generation, \n",
    "                                                predictions = df_generated_ja_generation, \n",
    "                                                references = df_reference_ja_generation,\n",
    "                                                tokenizer = my_custom_tokenizer_ja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Display the results<a id=\"results-2.2.c\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "11e3c55f-0a20-443d-9dd5-8ae436f1949a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"normalized_precision\": {\n",
      "    \"metric_value\": 0.9983850931677019,\n",
      "    \"mean\": 0.9983850931677019,\n",
      "    \"min\": 0.9761904761904762,\n",
      "    \"max\": 1.0,\n",
      "    \"std\": 0.00545610526818546,\n",
      "    \"total_records\": 23\n",
      "  },\n",
      "  \"rouge_score\": {\n",
      "    \"rouge1\": 0.8351,\n",
      "    \"rouge1_recall\": 0.7233,\n",
      "    \"rouge2\": 0.8287,\n",
      "    \"rouge2_recall\": 0.7158,\n",
      "    \"rougeL\": 0.8351,\n",
      "    \"rougeL_recall\": 0.7233,\n",
      "    \"rougeLsum\": 0.8351,\n",
      "    \"rougeLsum_recall\": 0.7233,\n",
      "    \"total_records\": 23\n",
      "  },\n",
      "  \"normalized_recall\": {\n",
      "    \"metric_value\": 0.7232754525118498,\n",
      "    \"mean\": 0.7232754525118498,\n",
      "    \"min\": 0.4807692307692308,\n",
      "    \"max\": 0.925,\n",
      "    \"std\": 0.0953663927099713,\n",
      "    \"total_records\": 23\n",
      "  },\n",
      "  \"meteor\": {\n",
      "    \"metric_value\": 0.6921405027118602,\n",
      "    \"total_records\": 23\n",
      "  },\n",
      "  \"normalized_f1\": {\n",
      "    \"metric_value\": 0.8351304305697805,\n",
      "    \"mean\": 0.8351304305697805,\n",
      "    \"min\": 0.6493506493506493,\n",
      "    \"max\": 0.9548387096774195,\n",
      "    \"std\": 0.06538224681019711,\n",
      "    \"total_records\": 23\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result_ja_2_generation,indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction metrics<a id=\"extraction-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Configure extraction metrics<a id=\"config-2.3.a\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "d51dac35-6fcf-49c8-80f7-859c9e48c188"
   },
   "outputs": [],
   "source": [
    "metric_config_2_extraction = {   \n",
    "    \"configuration\": {\n",
    "        LLMTextMetricGroup.EXTRACTION.value: {\n",
    "            LLMExtractionMetrics.ROUGE_SCORE.value: {}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Compute the extraction metrics<a id=\"compute-2.3.b\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "4894fa90-17ff-4ea8-aa18-5d7d5833644e"
   },
   "outputs": [],
   "source": [
    "result_ja_2_extraction = client.llm_metrics.compute_metrics(metric_config_2_extraction,\n",
    "                                                sources = df_input_ja_extraction, \n",
    "                                                predictions = df_generated_ja_extraction, \n",
    "                                                references = df_reference_ja_extraction,\n",
    "                                                tokenizer = my_custom_tokenizer_ja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Display the results<a id=\"results-2.3.c\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "82b03fa0-2678-4078-8d7b-3ac112ee1f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rouge_score\": {\n",
      "    \"rouge1\": 0.9,\n",
      "    \"rouge1_recall\": 0.9,\n",
      "    \"rouge2\": 0.8,\n",
      "    \"rouge2_recall\": 0.8,\n",
      "    \"rougeL\": 0.9,\n",
      "    \"rougeL_recall\": 0.9,\n",
      "    \"rougeLsum\": 0.9,\n",
      "    \"rougeLsum_recall\": 0.9,\n",
      "    \"total_records\": 10\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result_ja_2_extraction,indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering(QA) metrics<a id=\"qa-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Configure question answering metrics<a id=\"config-2.4.a\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "56dfb7de-1cc8-46a5-afc5-54629f3e1831"
   },
   "outputs": [],
   "source": [
    "metric_config_2_qa = {   \n",
    "    \"configuration\": {\n",
    "        LLMTextMetricGroup.QA.value: {\n",
    "            LLMQAMetrics.ROUGE_SCORE.value: {}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Compute the question answering(qa) metrics<a id=\"compute-2.4.b\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "c3f14a82-8ac4-4489-8f72-f368ffba76c3"
   },
   "outputs": [],
   "source": [
    "result_ja_2_qa = client.llm_metrics.compute_metrics(metric_config_2_qa,\n",
    "                                                sources = df_input_ja_qa, \n",
    "                                                predictions = df_generated_ja_qa,\n",
    "                                                references=df_reference_ja_qa,\n",
    "                                                tokenizer = my_custom_tokenizer_ja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Display the results<a id=\"results-2.4.c\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "ce2e18d5-7646-475b-adeb-cd98bcd76a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rouge_score\": {\n",
      "    \"rouge1\": 1.0,\n",
      "    \"rouge1_recall\": 1.0,\n",
      "    \"rouge2\": 0.72,\n",
      "    \"rouge2_recall\": 0.72,\n",
      "    \"rougeL\": 1.0,\n",
      "    \"rougeL_recall\": 1.0,\n",
      "    \"rougeLsum\": 1.0,\n",
      "    \"rougeLsum_recall\": 1.0,\n",
      "    \"total_records\": 50\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result_ja_2_qa,indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb010532-ba3e-4e61-a28f-ecb69e3f53c8"
   },
   "source": [
    "Author: <a href=\"mailto:kshitij.g1@ibm.com\">Kshitij Gopali</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48ec96f2-55ab-4435-bb06-681a8b27aa90"
   },
   "source": [
    "Copyright © 2024 IBM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
