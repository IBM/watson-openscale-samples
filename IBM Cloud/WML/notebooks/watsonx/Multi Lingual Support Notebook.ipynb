{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Design time notebook for Multi Lingual support of Generative AI Quality summarization metrics for IBM WatsonX.governance",
      "metadata": {
        "id": "af3fa5a9-d008-46db-8f13-d61fcd8cc6d3"
      }
    },
    {
      "cell_type": "markdown",
      "source": "This notebook demonstrates the metric results of the Generative AI Quality monitors for a prompt in Japanese. The various metrics computed across the particular task types are :\n- Summarization:\n    - Rouge Score\n    - Cosine Similarity\n    - Normalized Precision\n    - Normalized Recall\n    - Normalized F1 Score\n    - HAP Score\n    - PII\n- Generation:\n    - Rouge Score\n    - Normalized Precision\n    - Normalized Recall\n    - Normalized F1 Score\n    - HAP Score\n    - PII\n- Extraction:\n    - Rouge Score\n    - HAP Score\n    - PII\n- Question Answering(QA):\n    - Rouge Score\n    - HAP Score\n    - PII\n\nThe notebook aims to show the Japanese metric values using a tokenizer in 2 different scenarios:\n- Scenario 1 : When `language_code` is passed in the configuration to use the in-built tokenizer for a particular language\n- Scenario 2 : When the user passes a custom tokenizer present on their system",
      "metadata": {
        "id": "26b7d8e1-db3f-4160-a6ee-3ed530642f15"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Note** : \n- The below given example is specific to the Japanese language.\n- HAP Score and PII do not support a custom tokenizer\n\nList of supported languages and the language code associated to these language:    \n- English : en\n- Japanese : ja\n- German : de\n- French : fr\n- Spanish : es\n- Arabic : ar\n- Italian : it\n- Portugese : pt\n- Korean : ko\n- Danish : da\n\nRequirements to run in another language: A dataset consisting of source(input) and reference columns. The predictions(output) column is also needed, but if not present then a suitable Hugging Face model can be used to generate the predictions for the above given inputs\n\nChanges to be made to run the cells in another language:\n- Replace the filename and url to fetch the dataset in [Step 2](#data)\n- If the predictions column is not present, replace the model id in [Step 3](#model) with that of a suitable Hugging Face model and run [Step 4](#predict)\n- Change the language code [here](#language_code) and run the cells in [Scenario 1](#scenario-1)",
      "metadata": {
        "id": "164a6bcd-cd14-4bb5-9f06-d07d20385222"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Contents\n\n- [Step 1 - Setup](#setup)\n- [Step 2 - Read data and store in dataframes](#data-1)\n- [Step 3 - Initialize Hugging Face model](#model)\n- [Step 4 - Generate the predictions for sample input](#predict)\n- [Step 5 - Set the language code](#language_code)\n\n- [Scenario 1 - Metrics with language code which uses the in-built WatsonNLP tokenizer](#scenario-1)\n    - [Summarization metrics](#summarization-1)\n        - [Step 1 - Configure the summarization metrics](#config-1.1.a)\n        - [Step 2 - Compute the summarization metrics](#compute-1.1.b)\n        - [Step 3 - Display the results](#results-1.1.c)\n    - [Generation metrics](#generation-1)\n        - [Step 1 - Read data and store in dataframes](#data-2)\n        - [Step 2 - Configure the generation metrics](#config-1.2.a)\n        - [Step 3 - Compute the generation metrics](#compute-1.2.b)\n        - [Step 4 - Display the results](#results-1.2.c)\n    - [Extraction metrics](#extraction-1)\n        - [Step 1 - Read data and store in dataframes](#data-3)\n        - [Step 2 - Configure the extraction metrics](#config-1.3.a)\n        - [Step 3 - Compute the extraction metrics](#compute-1.3.b)\n        - [Step 4 - Display the results](#results-1.3.c)\n    - [Question Answering(QA) metrics](#qa-1)\n        - [Step 1 - Read data and store in dataframes](#data-4)\n        - [Step 2 - Configure the question answering(qa) metrics](#config-1.4.a)\n        - [Step 3 - Compute the question answering(qa) metrics](#compute-1.4.b)\n        - [Step 4 - Display the results](#results-1.4.c)\n- [Scenario 2 - Metrics with custom tokenizer](#scenario-2)\n    - [Step 1 - Create a custom tokenizer](#custom_tokenizer)\n    - [Summarization metrics](#summarization-2)\n        - [Step 1 - Configure the summarization metrics](#config-2.1.a)\n        - [Step 2 - Compute the summarization metrics](#compute-2.1.b)\n        - [Step 3 - Display the results](#results-2.1.c)\n    - [Generation metrics](#generation-2)\n        - [Step 2 - Configure the generation metrics](#config-2.2.a)\n        - [Step 3 - Compute the generation metrics](#compute-2.2.b)\n        - [Step 4 - Display the results](#results-2.2.c)\n    - [Extraction metrics](#extraction-2)\n        - [Step 2 - Configure the extraction metrics](#config-2.3.a)\n        - [Step 3 - Compute the extraction metrics](#compute-2.3.b)\n        - [Step 4 - Display the results](#results-2.3.c)\n    - [Question Answering(QA) metrics](#qa-2)\n        - [Step 2 - Configure the question answering(qa) metrics](#config-2.4.a)\n        - [Step 3 - Compute the question answering(qa) metrics](#compute-2.4.b)\n        - [Step 4 - Display the results](#results-2.4.c)",
      "metadata": {
        "id": "d7622088-c7d1-468a-8d27-5780459c4cc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Step 1 - Setup <a id=\"setup\"></a>",
      "metadata": {
        "id": "67e4cb09-de1c-4bc6-bd2f-b2ff066d1ca0"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Install necessary libraries",
      "metadata": {
        "id": "97c5f0ac-a081-4d41-a94e-63b6165f3661"
      }
    },
    {
      "cell_type": "code",
      "source": "!pip install -U ibm_watson_openscale | tail -n 1\n!pip install -U \"ibm-metrics-plugin[generative-ai-quality]~=3.0.11\" | tail -n 1\n\nimport warnings\nwarnings.filterwarnings('ignore')",
      "metadata": {
        "id": "794c2a16-d9d4-44a0-9e35-19e8e971613b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0,>=2.0->ibm_watson_openscale) (2024.8.30)\nSuccessfully installed blis-0.7.11 boto3-1.34.162 botocore-1.34.162 catalogue-2.0.10 cloudpathlib-0.19.0 colorama-0.4.6 confection-0.1.5 cymem-2.0.8 datasets-3.0.1 dill-0.3.8 evaluate-0.4.3 h5py-3.11.0 huggingface-hub-0.25.2 ibm-metrics-plugin-3.0.9 ibm-wos-utils-3.0.4 imageio-2.27.0 ipadic-1.0.0 jenkspy-0.4.1 langcodes-3.4.1 language-data-1.2.0 marisa-trie-1.2.0 more-itertools-10.2.0 multiprocess-0.70.16 murmurhash-1.0.10 nltk-3.9.1 portalocker-2.10.1 preshed-3.0.9 pyparsing-3.1.4 pyphen-0.16.0 rapidfuzz-3.10.0 regex-2024.9.11 retrying-1.3.4 s3transfer-0.10.3 sacrebleu-2.4.3 sacremoses-0.1.1 safetensors-0.4.5 service-locator-0.1.3 shap-0.45.1 slicer-0.0.8 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 spark-nlp-5.3.3 srsly-2.4.8 textstat-0.7.4 thefuzz-0.22.1 thinc-8.2.5 toolz-0.12.1 torchmetrics-1.4.3 transformers-4.39.3 unitxt-1.9.0 wasabi-1.1.3 weasel-0.4.1 xxhash-3.5.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "import spacy\n\nspacy.cli.download(\"en_core_web_sm\")\nspacy.cli.download(\"ja_core_news_sm\")\n!python -m nltk.downloader punkt",
      "metadata": {
        "id": "a3ab4501-553b-4ba3-a932-7410c56bd6f6",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.2)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (72.1.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.19)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\nRequirement already satisfied: wrapt in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\nInstalling collected packages: en-core-web-sm\nSuccessfully installed en-core-web-sm-3.7.1\n\u001b[38;5;2m\u2714 Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m\u26a0 Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nCollecting ja-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/ja_core_news_sm-3.7.0/ja_core_news_sm-3.7.0-py3-none-any.whl (12.1 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ja-core-news-sm==3.7.0) (3.7.5)\nCollecting sudachipy!=0.6.1,>=0.5.2 (from ja-core-news-sm==3.7.0)\n  Downloading SudachiPy-0.6.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting sudachidict-core>=20211220 (from ja-core-news-sm==3.7.0)\n  Downloading SudachiDict_core-20240716-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (2.32.2)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (3.1.4)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (72.1.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (23.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (3.4.1)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (1.2.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (4.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (1.26.19)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (2024.8.30)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (2.1.3)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (1.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (2.15.1)\nRequirement already satisfied: wrapt in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (1.14.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ja-core-news-sm==3.7.0) (0.1.2)\nDownloading SudachiDict_core-20240716-py3-none-any.whl (72.0 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading SudachiPy-0.6.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: sudachipy, sudachidict-core, ja-core-news-sm\nSuccessfully installed ja-core-news-sm-3.7.0 sudachidict-core-20240716 sudachipy-0.6.8\n\u001b[38;5;2m\u2714 Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('ja_core_news_sm')\n\u001b[38;5;3m\u26a0 Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n[nltk_data] Downloading package punkt to /home/wsuser/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m4.7/72.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.4/72.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m9.8/72.0 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m12.7/72.0 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m15.4/72.0 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m17.8/72.0 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m20.3/72.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.1/72.0 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m25.4/72.0 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m28.1/72.0 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m30.5/72.0 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m33.0/72.0 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m35.5/72.0 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m38.1/72.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m41.0/72.0 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m43.7/72.0 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m46.2/72.0 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m48.7/72.0 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m51.3/72.0 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m53.9/72.0 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.9/72.0 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.5/72.0 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m62.1/72.0 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u001b[0m \u001b[32m65.2/72.0 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u001b[0m \u001b[32m67.9/72.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m \u001b[32m70.8/72.0 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading SudachiPy-0.6.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/2.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Installing collected packages: sudachipy, sudachidict-core, ja-core-news-sm\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Successfully installed ja-core-news-sm-3.7.0 sudachidict-core-20240716 sudachipy-0.6.8\n\u001b[38;5;2m\u2714 Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('ja_core_news_sm')\n\u001b[38;5;3m\u26a0 Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\r\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[nltk_data] Downloading package punkt to /home/wsuser/nltk_data...\r\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[nltk_data]   Unzipping tokenizers/punkt.zip.\r\n"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "**Note**: you may need to restart the kernel to use updated libraries.",
      "metadata": {
        "id": "22f3adee-0684-4b8c-bdcb-fd4b9b71b34b"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Configure your credentials",
      "metadata": {
        "id": "5f669847-1446-429d-96bf-0d9958cbb4d4"
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### Provision services and configure credentials",
      "metadata": {
        "id": "f9ccb571-e08d-4254-9796-4ce683ad6a51"
      }
    },
    {
      "cell_type": "markdown",
      "source": "If you have not already, provision an instance of IBM Watson OpenScale using the [OpenScale link in the Cloud catalog](https://cloud.ibm.com/catalog/services/watson-openscale).\nYour Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below.\n**NOTE:** You can also get OpenScale `API_KEY` using IBM CLOUD CLI.\n\nHow to install IBM Cloud (bluemix) console: [instruction](https://console.bluemix.net/docs/cli/reference/ibmcloud/download_cli.html#install_use)\n\nHow to get api key using console:\n```\nbx login --sso\nbx iam api-key-create 'my_key'\n```",
      "metadata": {
        "id": "e8158f13-3808-4aaf-8d2a-5ca62fe4c2cd"
      }
    },
    {
      "cell_type": "code",
      "source": "use_cpd = False\nCLOUD_API_KEY = \"****\"\nIAM_URL=\"https://iam.cloud.ibm.com\"\nSERVICE_URL=\"https://aiopenscale.cloud.ibm.com\"",
      "metadata": {
        "id": "3a11f13b-b737-4e7a-862e-57f1ac4c2ddc"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "Uncomment the code and run the below cell only if you are running your notebook on a CPD cluster.",
      "metadata": {
        "id": "5bb21fff-a6a3-41af-bd71-ad1ed0acf413"
      }
    },
    {
      "cell_type": "code",
      "source": "# use_cpd = True\n# WOS_CREDENTIALS = {\n#     \"url\": \"xxxxx\",\n#     \"username\": \"xxxxx\",\n#     \"password\": \"xxxxx\",\n#     \"apikey\": \"xxxxx\"\n# }",
      "metadata": {
        "id": "7bf34a25-4077-4310-bd23-72444d809b3e"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2 - Read and store data in individual pandas dataframes <a id=\"data-1\"></a>",
      "metadata": {
        "id": "11f51bc0-4bc7-4fc6-9a2d-5a7336edb9f7"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Read the data\n\nDownload the sample \"llm_content_summarization_ja\" file.",
      "metadata": {
        "id": "5b7bb384-9a29-41f3-87ff-5f9622adeefa"
      }
    },
    {
      "cell_type": "code",
      "source": "filename_summarization = \"llm_content_summarization_ja.csv\"\n!rm -fr \"llm_content_summarization_ja.csv\"\n!wget \"https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_summarization_ja.csv\"",
      "metadata": {
        "id": "8549da81-d788-406b-ab5d-f7dd52b655a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "--2024-10-10 17:33:51--  https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_summarization_ja.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 26758 (26K) [text/plain]\nSaving to: \u2018llm_content_summarization_ja.csv\u2019\n\nllm_content_summari 100%[===================>]  26.13K  --.-KB/s    in 0.001s  \n\n2024-10-10 17:33:52 (24.6 MB/s) - \u2018llm_content_summarization_ja.csv\u2019 saved [26758/26758]\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "### Converting the data into pandas dataframe\n\nExtracting the columns and creating individual data frames for `input`, `prediction` and `reference` columns",
      "metadata": {
        "id": "ce77a2b5-9ace-43b6-881d-b90d918f0eba"
      }
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\nllm_data_ja_summarization = pd.read_csv(filename_summarization)\ndf_input_ja_summarization = llm_data_ja_summarization[['input_text']].copy()\ndf_reference_ja_summarization = llm_data_ja_summarization[['reference_summary']].copy()\ndf_generated_ja_summarization = llm_data_ja_summarization[['generated_predictions']].copy() # Comment if using loacl LLM model",
      "metadata": {
        "id": "3dfab1eb-0f5f-40f6-9bbe-5223a46dfae8"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3 - Initialize a foundation model from Hugging Face\n<a id=\"model\"></a>",
      "metadata": {
        "id": "9126971f-ba10-44dd-96e2-600d73a9a2a6"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Uncomment the following cells to create a Hugging face model and generate the predictions for Japanese\n\nModel used - p1atdev/mt5-base-xlsum-ja-v1.1 : Japanese summarization model",
      "metadata": {
        "id": "ba0a5385-ca22-4ddc-b7c7-6bac871e4472"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Note: The below given example is specific to the summarization task type. The other task types mentioned will need to be run with the suitable models and column names",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# from transformers import pipeline\n\n# def summarize_fn_ja(input_text):\n#     seq2seq = pipeline(\"summarization\", model=\"p1atdev/mt5-base-xlsum-ja-v1.1\")\n#     result = seq2seq(input_text)\n#     return result[0]['summary_text']",
      "metadata": {
        "id": "15dc81bb-cbb2-4df9-b557-678915fa81b3"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "## Step 4 - Generate predictions for sample input\n<a id=\"predict\"></a>",
      "metadata": {
        "id": "4c5f6aff-17d1-4f78-937f-8468bd8a9c02"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Creating an empty list and storing the generated predictions",
      "metadata": {
        "id": "a50a6d4a-db08-461d-87a7-11851a055598"
      }
    },
    {
      "cell_type": "code",
      "source": "# generated_predictions_ja = []\n# for input in df_input_ja_summarization[\"input_text\"]:\n#     generated_predictions_ja.append(summarize_fn_ja(input))",
      "metadata": {
        "id": "bcba9968-09ed-458c-89a6-04d91ec48290"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "Converting the list to an individual dataframe",
      "metadata": {
        "id": "8e3f73a7-3abd-4c59-8ea1-3d10413c01fc"
      }
    },
    {
      "cell_type": "code",
      "source": "# df_generated_ja_summarization = pd.DataFrame(columns=[\"generated_predictions\"])\n# df_generated_ja_summarization['generated_predictions'] = generated_predictions_ja\n# print(df_generated_ja_summarization)",
      "metadata": {
        "id": "c32df374-2521-448a-9eec-32c16520d6ad"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "### Setting the language code <a id=\"language_code\"></a>",
      "metadata": {
        "id": "043e5879-7f5e-48b0-aba2-b3001f956eb7"
      }
    },
    {
      "cell_type": "code",
      "source": "language_code = \"ja\"",
      "metadata": {
        "id": "27401942-804c-4e80-b5a2-0f815ba603db"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "## Scenario 1 - Metrics with `language_code` which uses the in-built WatsonNLP tokenizer <a id=\"scenario-1\"></a>",
      "metadata": {
        "id": "94ac6115-a810-4204-931c-ccf14447c863"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### IBM watsonx.governance authentication and verifying client version",
      "metadata": {
        "id": "c22b1c72-167d-47f8-b518-1bce7b6fce87"
      }
    },
    {
      "cell_type": "code",
      "source": "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator,BearerTokenAuthenticator,CloudPakForDataAuthenticator\n\nfrom ibm_watson_openscale import *\nfrom ibm_watson_openscale.supporting_classes.enums import *\nfrom ibm_watson_openscale.supporting_classes import *\n\nif use_cpd:\n    authenticator = CloudPakForDataAuthenticator(\n            url=WOS_CREDENTIALS['url'],\n            username=WOS_CREDENTIALS['username'],\n            apikey=WOS_CREDENTIALS['apikey'],\n            disable_ssl_verification=True,\n        )\n    \n    client = APIClient(service_url=WOS_CREDENTIALS['url'],authenticator=authenticator)\n    print(client.version)\nelse:\n    authenticator = IAMAuthenticator(apikey=CLOUD_API_KEY, url=IAM_URL)\n    client = APIClient(authenticator=authenticator, service_url=SERVICE_URL)\n    print(client.version)",
      "metadata": {
        "id": "7c94290b-d300-4ad0-9612-75d03951d601"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "3.0.41\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "from ibm_metrics_plugin.metrics.llm.utils.constants import LLMTextMetricGroup\nfrom ibm_metrics_plugin.metrics.llm.utils.constants import LLMSummarizationMetrics\nfrom ibm_metrics_plugin.metrics.llm.utils.constants import LLMCommonMetrics\nfrom ibm_metrics_plugin.metrics.llm.utils.constants import LLMGenerationMetrics\nfrom ibm_metrics_plugin.metrics.llm.utils.constants import LLMExtractionMetrics\nfrom ibm_metrics_plugin.metrics.llm.utils.constants import LLMQAMetrics\nimport json",
      "metadata": {
        "id": "dc08be32-a77c-4f0b-a977-e00fec73a442"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "## Summarization metrics<a id=\"summarization-1\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 1 - Configure summarization metrics<a id=\"config-1.1.a\"></a>",
      "metadata": {
        "id": "30a12c5b-2be5-4a81-be35-12afb165e7c6"
      }
    },
    {
      "cell_type": "code",
      "source": "metric_config_1_summarization = {   \n    \"configuration\": {\n        LLMTextMetricGroup.SUMMARIZATION.value: {\n            LLMSummarizationMetrics.ROUGE_SCORE.value: {},\n            LLMSummarizationMetrics.COSINE_SIMILARITY.value: {},\n            LLMSummarizationMetrics.NORMALIZED_PRECISION.value: {},\n            LLMSummarizationMetrics.NORMALIZED_RECALL.value: {},\n            LLMSummarizationMetrics.NORMALIZED_F1_SCORE.value: {},\n            LLMCommonMetrics.HAP_SCORE.value: {},\n            LLMCommonMetrics.PII_DETECTION.value: {\n                \"language_code\" : language_code\n            }\n        },\n        \"language_code\" : language_code\n    }\n}",
      "metadata": {
        "id": "ac7106e7-f9af-45b8-ae8c-273dfe1cdd9b"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 2 - Compute the summarization metrics<a id=\"compute-1.1.b\"></a>",
      "metadata": {
        "id": "ac36b3cf-30fc-4252-9f95-597b35a1f8b0"
      }
    },
    {
      "cell_type": "code",
      "source": "result_ja_1_summarization = client.llm_metrics.compute_metrics(metric_config_1_summarization,\n                                                sources = df_input_ja_summarization, \n                                                predictions = df_generated_ja_summarization, \n                                                references = df_reference_ja_summarization)",
      "metadata": {
        "id": "6016025b-80e8-411e-8f77-02b7c91f03fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt_tab to /home/wsuser/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 3 - Display the results<a id=\"results-1.1.c\"></a>",
      "metadata": {
        "id": "5f9b69d1-a4c4-45d2-80c4-d93f62cb1baf"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Fetching the results",
      "metadata": {
        "id": "474465a6-9050-4205-924a-271f38297c1f"
      }
    },
    {
      "cell_type": "code",
      "source": "final_results_ja_1_summarization = client.llm_metrics.get_metrics_result(configuration=metric_config_1_summarization, \n                                                           metrics_result=result_ja_1_summarization)",
      "metadata": {
        "id": "012ab200-9470-4f29-867c-ca8568262763"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "print(json.dumps(final_results_ja_1_summarization,indent=2))",
      "metadata": {
        "id": "2d8609c9-8464-40f4-a250-257135d15009"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{\n  \"cosine_similarity\": {\n    \"total_records\": 20,\n    \"max\": 0.4972134156783251,\n    \"mean\": 0.3267,\n    \"metric_value\": 0.3267,\n    \"min\": 0.20829453553574567\n  },\n  \"hap_score\": {\n    \"total_records\": 20,\n    \"max\": 0.10210397094488144,\n    \"mean\": 0.0553,\n    \"metric_value\": 0.0553,\n    \"min\": 0.02366599254310131\n  },\n  \"normalized_f1\": {\n    \"total_records\": 20,\n    \"max\": 0.5454545454545455,\n    \"mean\": 0.3755,\n    \"metric_value\": 0.3755,\n    \"min\": 0.22988505747126436\n  },\n  \"normalized_precision\": {\n    \"total_records\": 20,\n    \"max\": 0.72,\n    \"mean\": 0.4214,\n    \"metric_value\": 0.4214,\n    \"min\": 0.23529411764705882\n  },\n  \"normalized_recall\": {\n    \"total_records\": 20,\n    \"max\": 0.8,\n    \"mean\": 0.4073,\n    \"metric_value\": 0.4073,\n    \"min\": 0.16129032258064516\n  },\n  \"pii\": {\n    \"total_records\": 20,\n    \"max\": 0,\n    \"mean\": 0.0,\n    \"metric_value\": 0.0,\n    \"min\": 0\n  },\n  \"rouge_score\": {\n    \"rouge1\": 0.3755,\n    \"rouge1_recall\": 0.4073,\n    \"rouge2\": 0.1853,\n    \"rouge2_recall\": 0.1955,\n    \"rougeL\": 0.2903,\n    \"rougeL_recall\": 0.3115,\n    \"rougeLsum\": 0.2903,\n    \"rougeLsum_recall\": 0.3115,\n    \"total_records\": 20\n  }\n}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "## Generation metrics<a id=\"generation-1\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Step 1 - Read data and store in dataframes<a id=\"data-2\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Read the data\n\nDownload the sample \"llm_content_generation_ja\" file",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "filename_generation = \"llm_content_generation_ja.csv\"\n!rm -fr \"llm_content_generation_ja.csv\"\n!wget \"https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_generation_ja.csv\"",
      "metadata": {
        "id": "16b291da-dc80-4639-ad50-ceeccbdf36fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "--2024-10-10 17:37:15--  https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_generation_ja.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 14183 (14K) [text/plain]\nSaving to: \u2018llm_content_generation_ja.csv\u2019\n\nllm_content_generat 100%[===================>]  13.85K  --.-KB/s    in 0s      \n\n2024-10-10 17:37:15 (51.0 MB/s) - \u2018llm_content_generation_ja.csv\u2019 saved [14183/14183]\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "### Converting the data into pandas dataframe\n\nExtracting the columns and creating individual data frames for `input`, `prediction` and `reference` columns",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\nllm_data_ja_generation = pd.read_csv(filename_generation)\ndf_input_ja_generation = llm_data_ja_generation[['question']].copy()\ndf_reference_ja_generation = llm_data_ja_generation[['reference_text']].copy()\ndf_generated_ja_generation = llm_data_ja_generation[['generated_text']].copy() # Comment if using loacl LLM model",
      "metadata": {
        "id": "ed337d61-69dd-4f1c-b5df-ee1a0a030489"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 1 - Configure generation metrics<a id=\"config-1.2.a\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "metric_config_1_generation = {   \n    \"configuration\": {\n        LLMTextMetricGroup.GENERATION.value: {\n            LLMGenerationMetrics.ROUGE_SCORE.value: {},\n            LLMGenerationMetrics.NORMALIZED_PRECISION.value: {},\n            LLMGenerationMetrics.NORMALIZED_RECALL.value: {},\n            LLMGenerationMetrics.NORMALIZED_F1_SCORE.value: {},\n            LLMCommonMetrics.HAP_SCORE.value: {},\n            LLMCommonMetrics.PII_DETECTION.value: {\n                \"language_code\" : language_code\n            }\n        },\n        \"language_code\" : language_code\n    }\n}",
      "metadata": {
        "id": "628cfcb1-51a9-4398-be6f-439850388e43"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 2 - Compute the generation metrics<a id=\"compute-1.2.b\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "result_ja_1_generation = client.llm_metrics.compute_metrics(metric_config_1_generation,\n                                                sources = df_input_ja_generation, \n                                                predictions = df_generated_ja_generation, \n                                                references = df_reference_ja_generation)",
      "metadata": {
        "id": "6bcd7c61-1d9c-4ca9-b7ce-74847db5eb62"
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 3 - Display the results<a id=\"results-1.2.c\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Fetching the results",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "final_results_ja_1_generation = client.llm_metrics.get_metrics_result(configuration=metric_config_1_generation, \n                                                           metrics_result=result_ja_1_generation)",
      "metadata": {
        "id": "4b918fc8-339c-467b-9029-b3fa298c9074"
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": "print(json.dumps(final_results_ja_1_generation,indent=2))",
      "metadata": {
        "id": "84666aa8-daf2-4220-810d-44b53cfba9b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{\n  \"hap_score\": {\n    \"total_records\": 23,\n    \"max\": 0.12608999013900757,\n    \"mean\": 0.0141,\n    \"metric_value\": 0.0141,\n    \"min\": 0.0021147574298083782\n  },\n  \"normalized_f1\": {\n    \"total_records\": 23,\n    \"max\": 0.9481481481481482,\n    \"mean\": 0.8329,\n    \"metric_value\": 0.8329,\n    \"min\": 0.6399999999999999\n  },\n  \"normalized_precision\": {\n    \"total_records\": 23,\n    \"max\": 1.0,\n    \"mean\": 0.9981,\n    \"metric_value\": 0.9981,\n    \"min\": 0.9722222222222222\n  },\n  \"normalized_recall\": {\n    \"total_records\": 23,\n    \"max\": 0.9142857142857143,\n    \"mean\": 0.7201,\n    \"metric_value\": 0.7201,\n    \"min\": 0.47058823529411764\n  },\n  \"pii\": {\n    \"total_records\": 23,\n    \"max\": 0,\n    \"mean\": 0.0,\n    \"metric_value\": 0.0,\n    \"min\": 0\n  },\n  \"rouge_score\": {\n    \"rouge1\": 0.8328,\n    \"rouge1_recall\": 0.7202,\n    \"rouge2\": 0.8257,\n    \"rouge2_recall\": 0.7118,\n    \"rougeL\": 0.8328,\n    \"rougeL_recall\": 0.7202,\n    \"rougeLsum\": 0.8328,\n    \"rougeLsum_recall\": 0.7202,\n    \"total_records\": 23\n  }\n}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "## Extraction metrics<a id=\"extraction-1\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Step 1 - Read data and store in dataframes<a id=\"data-3\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Read the data\n\nDownload the sample \"llm_content_extraction_ja\" file",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "filename_extraction = \"llm_content_extraction_ja.csv\"\n!rm -fr \"llm_content_extraction_ja.csv\"\n!wget \"https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_extraction_ja.csv\"",
      "metadata": {
        "id": "be3e1eb9-c45a-4662-9dc3-a06aa2e05bb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "--2024-10-10 17:37:23--  https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_extraction_ja.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2478 (2.4K) [text/plain]\nSaving to: \u2018llm_content_extraction_ja.csv\u2019\n\nllm_content_extract 100%[===================>]   2.42K  --.-KB/s    in 0s      \n\n2024-10-10 17:37:24 (22.4 MB/s) - \u2018llm_content_extraction_ja.csv\u2019 saved [2478/2478]\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": "### Converting the data into pandas dataframe\n\nExtracting the columns and creating individual data frames for `input`, `prediction` and `reference` columns",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\nllm_data_ja_extraction = pd.read_csv(filename_extraction)\ndf_input_ja_extraction = llm_data_ja_extraction[['input_text']].copy()\ndf_reference_ja_extraction = llm_data_ja_extraction[['reference_text']].copy()\ndf_generated_ja_extraction = llm_data_ja_extraction[['generated_text']].copy() # Comment if using loacl LLM model",
      "metadata": {
        "id": "e01a8c84-d9fe-4602-a5b7-f19ae177c1d6"
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 1 - Configure extraction metrics<a id=\"config-1.3.a\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "metric_config_1_extraction = {   \n    \"configuration\": {\n        LLMTextMetricGroup.EXTRACTION.value: {\n            LLMExtractionMetrics.ROUGE_SCORE.value: {},\n            LLMCommonMetrics.HAP_SCORE.value: {},\n            LLMCommonMetrics.PII_DETECTION.value: {\n                \"language_code\" : language_code\n            }\n        },\n        \"language_code\" : language_code\n    }\n}",
      "metadata": {
        "id": "014f0e34-5e74-4b9e-b0d6-7747f21b61d2"
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 2 - Compute the extraction metrics<a id=\"compute-1.3.b\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "result_ja_1_extraction = client.llm_metrics.compute_metrics(metric_config_1_extraction,\n                                                sources = df_input_ja_extraction, \n                                                predictions = df_generated_ja_extraction, \n                                                references = df_reference_ja_extraction)",
      "metadata": {
        "id": "eeccf93d-e6d3-4a34-8918-d632c3d3273b"
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 3 - Display the results<a id=\"results-1.3.c\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Fetching the results",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "final_results_ja_1_extraction = client.llm_metrics.get_metrics_result(configuration=metric_config_1_extraction, \n                                                           metrics_result=result_ja_1_extraction)",
      "metadata": {
        "id": "e941ccbe-0cb7-4a87-9b50-69a031e24e89"
      },
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": "print(json.dumps(final_results_ja_1_extraction,indent=2))",
      "metadata": {
        "id": "0810ace7-1bf3-4e37-ab9f-ddb00d3c1b76"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{\n  \"hap_score\": {\n    \"total_records\": 10,\n    \"max\": 0.12826542556285858,\n    \"mean\": 0.0241,\n    \"metric_value\": 0.0241,\n    \"min\": 0.0043441494926810265\n  },\n  \"pii\": {\n    \"total_records\": 10,\n    \"max\": 0.8,\n    \"mean\": 0.56,\n    \"metric_value\": 0.56,\n    \"min\": 0.0\n  },\n  \"rouge_score\": {\n    \"rouge1\": 0.9,\n    \"rouge1_recall\": 0.9,\n    \"rouge2\": 0.8,\n    \"rouge2_recall\": 0.8,\n    \"rougeL\": 0.9,\n    \"rougeL_recall\": 0.9,\n    \"rougeLsum\": 0.9,\n    \"rougeLsum_recall\": 0.9,\n    \"total_records\": 10\n  }\n}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "## Question Answering(QA) metrics<a id=\"qa-1\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Step 1 - Read data and store in dataframes<a id=\"data-4\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Read the data\n\nDownload the sample \"llm_content_qa_ja\" file",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "filename_qa = \"llm_content_qa_ja.csv\"\n!rm -fr \"llm_content_qa_ja.csv\"\n!wget \"https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_qa_ja.csv\"",
      "metadata": {
        "id": "e454ea6b-f53c-419c-aedb-1ea885761e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "--2024-10-10 17:39:37--  https://raw.githubusercontent.com/IBM/watson-openscale-samples/refs/heads/main/IBM%20Cloud/WML/assets/data/watsonx/Multi_Lingual_Support/llm_content_qa_ja.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4407 (4.3K) [text/plain]\nSaving to: \u2018llm_content_qa_ja.csv\u2019\n\nllm_content_qa_ja.c 100%[===================>]   4.30K  --.-KB/s    in 0s      \n\n2024-10-10 17:39:38 (39.2 MB/s) - \u2018llm_content_qa_ja.csv\u2019 saved [4407/4407]\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": "### Converting the data into pandas dataframe\n\nExtracting the columns and creating individual data frames for `input`, `prediction` and `reference` columns",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\nllm_data_ja_qa = pd.read_csv(filename_qa)\ndf_input_ja_qa = llm_data_ja_qa[['question']].copy()\ndf_reference_ja_qa = llm_data_ja_qa[['answers']].copy()\ndf_generated_ja_qa = llm_data_ja_qa[['answers']].copy() # Comment if using loacl LLM model",
      "metadata": {
        "id": "5bdbbeba-3e0d-4992-aeaf-64de778c142c"
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 1 - Configure question answering metrics<a id=\"config-1.4.a\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "metric_config_1_qa = {   \n    \"configuration\": {\n        LLMTextMetricGroup.QA.value: {\n            LLMQAMetrics.ROUGE_SCORE.value: {},\n            LLMCommonMetrics.HAP_SCORE.value: {},\n            LLMCommonMetrics.PII_DETECTION.value: {\n                \"language_code\" : language_code\n            }\n        },\n        \"language_code\" : language_code\n    }\n}",
      "metadata": {
        "id": "7daf6daa-cd5a-4f4b-a2f3-a2860027ded6"
      },
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 2 - Compute the question answering(qa) metrics<a id=\"compute-1.4.b\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "result_ja_1_qa = client.llm_metrics.compute_metrics(metric_config_1_qa,\n                                                sources = df_input_ja_qa, \n                                                predictions = df_generated_ja_qa,\n                                                references=df_reference_ja_qa)",
      "metadata": {
        "id": "01298e9f-d536-486c-ac46-ba9e9b1f1794"
      },
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 3 - Display the results<a id=\"results-1.4.c\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Fetching the results",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "final_results_ja_1_qa = client.llm_metrics.get_metrics_result(configuration=metric_config_1_qa, \n                                                           metrics_result=result_ja_1_qa)",
      "metadata": {
        "id": "01bcafb6-7d88-4d79-94c1-181b7954fb98"
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "source": "print(json.dumps(final_results_ja_1_qa,indent=2))",
      "metadata": {
        "id": "226f0882-ab69-4713-b16b-8a1380ea3095"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{\n  \"hap_score\": {\n    \"total_records\": 50,\n    \"max\": 0.9634731411933899,\n    \"mean\": 0.0748,\n    \"metric_value\": 0.0748,\n    \"min\": 0.001772725721821189\n  },\n  \"pii\": {\n    \"total_records\": 50,\n    \"max\": 0,\n    \"mean\": 0.0,\n    \"metric_value\": 0.0,\n    \"min\": 0\n  },\n  \"rouge_score\": {\n    \"rouge1\": 1.0,\n    \"rouge1_recall\": 1.0,\n    \"rouge2\": 0.72,\n    \"rouge2_recall\": 0.72,\n    \"rougeL\": 1.0,\n    \"rougeL_recall\": 1.0,\n    \"rougeLsum\": 1.0,\n    \"rougeLsum_recall\": 1.0,\n    \"total_records\": 50\n  }\n}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "markdown",
      "source": "## Scenario 2 - Metrics with custom tokenizer <a id=\"scenario-2\"></a>",
      "metadata": {
        "id": "c2f7e4e0-dfab-40e3-8de7-80abd85dca7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Creating a custom tokenizer using Spacy",
      "metadata": {
        "id": "d1465041-309a-4a4c-8c41-67c23cc455b0"
      }
    },
    {
      "cell_type": "code",
      "source": "import spacy",
      "metadata": {
        "id": "716101c2-dcc2-4704-9994-8d01c2d2d5c3"
      },
      "outputs": [],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": "def get_language_model_sp(language='en'):\n    nlp = None\n    if language=='en':\n        nlp = spacy.load(\"en_core_web_sm\")\n    if language=='ja':\n        nlp = spacy.load(\"ja_core_news_sm\")\n    return nlp  ",
      "metadata": {
        "id": "265bf670-2ba5-4769-aaa9-fdd090c04a76"
      },
      "outputs": [],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": "class MyCustomTokenizer():    \n    def __init__(self, language = 'en'):\n        self.language = language\n        self.tokenizer = None\n    \n    def tokenize(self, input_text):\n        tokens = []\n        nlp = get_language_model_sp(self.language)        \n        doc = nlp(input_text)\n        for token in doc:\n            tokens.append(str(token))\n        return tokens\n    \n    def __call__(self, input_text):\n        return self.tokenize(input_text)",
      "metadata": {
        "id": "b1fc48cb-0868-4ef5-b634-4b4ff1b15ed5"
      },
      "outputs": [],
      "execution_count": 38
    },
    {
      "cell_type": "markdown",
      "source": "### Initializing tokenizer",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "my_custom_tokenizer_ja = MyCustomTokenizer(language_code).tokenize",
      "metadata": {
        "id": "65ee1739-1699-4bf4-a625-b2a18339df22"
      },
      "outputs": [],
      "execution_count": 39
    },
    {
      "cell_type": "markdown",
      "source": "## Summarization Metrics<a id=\"summarization-2\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Step 1 - Configure summarization metrics<a id=\"config-2.1.a\"></a>",
      "metadata": {
        "id": "266b5b53-26fb-4f12-974c-7c29163e42f2"
      }
    },
    {
      "cell_type": "code",
      "source": "metric_config_2_summarization = {   \n    \"configuration\": {\n        LLMTextMetricGroup.SUMMARIZATION.value: {\n            LLMSummarizationMetrics.ROUGE_SCORE.value: {},\n            LLMSummarizationMetrics.COSINE_SIMILARITY.value: {},\n            LLMSummarizationMetrics.NORMALIZED_PRECISION.value: {},\n            LLMSummarizationMetrics.NORMALIZED_RECALL.value: {},\n            LLMSummarizationMetrics.NORMALIZED_F1_SCORE.value: {}\n        },\n    }\n}",
      "metadata": {
        "id": "b51855fc-34f6-4ff2-96e2-5abdf723c8c4"
      },
      "outputs": [],
      "execution_count": 40
    },
    {
      "cell_type": "markdown",
      "source": "### Step 2 - Compute the summarization metrics<a id=\"compute-2.1.b\"></a>",
      "metadata": {
        "id": "a671fd6d-79d3-4e10-973c-4494c314a131"
      }
    },
    {
      "cell_type": "code",
      "source": "result_ja_2_summarization = client.llm_metrics.compute_metrics(metric_config_2_summarization, \n                                                sources = df_input_ja_summarization, \n                                                predictions = df_generated_ja_summarization, \n                                                references = df_reference_ja_summarization, \n                                                tokenizer = my_custom_tokenizer_ja)",
      "metadata": {
        "id": "1df9086a-1395-4c55-bda9-c231e272d148"
      },
      "outputs": [],
      "execution_count": 41
    },
    {
      "cell_type": "markdown",
      "source": "### Step 3 - Display the results<a id=\"results-2\"></a>",
      "metadata": {
        "id": "811b4eab-014d-4dbd-99e2-b58166598c57"
      }
    },
    {
      "cell_type": "code",
      "source": "print(json.dumps(result_ja_2_summarization,indent=2))",
      "metadata": {
        "id": "c80bc239-eefa-4ab4-a94c-6ab3d1c6ae66"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{\n  \"normalized_f1\": {\n    \"metric_value\": 0.38993368875948925,\n    \"mean\": 0.38993368875948925,\n    \"min\": 0.2391304347826087,\n    \"max\": 0.5306122448979591,\n    \"std\": 0.0987514928187935,\n    \"total_records\": 20\n  },\n  \"normalized_recall\": {\n    \"metric_value\": 0.4271739649831853,\n    \"mean\": 0.4271739649831853,\n    \"min\": 0.16176470588235295,\n    \"max\": 0.8125,\n    \"std\": 0.1994148081880162,\n    \"total_records\": 20\n  },\n  \"cosine_similarity\": {\n    \"metric_value\": 0.34002565443055394,\n    \"mean\": 0.34002565443055394,\n    \"min\": 0.19468993337739407,\n    \"max\": 0.4863954385551848,\n    \"std\": 0.08588403829894319,\n    \"total_records\": 20\n  },\n  \"normalized_precision\": {\n    \"metric_value\": 0.4330320512820512,\n    \"mean\": 0.4330320512820512,\n    \"min\": 0.20512820512820512,\n    \"max\": 0.7083333333333334,\n    \"std\": 0.1250694049511426,\n    \"total_records\": 20\n  },\n  \"rouge_score\": {\n    \"rouge1\": 0.3899,\n    \"rouge1_recall\": 0.4272,\n    \"rouge2\": 0.2031,\n    \"rouge2_recall\": 0.2203,\n    \"rougeL\": 0.2986,\n    \"rougeL_recall\": 0.3229,\n    \"rougeLsum\": 0.2986,\n    \"rougeLsum_recall\": 0.3229,\n    \"total_records\": 20\n  }\n}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 42
    },
    {
      "cell_type": "markdown",
      "source": "## Generation metrics<a id=\"generation-2\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 1 - Configure generation metrics<a id=\"config-2.2.a\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "metric_config_2_generation = {   \n    \"configuration\": {\n        LLMTextMetricGroup.GENERATION.value: {\n            LLMGenerationMetrics.ROUGE_SCORE.value: {},\n            LLMGenerationMetrics.NORMALIZED_PRECISION.value: {},\n            LLMGenerationMetrics.NORMALIZED_RECALL.value: {},\n            LLMGenerationMetrics.NORMALIZED_F1_SCORE.value: {},\n        }\n    }\n}",
      "metadata": {
        "id": "d27e802e-6642-451d-aca4-d994df681bef"
      },
      "outputs": [],
      "execution_count": 43
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 2 - Compute the generation metrics<a id=\"compute-2.2.b\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "result_ja_2_generation = client.llm_metrics.compute_metrics(metric_config_2_generation,\n                                                sources = df_input_ja_generation, \n                                                predictions = df_generated_ja_generation, \n                                                references = df_reference_ja_generation,\n                                                tokenizer = my_custom_tokenizer_ja)",
      "metadata": {
        "id": "78a4dc78-ac15-4307-8a47-b0311f157e90"
      },
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 3 - Display the results<a id=\"results-2.2.c\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(json.dumps(result_ja_2_generation,indent=2))",
      "metadata": {
        "id": "11e3c55f-0a20-443d-9dd5-8ae436f1949a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{\n  \"normalized_f1\": {\n    \"metric_value\": 0.8351304305697805,\n    \"mean\": 0.8351304305697805,\n    \"min\": 0.6493506493506493,\n    \"max\": 0.9548387096774195,\n    \"std\": 0.06538224681019711,\n    \"total_records\": 23\n  },\n  \"normalized_recall\": {\n    \"metric_value\": 0.7232754525118498,\n    \"mean\": 0.7232754525118498,\n    \"min\": 0.4807692307692308,\n    \"max\": 0.925,\n    \"std\": 0.0953663927099713,\n    \"total_records\": 23\n  },\n  \"normalized_precision\": {\n    \"metric_value\": 0.9983850931677019,\n    \"mean\": 0.9983850931677019,\n    \"min\": 0.9761904761904762,\n    \"max\": 1.0,\n    \"std\": 0.00545610526818546,\n    \"total_records\": 23\n  },\n  \"rouge_score\": {\n    \"rouge1\": 0.8351,\n    \"rouge1_recall\": 0.7233,\n    \"rouge2\": 0.8287,\n    \"rouge2_recall\": 0.7158,\n    \"rougeL\": 0.8351,\n    \"rougeL_recall\": 0.7233,\n    \"rougeLsum\": 0.8351,\n    \"rougeLsum_recall\": 0.7233,\n    \"total_records\": 23\n  }\n}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 45
    },
    {
      "cell_type": "markdown",
      "source": "## Extraction metrics<a id=\"extraction-2\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 1 - Configure extraction metrics<a id=\"config-2.3.a\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "metric_config_2_extraction = {   \n    \"configuration\": {\n        LLMTextMetricGroup.EXTRACTION.value: {\n            LLMExtractionMetrics.ROUGE_SCORE.value: {}\n        }\n    }\n}",
      "metadata": {
        "id": "d51dac35-6fcf-49c8-80f7-859c9e48c188"
      },
      "outputs": [],
      "execution_count": 46
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 2 - Compute the extraction metrics<a id=\"compute-2.3.b\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "result_ja_2_extraction = client.llm_metrics.compute_metrics(metric_config_2_extraction,\n                                                sources = df_input_ja_extraction, \n                                                predictions = df_generated_ja_extraction, \n                                                references = df_reference_ja_extraction,\n                                                tokenizer = my_custom_tokenizer_ja)",
      "metadata": {
        "id": "4894fa90-17ff-4ea8-aa18-5d7d5833644e"
      },
      "outputs": [],
      "execution_count": 47
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 3 - Display the results<a id=\"results-2.3.c\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(json.dumps(result_ja_2_extraction,indent=2))",
      "metadata": {
        "id": "82b03fa0-2678-4078-8d7b-3ac112ee1f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{\n  \"rouge_score\": {\n    \"rouge1\": 0.9,\n    \"rouge1_recall\": 0.9,\n    \"rouge2\": 0.8,\n    \"rouge2_recall\": 0.8,\n    \"rougeL\": 0.9,\n    \"rougeL_recall\": 0.9,\n    \"rougeLsum\": 0.9,\n    \"rougeLsum_recall\": 0.9,\n    \"total_records\": 10\n  }\n}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "markdown",
      "source": "## Question Answering(QA) metrics<a id=\"qa-2\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 1 - Configure question answering metrics<a id=\"config-2.4.a\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "metric_config_2_qa = {   \n    \"configuration\": {\n        LLMTextMetricGroup.QA.value: {\n            LLMQAMetrics.ROUGE_SCORE.value: {}\n        }\n    }\n}",
      "metadata": {
        "id": "56dfb7de-1cc8-46a5-afc5-54629f3e1831"
      },
      "outputs": [],
      "execution_count": 49
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 2 - Compute the question answering(qa) metrics<a id=\"compute-2.4.b\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "result_ja_2_qa = client.llm_metrics.compute_metrics(metric_config_2_qa,\n                                                sources = df_input_ja_qa, \n                                                predictions = df_generated_ja_qa,\n                                                references=df_reference_ja_qa,\n                                                tokenizer = my_custom_tokenizer_ja)",
      "metadata": {
        "id": "c3f14a82-8ac4-4489-8f72-f368ffba76c3"
      },
      "outputs": [],
      "execution_count": 50
    },
    {
      "cell_type": "markdown",
      "source": "#### Step 3 - Display the results<a id=\"results-2.4.c\"></a>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(json.dumps(result_ja_2_qa,indent=2))",
      "metadata": {
        "id": "ce2e18d5-7646-475b-adeb-cd98bcd76a04"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{\n  \"rouge_score\": {\n    \"rouge1\": 1.0,\n    \"rouge1_recall\": 1.0,\n    \"rouge2\": 0.72,\n    \"rouge2_recall\": 0.72,\n    \"rougeL\": 1.0,\n    \"rougeL_recall\": 1.0,\n    \"rougeLsum\": 1.0,\n    \"rougeLsum_recall\": 1.0,\n    \"total_records\": 50\n  }\n}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 51
    },
    {
      "cell_type": "markdown",
      "source": "Author: <a href=\"mailto:kshitij.g1@ibm.com\">Kshitij Gopali</a>",
      "metadata": {
        "id": "cb010532-ba3e-4e61-a28f-ecb69e3f53c8"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Copyright \u00a9 2024 IBM.",
      "metadata": {
        "id": "48ec96f2-55ab-4435-bb06-681a8b27aa90"
      }
    }
  ]
}