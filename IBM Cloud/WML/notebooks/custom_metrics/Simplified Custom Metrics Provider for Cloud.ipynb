{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "130546d4-d72c-46f1-a506-246ace42ad56"
   },
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6d32920-c6f8-4df6-91a7-925640a9920a"
   },
   "source": [
    "# Working with a custom metrics provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab7073b7-baf8-48ba-b9fb-e39e497596aa"
   },
   "source": [
    "This notebook should be run in a Watson Studio project, using **IBM Runtime 24.1 on Python 3.11 XS** runtime environment. **If you are viewing this in Watson Studio and do not see the required runtime env in the upper right corner of your screen, please update the runtime now.**. It requires service credentials for the following services:\n",
    "  * Watson OpenScale\n",
    "  * Watson Machine Learning\n",
    "\n",
    "## Overview\n",
    "\n",
    "This sample notebook demonstrates how to configure a custom monitor and compute metrics such as specificity, sensitivity and gender_less40_fav_prediction_ratio for traditional subscriptions. Based on the values specified in the configuration cell, it automatically creates the custom monitor definition, WML batch deployment for the Python function and custom metrics provider with the deployment scoring endpoint. Users must update the appropriate metric computation logic inside the Python function.\n",
    "\n",
    "During each run, OpenScale invokes the custom metrics provider(python function) and sends inputs like data_mart_id, subscription_id, custom_monitor_id and other parameters. The provider then:\n",
    "\n",
    "- Reads data from feedback, payload logging, or other datasets.\n",
    "- Computes and publishes aggregated metrics to the Measurements API.\n",
    "- Updates the monitor run status to Finished.\n",
    "  \n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "  1. [Set up your environment](#setup)\n",
    "  1. [Configure values for the custom monitor](#configure_values)\n",
    "  1. [Create the custom metrics provider - python function](#provider)\n",
    "  1. [Configure Watson OpenScale](#config)\n",
    "  1. [Set up the custom monitor](#custom_monitor)\n",
    "  1. [Get the custom monitor configuration](#get_config)\n",
    "  1. [Run the custom monitor](#run)\n",
    "  1. [Risk evaluations for subscription](#evaluate_risk)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c3c7fcc-8701-45f3-ab34-af1b093b590c"
   },
   "source": [
    "## 1. Set up your environment <a name=\"setup\"></a>\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "8b4212ee-4116-4a47-a586-f0997df1ec53",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Install the  `ibm_watsonx_ai` and `ibm-watson-openscale` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2eb75b61-93b5-4139-96d5-fae98c8c9173",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm_watsonx_ai   | tail -n 1\n",
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd55a125-14e4-440c-a2ee-c58813d75f9e"
   },
   "source": [
    "### Action: restart the kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2abe81f0-cd47-4fe0-9b5c-505712c17752",
    "scrolled": true
   },
   "source": [
    "### Credentials for IBM Cloud\n",
    "To authenticate, in the following code boxes, replace the sample data with your own credentials. Get the information from your system administrator or through the IBM Cloud dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "37f4abdea5d34ffd87dc6716b8ff989c"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Paste your credentials into the following section and then run this cell.\n",
    "############################################################################################\n",
    "CLOUD_API_KEY = \"<Your Cloud IAM API Key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROJECT_ID = \"<Your project id>\" #update the project id for pre-production subscription\n",
    "SPACE_ID = \"<Your space id>\"\n",
    "DATAMART_ID =  \"<DataMart Id>\"\n",
    "SUBSCRIPTION_ID= \"<Subscription Id>\"\n",
    "OPENSCALE_API_URL = \"https://api.aiopenscale.cloud.ibm.com\"\n",
    "IAM_URL = \"https://iam.cloud.ibm.com/oidc/token\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure values for the custom monitor <a name=\"configure_values\"></a>\n",
    "Default values for the following custom monitor parameters are set. You can override them by specifying parameter values in the configuration cell.\n",
    "\n",
    "| Parameter Name                                | Type           | Optional | Description                                                                 | Default Value                              |\n",
    "|----------------------------------------------|----------------|----------|-----------------------------------------------------------------------------|-------------------------------------------|\n",
    "| `DEPLOYMENT_NAME`                             | string         | Yes      | Name of the function deployment                                             | `\"Custom Metrics Provider Deployment\"`   |\n",
    "| `PYTHON_FUNCTION_NAME`                        | string         | Yes      | Name of the Python function to be deployed                                 | `\"Custom Metrics Provider Function\"`      |\n",
    "| `CUSTOM_METRICS_PROVIDER_NAME`                | string         | Yes      | Name for the Custom Metrics Provider                                       | `\"Custom Metrics Provider\"`               |\n",
    "| `CUSTOM_MONITOR_NAME`                         | string         | Yes      | Name of the custom monitor                                                 | `\"Sample Model Performance\"`              |\n",
    "| `DATAMART_ID`                                 | string         | Yes      | Watson OpenScale DataMart GUID                                             | `\"00000000-0000-0000-0000-000000000000\"`  |\n",
    "| `SPACE_ID`                                    | string         | No      | Watson OpenScale Space ID                                                   | `\"<Your Space ID>\"`  |\n",
    "| `RUNTIME_ENV`                                 | string         | Yes      | Runtime environment for the Python function                                | `\"runtime-24.1-py3.11\"`                   |\n",
    "| `ENABLE_SCHEDULE`                             | boolean        | Yes      | Flag to enable scheduled runs of the monitor                               | `True`                                    |\n",
    "| `START_TIME`                                  | string         | Yes      | Scheduled run start time (format: `HH:MM:SS`)                              | `\"10:00:00\"`                              |\n",
    "| `CUSTOM_METRICS_WAIT_TIME`                    | integer        | Yes      | Time in seconds to check the run status                                    | `60`                                     |\n",
    "| `DELETE_CUSTOM_MONITOR`                       | boolean        | Yes      | Flag to delete any existing monitor with the same name                     | `True`                                   |\n",
    "| `DELETE_CUSTOM_MONITOR_INSTANCE`              | boolean        | Yes      | Flag to delete any existing monitor instance                               | `True`                                   |\n",
    "| `DELETE_INTEGRATED_SYSTEM`                 | boolean        | Yes      | Flag to delete the existing python function and associated custom metric provider                              | `True`                                   |\n",
    "| `ALGORITHM_TYPES`                              | list[string]   | Yes      | Types of algorithms used (`binary`, `regression`, etc.)                    | `[\"binary\",\"multiclass\",\"regression\",\"question_answering\",\"summarization\",\"retrieval_augmented_generation\",\"classification\",\"generation\",\"extraction\"]`                              |\n",
    "| `INPUT_DATA_TYPES`                              | list[string]   | Yes      | Type of input data (`structured`, `unstructured`)                          | `[\"structured\",\"unstructured_text\",\"unstructured_image\"]`                          |\n",
    "| `WOS_URL`                                      | string         | No       | URL of the Watson OpenScale instance                                       | `\"https://api.aiopenscale.cloud.ibm.com\"` |\n",
    "| `WML_URL`                                      | string         | No       | URL of Watson Machine Learning instance                                    | `\"https://us-south.ml.cloud.ibm.com\"`     |\n",
    "| `CLOUD_API_KEY`                                | string         | No       | IBM Cloud API Key for IAM authentication                                   | `\"<Your Cloud IAM API Key>\"`             |\n",
    "| `IAM_URL`                                      | string         | No       | IAM authentication URL                                                     | `\"https://iam.ng.bluemix.net/oidc/token\"` |\n",
    "| `SUBSCRIPTION_ID`                              | string         | Yes      | ID of the subscription to be monitored                                     | `\"<Subscription Id>\"`                    |\n",
    "| `CUSTOM_MONITOR_METRICS`                       | list[dict]     | No       | List of metric definitions used in the custom monitor                      |                                           |\n",
    "| └─ `name`                                      | string         | No       | Name of the custom metric (e.g., `sensitivity`)                            |                                           |\n",
    "| └─ `description`                               | string         | No       | Human-readable description of the metric                                   |                                           |\n",
    "| └─ `type`                                      | string         | No       | Data type of the metric value (e.g., `number`)                             |                                           |\n",
    "| `CUSTOM_METRICS_PROVIDER_CREDENTIALS`          | dict           | No       | Dictionary with authentication method for custom metrics provider          |                                           |\n",
    "| └─ `auth_type`                                 | string         | No       | Authentication method (e.g., `bearer`)                                     |                                           |\n",
    "| └─ `token_info`                                | dict           | Yes      | Token generation details (used for bearer tokens)                          |                                           |\n",
    "|     └─ `url`                                   | string         | No       | URL to request IAM token                                                   |                                           |\n",
    "|     └─ `headers`                               | dict           | No       | HTTP headers for token request                                             |                                           |\n",
    "| `SCHEDULE              `                       | list[dict]     | No       | List of metric definitions used in the custom monitor                      |                                           |\n",
    "| └─ `repeat_interval`                           | integer        | No       | Interval between scheduled executions                                      | `1`                                       |\n",
    "| └─ `repeat_type`                               | string         | No       | Unit of repeat interval (`hour`, `day`, etc.)                              | `\"hour\"`                                  |\n",
    "| └─ `delay_unit`                                | string         | No       | Unit of delay duration (`minute`, `second`, etc.)                          |`\"minute\"`                                 |\n",
    "| └─ `delay_time`                                | integer        | No       | Delay duration before execution                                            |`5`                                        |\n",
    "| `CPD_INFO              `                       | list[dict]     | No       | List of metric definitions used in the custom monitor                      |                                           |\n",
    "| └─ `CPD_URL`                                   | string         | No       | CPD instance URL (if using CPD)                                            |                                           |\n",
    "| └─ `USERNAME   `                               | string         | No       | CPD Username                                                               |                                           |\n",
    "| └─ `PASSWORD`                                  | string         | No       | CPD User API Key                                                           |                                           |\n",
    "| └─ `VERSION`                                   | integer        | No       | Version                                                                    |`5.0`                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"CLOUD_API_KEY\": CLOUD_API_KEY,\n",
    "  \"SPACE_ID\": SPACE_ID,\n",
    "  \"DATAMART_ID\": DATAMART_ID,\n",
    "  \"SUBSCRIPTION_ID\": SUBSCRIPTION_ID,\n",
    "  \"WOS_URL\": OPENSCALE_API_URL,\n",
    "  \"CUSTOM_METRICS_WAIT_TIME\": 60,\n",
    "  \"CUSTOM_METRICS_PROVIDER_NAME\":\"Custom Metrics Provider\",\n",
    "  \"CUSTOM_MONITOR_NAME\":\"Sample Model Performance\",\n",
    "  \"DEPLOYMENT_NAME\": \"Custom Metrics Provider Deployment\",\n",
    "  \"PYTHON_FUNCTION_NAME\": \"Custom Metrics Provider Function\",\n",
    "  \"MONITOR_METRICS\": [\n",
    "    {\n",
    "      \"name\": \"specificity\",\n",
    "      \"thresholds\": {\n",
    "        \"lower_limit\": 0.8\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"sensitivity\",\n",
    "      \"thresholds\": {\n",
    "        \"lower_limit\": 0.6,\n",
    "        \"upper_limit\": 1.0\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"gender_less40_fav_prediction_ratio\",\n",
    "      \"thresholds\": {\n",
    "        \"lower_limit\": 0.6,\n",
    "        \"upper_limit\": 1.0\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"TAGS\": [\n",
    "      {\n",
    "          \"name\": \"region\",\n",
    "          \"TAG_DESCRIPTION\": \"Custom metrics tag for monitoring\"\n",
    "      }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51dab6f2e41045f38ead783922814c0a"
   },
   "source": [
    "## 3. Create the custom metrics provider - Python function <a name=\"provider\"></a>\n",
    "\n",
    "The Python function receives the required variables, such as the `datamart_id`, `monitor_instance_id`, `monitor_id`, `monitor_instance_parameters` and `subscription_id` from the Watson OpenScale service when it is invoked by the custom monitor. \n",
    "\n",
    "In the Python function, add your own logic to compute the custom metrics in the `get_metrics` method, publish the metrics to the Watson Openscale service and update the status of the run to the `finished` state in the custom monitor instance run.\n",
    "\n",
    "Note: Metric names must exactly match the names defined in the configuration otherwise, an error will occur while publishing the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "e7ec6979ce114f528246ba99e8619090"
   },
   "outputs": [],
   "source": [
    "#wml_python_function\n",
    "parms = {\n",
    "        \"url\": OPENSCALE_API_URL,\n",
    "        \"iam_url\": IAM_URL,\n",
    "        \"apikey\": CLOUD_API_KEY\n",
    "    }\n",
    "def custom_metrics_provider(parms = parms):\n",
    "    \n",
    "    import json\n",
    "    import requests\n",
    "    import base64\n",
    "    from requests.auth import HTTPBasicAuth\n",
    "    import time\n",
    "    import uuid\n",
    "    import datetime\n",
    "    \n",
    "    headers = {}\n",
    "    headers[\"Content-Type\"] = \"application/json\"\n",
    "    headers[\"Accept\"] = \"application/json\"\n",
    "\n",
    "    def get_access_token():\n",
    "        headers={}\n",
    "        headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n",
    "        headers[\"Accept\"] = \"application/json\"\n",
    "        auth = HTTPBasicAuth(\"bx\", \"bx\")\n",
    "        data = {\n",
    "            \"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\",\n",
    "            \"apikey\": parms[\"apikey\"]\n",
    "        }\n",
    "        response = requests.post(parms[\"iam_url\"], data=data, headers=headers, auth=auth)\n",
    "        json_data = response.json()\n",
    "        access_token = json_data['access_token']\n",
    "        return access_token    \n",
    "    \n",
    "    \n",
    "    def get_feedback_data(access_token, data_mart_id, feedback_dataset_id):\n",
    "        json_data = None\n",
    "        if feedback_dataset_id is not None:\n",
    "            headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "            DATASETS_STORE_RECORDS_URL = parms[\"url\"] + \"/openscale/{0}/v2/data_sets/{1}/records?limit={2}&format=list\".format(data_mart_id, feedback_dataset_id, 100)\n",
    "            response = requests.get(DATASETS_STORE_RECORDS_URL, headers=headers, verify=False)\n",
    "            json_data = response.json()\n",
    "            return json_data\n",
    "    \n",
    "    #Update the run status to Finished in the Monitor Run\n",
    "    def update_monitor_run_status(base_url, access_token, custom_monitor_instance_id, run_id, status, error_msg = None):\n",
    "        monitor_run_url = base_url + '/v2/monitor_instances/' + custom_monitor_instance_id + '/runs/'+run_id\n",
    "        completed_timestamp = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        patch_payload  = []\n",
    "        base_path = \"/status\"\n",
    "        \n",
    "        patch_payload.append(get_patch_request_field(base_path, \"state\", status))\n",
    "        patch_payload.append(get_patch_request_field(base_path, \"completed_at\", completed_timestamp))\n",
    "        if error_msg != None:\n",
    "            error_json = get_error_json(error_msg)\n",
    "            patch_payload.append(get_patch_request_field(base_path, \"failure\", error_json))\n",
    "        \n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "        response = requests.patch(monitor_run_url, headers=headers, json = patch_payload, verify=False)\n",
    "        monitor_run_response = response.json()\n",
    "        return response.status_code, monitor_run_response\n",
    "    \n",
    "    def get_error_json(error_message):\n",
    "        trace = str(uuid.uuid4())\n",
    "        error_json = {\n",
    "            'trace': trace,\n",
    "            'errors': [{\n",
    "                'code': \"custom_metrics_error_code\",\n",
    "                'message': str(error_message)\n",
    "            }]\n",
    "        }\n",
    "        return error_json\n",
    "    \n",
    "    def get_patch_request_field(base_path, field_name, field_value, op_name=\"replace\"):\n",
    "        field_json = {\n",
    "            \"op\": op_name,\n",
    "            \"path\": \"{0}/{1}\".format(base_path, field_name),\n",
    "            \"value\": field_value\n",
    "        }\n",
    "        return field_json\n",
    "    \n",
    "    #Add your code to compute the custom metrics. \n",
    "    def get_metrics(access_token, data_mart_id, subscription_id, feedback_dataset_id):\n",
    "        #Add the logic here to compute the metrics. Use the below metric names while creating the custom monitor definition\n",
    "        json_data = get_feedback_data(access_token, data_mart_id, feedback_dataset_id)\n",
    "        gender_less40_fav_prediction_ratio = 0\n",
    "        if json_data is not None and len(json_data['records']) > 0:\n",
    "            fields = json_data['records'][0]['fields']\n",
    "            values = json_data['records'][0]['values']\n",
    "            import pandas as pd\n",
    "            feedback_data = pd.DataFrame(values, columns = fields)\n",
    "            if 'Sex' in feedback_data.columns:\n",
    "                female_less40_fav_prediction = len(feedback_data.query('Sex == \\'female\\' & Age <= 40 & Risk == \\'No Risk\\''))\n",
    "                male_less40_fav_prediction = len(feedback_data.query('Sex == \\'male\\' & Age <= 40 & Risk == \\'No Risk\\''))\n",
    "                gender_less40_fav_prediction_ratio = female_less40_fav_prediction / male_less40_fav_prediction\n",
    "            \n",
    "        #Remove the tag(\"region\": \"us-south\") in below metrics while publishing the metric values to Openscale Datamart \n",
    "        #if the custom monitor definition is not created with tags\n",
    "        metrics = {\"specificity\": 1.2, \"sensitivity\": 0.85, \"gender_less40_fav_prediction_ratio\": gender_less40_fav_prediction_ratio, \"region\": \"us-south\"}\n",
    "        #metrics = {\"specificity\": 1.2, \"sensitivity\": 0.85, \"gender_less40_fav_prediction_ratio\": gender_less40_fav_prediction_ratio}\n",
    "                \n",
    "        return metrics\n",
    "        \n",
    "        \n",
    "    # Publishes the Custom Metrics to OpenScale\n",
    "    def publish_metrics(base_url, access_token, data_mart_id, subscription_id, custom_monitor_id, custom_monitor_instance_id, custom_monitoring_run_id, feedback_dataset_id, timestamp):\n",
    "        # Generate an monitoring run id, where the publishing happens against this run id\n",
    "        custom_metrics = get_metrics(access_token, data_mart_id, subscription_id, feedback_dataset_id)\n",
    "        measurements_payload = [\n",
    "                  {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"run_id\": custom_monitoring_run_id,\n",
    "                    \"metrics\": [custom_metrics]\n",
    "                  }\n",
    "                ]\n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "        headers[\"Content-Type\"] = \"application/json\"\n",
    "        measurements_url = base_url + '/v2/monitor_instances/' + custom_monitor_instance_id + '/measurements'\n",
    "        response = requests.post(measurements_url, headers=headers, json = measurements_payload, verify=False)\n",
    "        published_measurement = response.json()\n",
    "     \n",
    "        return response.status_code, published_measurement\n",
    "        \n",
    "    \n",
    "    def publish( input_data ):\n",
    "\n",
    "        timestamp = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        \n",
    "        payload = input_data.get(\"input_data\")[0].get(\"values\")\n",
    "        data_mart_id = payload['data_mart_id']\n",
    "        subscription_id = payload['subscription_id']\n",
    "        custom_monitor_id = payload['custom_monitor_id']\n",
    "        custom_monitor_instance_id = payload['custom_monitor_instance_id']\n",
    "        custom_monitor_instance_params  = payload['custom_monitor_instance_params']\n",
    "        custom_monitor_run_id = payload['custom_monitor_run_id']\n",
    "        payload_dataset_id = payload.get('payload_dataset_id')\n",
    "        feedback_dataset_id = payload.get('feedback_dataset_id')\n",
    "\n",
    "        base_url = parms['url'] + '/openscale' + '/' + data_mart_id\n",
    "        access_token = get_access_token()\n",
    "        \n",
    "        published_measurements = []\n",
    "        error_msgs = []\n",
    "        run_status = \"finished\"\n",
    "        error_msg = None\n",
    "        \n",
    "        try:\n",
    "            status_code, published_measurement = publish_metrics(base_url, access_token, data_mart_id, subscription_id, custom_monitor_id, custom_monitor_instance_id, custom_monitor_run_id, feedback_dataset_id, timestamp)\n",
    "            if int(status_code) in [200, 201, 202]:\n",
    "                published_measurements.append(published_measurement)\n",
    "            else:\n",
    "                run_status = \"error\"\n",
    "                error_msg = published_measurement\n",
    "                error_msgs.append(error_msg)\n",
    "                \n",
    "        except Exception as ex:\n",
    "            run_status = \"error\"\n",
    "            error_msg = str(ex)\n",
    "            error_msgs.append(error_msg)\n",
    "            \n",
    "        finally:\n",
    "            status_code, response = update_monitor_run_status(base_url, access_token, custom_monitor_instance_id, custom_monitor_run_id, run_status, error_msg)\n",
    "            if not int(status_code) in [200, 201, 202]:\n",
    "                error_msgs.append(response)\n",
    "    \n",
    "        if len(error_msgs) == 0:\n",
    "            response_payload = {\n",
    "                \"predictions\" : [{ \n",
    "                    \"values\" : published_measurements\n",
    "                }]\n",
    "\n",
    "            }\n",
    "        else:\n",
    "            response_payload = {\n",
    "                \"predictions\":[{\n",
    "                    \"values\":[{\"errors\": error_msgs}]\n",
    "                }]\n",
    "            }\n",
    "        \n",
    "        return response_payload\n",
    "        \n",
    "    return publish\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47683fe263944fafb25f856214b1ec70"
   },
   "source": [
    "## 4. Configure OpenScale. <a name=\"config\"></a>\n",
    "\n",
    "Import the required libraries and set up the Watson OpenScale Python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.2'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_watson_openscale import APIClient\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "authenticator = IAMAuthenticator(\n",
    "    apikey=config[\"CLOUD_API_KEY\"]\n",
    ")\n",
    "wos_client = APIClient(service_url=OPENSCALE_API_URL, authenticator=authenticator, service_instance_id = DATAMART_ID)\n",
    "wos_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set up the custom monitor configuration. <a name=\"custom_monitor\"></a>\n",
    "\n",
    "\n",
    "This setup initializes the WML client, sets the default space, deletes existing resources, and recreates the python function deployment, custom metrics provider, custom monitor definition, and monitor instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising  Watson Machine Learning (WML) client.\n",
      "Initilising Cloud WML\n",
      "Default space set to 192e05be-2fa2-4eda-b377-d32a941fb638\n",
      "Cleaning up existing deployment Custom Metrics Provider Deployment.\n",
      "Performing wml_online deployment Cleanup for: Custom Metrics Provider Deployment0199e738-6c4b-7ef4-b115-9c042e463e91\n",
      "Creating custom function.\n",
      "Deploy function as ONLINE : Custom Metrics Provider Deployment\n",
      "\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "Synchronous deployment creation for id: '4a2f3b7b-132d-4454-a48c-91c66a62357a' started\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "\n",
      "initializing\n",
      "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
      "....\n",
      "ready\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_id='257cc752-9f07-4bce-b273-da09f2d6cb11'\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Note: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n",
      "Deployed Custom Metrics Provider: https://us-south.ml.cloud.ibm.com/ml/v4/deployments/257cc752-9f07-4bce-b273-da09f2d6cb11/predictions?version=2025-10-16\n",
      "Setting up an Integration System for Custom Metrics Provider\n",
      "0199ec4b-c973-7050-b672-68fdb2b04940\n",
      "Creating custom monitor.\n",
      "Deleting existing monitor: Sample Model Performance\n",
      "\n",
      "\n",
      "=========================================================================\n",
      "\n",
      " Waiting for end of deleting monitor definition sample_model_performance \n",
      "\n",
      "=========================================================================\n",
      "\n",
      "\n",
      "\n",
      "finished\n",
      "\n",
      "---------------------------------------------------\n",
      " Successfully finished deleting monitor definition \n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=======================================================================\n",
      "\n",
      " Waiting for end of adding monitor definition sample_model_performance \n",
      "\n",
      "=======================================================================\n",
      "\n",
      "\n",
      "\n",
      "finished\n",
      "\n",
      "-------------------------------------------------\n",
      " Successfully finished adding monitor definition \n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "Custom monitor created with ID: sample_model_performance\n",
      "Creating monitor instance.\n",
      "Creating new monitor instance for monitor definition: sample_model_performance\n",
      "\n",
      "\n",
      "===================================================================================\n",
      "\n",
      " Waiting for end of monitor instance creation 0199ec50-9b6a-7b05-a6cf-7a61cd73b51f \n",
      "\n",
      "===================================================================================\n",
      "\n",
      "\n",
      "\n",
      "active\n",
      "\n",
      "---------------------------------------\n",
      " Monitor instance successfully created \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Monitor instance created: 0199ec50-9b6a-7b05-a6cf-7a61cd73b51f\n",
      "0199ec50-9b6a-7b05-a6cf-7a61cd73b51f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'function_id': '4a2f3b7b-132d-4454-a48c-91c66a62357a',\n",
       " 'deployment_id': '257cc752-9f07-4bce-b273-da09f2d6cb11',\n",
       " 'scoring_url': 'https://us-south.ml.cloud.ibm.com/ml/v4/deployments/257cc752-9f07-4bce-b273-da09f2d6cb11/predictions?version=2025-10-16',\n",
       " 'integrated_system_id': '0199ec4b-c973-7050-b672-68fdb2b04940',\n",
       " 'custom_monitor_id': 'sample_model_performance',\n",
       " 'custom_monitor_instance_id': '0199ec50-9b6a-7b05-a6cf-7a61cd73b51f'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wos_client.custom_monitor.setup_configuration(config,custom_metrics_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Get custom monitor configuration <a name=\"get_config\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_id': '4a2f3b7b-132d-4454-a48c-91c66a62357a',\n",
       " 'deployment_id': '257cc752-9f07-4bce-b273-da09f2d6cb11',\n",
       " 'scoring_url': 'https://us-south.ml.cloud.ibm.com/ml/v4/deployments/257cc752-9f07-4bce-b273-da09f2d6cb11/predictions?version=2025-10-16',\n",
       " 'integrated_system_id': '0199ec4b-c973-7050-b672-68fdb2b04940',\n",
       " 'custom_monitor_id': 'sample_model_performance',\n",
       " 'custom_monitor_instance_id': '0199ec50-9b6a-7b05-a6cf-7a61cd73b51f'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = wos_client.custom_monitor.get_custom_monitor_configuration(config=config)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_monitor_instance_id = result[\"custom_monitor_instance_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run the custom monitor <a name=\"run\"></a>\n",
    "\n",
    "The cell below runs the custom monitor and publishes the monitor metrics to OpenScale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================================================\n",
      "\n",
      " Waiting for end of monitoring run 6a6226f4-ee2c-43ca-900c-1f0934ddb7ff \n",
      "\n",
      "========================================================================\n",
      "\n",
      "\n",
      "\n",
      "finished\n",
      "\n",
      "---------------------------\n",
      " Successfully finished run \n",
      "---------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Execute the custom metrics provider deployment\n",
    "monitor_instance_run_info = wos_client.monitor_instances.run(\n",
    "        background_mode=False,\n",
    "        monitor_instance_id=custom_monitor_instance_id\n",
    "     ).result\n",
    "\n",
    "monitor_instance_run_info\n",
    "custom_monitor_run_id = monitor_instance_run_info.metadata.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Risk evaluations for subscription \n",
    "\n",
    "The cell below triggers all configured monitors (OOTB and custom) for the selected subscription. It assesses the test data, computes the metrics, and publishes the results to Watson OpenScale and Facts.\n",
    "\n",
    "For risk assessment of a development-type/pre production subscription, an evaluation dataset must be provided. The risk evaluation function uses the dataset path as an input parameter to evaluate the configured metric dimensions.\n",
    "\n",
    "Note: Disable Step 7 (Run the custom monitor) and uncomment the code in the following cell to run the custom monitor along with other monitors through MRM to evaluate the risk and publish the results to Facts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mrm_monitor_instance():\n",
    "    monitor_instances = wos_client.monitor_instances.list(data_mart_id = DATAMART_ID, monitor_definition_id = \"mrm\", target_target_id = SUBSCRIPTION_ID).result.monitor_instances\n",
    "    if len(monitor_instances) == 1:\n",
    "        return monitor_instances[0]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mrm_monitor_instance = get_mrm_monitor_instance()\n",
    "#mrm_monitor_instance_id = mrm_monitor_instance.metadata.id\n",
    "\n",
    "###################################################################################\n",
    "#Enable the below code for pre production flow\n",
    "######################################################################################\n",
    "\n",
    "#test_data_set_name = \"test_data\"\n",
    "#body = {}\n",
    "#test_data_path= \"test_data.csv\"\n",
    "\n",
    "#response = wos_client.monitor_instances.mrm.evaluate_risk(monitor_instance_id=mrm_monitor_instance_id, test_data_set_name=test_data_set_name,\n",
    "#                                                     test_data_path=test_data_path, body=body, project_id=PROJECT_ID,\n",
    "#                                                     includes_model_output=True, background_mode=False)\n",
    "#response.result.to_dict()\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "#Enable the below code for production flow \n",
    "######################################################################################\n",
    "#response  = wos_client.monitor_instances.mrm.evaluate_risk(monitor_instance_id=mrm_monitor_instance_id, \n",
    "#                                                      space_id = SPACE_ID, background_mode = False)\n",
    "#response.result.to_dict()\n",
    "############################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>0199ec50-9b6a-7b05-a6cf-7a61cd73b51f Monitor Runs Metrics from: 2025-10-09 14:50:29.023010  till: 2025-10-16 14:50:29.023028</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>ts</th><th style='border: 1px solid #dddddd'>id</th><th style='border: 1px solid #dddddd'>measurement_id</th><th style='border: 1px solid #dddddd'>value</th><th style='border: 1px solid #dddddd'>lower_limit</th><th style='border: 1px solid #dddddd'>upper_limit</th><th style='border: 1px solid #dddddd'>tags</th><th style='border: 1px solid #dddddd'>monitor_definition_id</th><th style='border: 1px solid #dddddd'>monitor_instance_id</th><th style='border: 1px solid #dddddd'>run_id</th><th style='border: 1px solid #dddddd'>target_type</th><th style='border: 1px solid #dddddd'>target_id</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>2025-10-16 09:20:19.477150+00:00</td><td style='border: 1px solid #dddddd'>sensitivity</td><td style='border: 1px solid #dddddd'>0199ec51-fa15-7d8f-8601-2827974b1ca5</td><td style='border: 1px solid #dddddd'>0.85</td><td style='border: 1px solid #dddddd'>0.6</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>['region:us-south']</td><td style='border: 1px solid #dddddd'>sample_model_performance</td><td style='border: 1px solid #dddddd'>0199ec50-9b6a-7b05-a6cf-7a61cd73b51f</td><td style='border: 1px solid #dddddd'>6a6226f4-ee2c-43ca-900c-1f0934ddb7ff</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>0199e738-6c4b-7ef4-b115-9c042e463e91</td></tr><tr><td style='border: 1px solid #dddddd'>2025-10-16 09:20:19.477150+00:00</td><td style='border: 1px solid #dddddd'>gender_less40_fav_prediction_ratio</td><td style='border: 1px solid #dddddd'>0199ec51-fa15-7d8f-8601-2827974b1ca5</td><td style='border: 1px solid #dddddd'>0.0</td><td style='border: 1px solid #dddddd'>0.6</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>['region:us-south']</td><td style='border: 1px solid #dddddd'>sample_model_performance</td><td style='border: 1px solid #dddddd'>0199ec50-9b6a-7b05-a6cf-7a61cd73b51f</td><td style='border: 1px solid #dddddd'>6a6226f4-ee2c-43ca-900c-1f0934ddb7ff</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>0199e738-6c4b-7ef4-b115-9c042e463e91</td></tr><tr><td style='border: 1px solid #dddddd'>2025-10-16 09:20:19.477150+00:00</td><td style='border: 1px solid #dddddd'>specificity</td><td style='border: 1px solid #dddddd'>0199ec51-fa15-7d8f-8601-2827974b1ca5</td><td style='border: 1px solid #dddddd'>1.2</td><td style='border: 1px solid #dddddd'>0.8</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['region:us-south']</td><td style='border: 1px solid #dddddd'>sample_model_performance</td><td style='border: 1px solid #dddddd'>0199ec50-9b6a-7b05-a6cf-7a61cd73b51f</td><td style='border: 1px solid #dddddd'>6a6226f4-ee2c-43ca-900c-1f0934ddb7ff</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>0199e738-6c4b-7ef4-b115-9c042e463e91</td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=custom_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e66248c-bbdb-4644-9dd8-b871e9aafaca"
   },
   "source": [
    "# [OPTIONAL STEP] Invoke the custom metrics provider python function as part of this notebook.\n",
    "\n",
    "Run the cell below to validate the custom metrics provider python function by providing the correct parameters to generate the custom metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_id(data_set_type: str):\n",
    "    data_sets = wos_client.data_sets.list(target_target_id= config[\"SUBSCRIPTION_ID\"], type = data_set_type).result.data_sets\n",
    "    feedback_data_set_id = None\n",
    "    if len(data_sets) > 0:\n",
    "        feedback_data_set_id = data_sets[0].metadata.id\n",
    "    return feedback_data_set_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "8fd2f8ec-bab9-4f9e-b3be-22822155fd9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'values': [[{'measurement_id': '0199ec53-dfb8-70db-854c-43e806680dc2',\n",
       "      'metrics': [{'gender_less40_fav_prediction_ratio': 0,\n",
       "        'region': 'us-south',\n",
       "        'sensitivity': 0.85,\n",
       "        'specificity': 1.2}],\n",
       "      'run_id': '6a6226f4-ee2c-43ca-900c-1f0934ddb7ff',\n",
       "      'timestamp': '2025-10-16T09:22:23.800294Z'}]]}]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "parameters = {\n",
    "    \"custom_metrics_provider_id\": result[\"integrated_system_id\"],\n",
    "    \"custom_metrics_wait_time\":   config[\"CUSTOM_METRICS_WAIT_TIME\"]\n",
    "}\n",
    "\n",
    "payload= {\n",
    "    \"data_mart_id\" : config[\"DATAMART_ID\"],\n",
    "    \"subscription_id\" : config[\"SUBSCRIPTION_ID\"],\n",
    "    \"custom_monitor_id\" : custom_monitor_instance_id,\n",
    "    \"custom_monitor_instance_id\" : custom_monitor_instance_id,\n",
    "    \"custom_monitor_run_id\":custom_monitor_run_id,\n",
    "    \"custom_monitor_instance_params\": parameters,\n",
    "    \"feedback_dataset_id\": get_dataset_id(\"feedback\")\n",
    "}\n",
    "\n",
    "input_data= { \"input_data\": [ { \"values\": payload } ]\n",
    "            }\n",
    "\n",
    "\n",
    "func_result = custom_metrics_provider()(input_data)\n",
    "func_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "210c3b5835494f67812f0704bad84705"
   },
   "source": [
    "## Congratulations\n",
    "\n",
    "You have finished configuring Custom Monitor Definition and Monitor instance and executing Custom Monitor Run for your Subscription. You can also run the custom monitor from `Watson OpenScale Dashboard`(http://aiopenscale.cloud.ibm.com). Click the tile of your model and select `Evaluate Now` option from `Actions` drop down menu to run the monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
