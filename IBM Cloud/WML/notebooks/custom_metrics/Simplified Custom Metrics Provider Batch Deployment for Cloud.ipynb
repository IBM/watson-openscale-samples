{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "130546d4-d72c-46f1-a506-246ace42ad56"
   },
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6d32920-c6f8-4df6-91a7-925640a9920a"
   },
   "source": [
    "# Working with a custom metrics provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab7073b7-baf8-48ba-b9fb-e39e497596aa"
   },
   "source": [
    "This notebook should be run in a Watson Studio project, using **IBM Runtime 24.1 on Python 3.11 XS** runtime environment. **If you are viewing this in Watson Studio and do not see the required runtime env in the upper right corner of your screen, please update the runtime now.** It requires service credentials for the following services:\n",
    "  * Watson OpenScale\n",
    "  * Watson Machine Learning\n",
    "\n",
    "## Overview\n",
    "\n",
    "This sample notebook demonstrates how to configure a custom monitor and compute metrics such as answer completeness, answer relevance, HAP, and PII for LLM subscriptions. Based on the values specified in the configuration cell, it automatically creates the custom monitor definition, WML batch deployment for the Python function, custom metrics provider with the deployment scoring endpoint, and a custom dataset for storing record-level metrics. Users must update the appropriate metric computation logic inside the Python function.\n",
    "\n",
    "During each run, OpenScale invokes the custom metrics provider(python function) and sends inputs like data_mart_id, subscription_id,  custom_monitor_id and other parameters. The provider then:\n",
    "\n",
    "- Reads data from feedback, payload logging, or other datasets.\n",
    "- Computes record-level metrics and saves them to the custom dataset.\n",
    "- Computes and publishes aggregated metrics to the Measurements API.\n",
    "- Updates the monitor run status to Finished.\n",
    "\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "  1. [Set up your environment](#setup)\n",
    "  1. [Configure values for the custom monitor](#provider)\n",
    "  1. [Create the custom metrics provider - python function](#deployment)\n",
    "  1. [Configure Watson OpenScale](#config)\n",
    "  1. [Set up the custom monitor](#custom_monitor)\n",
    "  1. [Get the custom monitor configuration](#get_config)\n",
    "  1. [Run the custom monitor](#run)\n",
    "  1. [Risk evaluations for subscription](#evaluate_risk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c3c7fcc-8701-45f3-ab34-af1b093b590c"
   },
   "source": [
    "## 1. Set up your environment <a name=\"#setup\"></a>\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "8b4212ee-4116-4a47-a586-f0997df1ec53",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Install the  `ibm_watsonx_ai` and `ibm-watson-openscale` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eb75b61-93b5-4139-96d5-fae98c8c9173",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm_watsonx_ai   | tail -n 1\n",
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd55a125-14e4-440c-a2ee-c58813d75f9e"
   },
   "source": [
    "### Action: restart the kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2abe81f0-cd47-4fe0-9b5c-505712c17752",
    "scrolled": true
   },
   "source": [
    "### Credentials for IBM Cloud\n",
    "To authenticate, in the following code boxes, replace the sample data with your own credentials. Get the information from your system administrator or through the IBM Cloud dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "37f4abdea5d34ffd87dc6716b8ff989c"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Paste your credentials into the following section and then run this cell.\n",
    "############################################################################################\n",
    "CLOUD_API_KEY = \"<Your Cloud IAM API Key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_ID = \"<Your space id>\"\n",
    "DATAMART_ID =  \"<DataMart Id>\"\n",
    "SUBSCRIPTION_ID= \"<Subscription Id>\"\n",
    "#PROJECT_ID = \"<Your project id>\" #update the project id for pre-production subscription\n",
    "\n",
    "OPENSCALE_API_URL = \"https://api.aiopenscale.cloud.ibm.com\"\n",
    "IAM_URL = \"https://iam.cloud.ibm.com/oidc/token\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure values for the custom monitor <a name=\"setup\"></a>\n",
    "\n",
    "Default values for the following custom monitor parameters are set. You can override them by specifying parameter values in the configuration cell.\n",
    "\n",
    "| Parameter Name                                | Type           | Optional | Description                                                                 | Default Value                              |\n",
    "|----------------------------------------------|----------------|----------|-----------------------------------------------------------------------------|-------------------------------------------|\n",
    "| `DEPLOYMENT_NAME`                             | string         | Yes      | Name of the function deployment                                             | `\"Custom Metrics Provider Deployment\"`   |\n",
    "| `PYTHON_FUNCTION_NAME`                        | string         | Yes      | Name of the Python function to be deployed                                 | `\"Custom Metrics Provider Function\"`      |\n",
    "| `CUSTOM_METRICS_PROVIDER_NAME`                | string         | Yes      | Name for the Custom Metrics Provider                                       | `\"Custom Metrics Provider\"`               |\n",
    "| `CUSTOM_MONITOR_NAME`                         | string         | Yes      | Name of the custom monitor                                                 | `\"Sample Model Performance\"`              |\n",
    "| `DATAMART_ID`                                 | string         | Yes      | Watson OpenScale DataMart GUID                                             | `\"00000000-0000-0000-0000-000000000000\"`  |\n",
    "| `SPACE_ID`                                    | string         | No      | Watson OpenScale Space ID                                                   | `\"<Your Space ID>\"`  |\n",
    "| `RUNTIME_ENV`                                 | string         | Yes      | Runtime environment for the Python function                                | `\"runtime-24.1-py3.11\"`                   |\n",
    "| `ENABLE_SCHEDULE`                             | boolean        | Yes      | Flag to enable scheduled runs of the monitor                               | `True`                                    |\n",
    "| `START_TIME`                                  | string         | Yes      | Scheduled run start time (format: `HH:MM:SS`)                              | `\"10:00:00\"`                              |\n",
    "| `CUSTOM_METRICS_WAIT_TIME`                    | integer        | Yes      | Time in seconds to check the run status                                    | `300`                                     |\n",
    "| `DELETE_CUSTOM_MONITOR`                       | boolean        | Yes      | Flag to delete any existing monitor with the same name                     | `True`                                   |\n",
    "| `DELETE_CUSTOM_MONITOR_INSTANCE`              | boolean        | Yes      | Flag to delete any existing monitor instance                               | `True`                                   |\n",
    "| `DELETE_INTEGRATED_SYSTEM`                    | boolean        | Yes      | Flag to delete the existing python function and associated custom metric provider                         | `True`                                   |\n",
    "| `ALGORITHM_TYPES`                              | list[string]   | Yes      | Types of algorithms used (`binary`, `regression`, etc.)                    | `[\"binary\",\"multiclass\",\"regression\",\"question_answering\",\"summarization\",\"retrieval_augmented_generation\",\"classification\",\"generation\",\"code_generation_and_conversion\",\"extraction\",\"translation\"]`                              |\n",
    "| `INPUT_DATA_TYPES`                              | list[string]   | Yes      | Type of input data (`structured`, `unstructured`)                          | `[\"structured\",\"unstructured_text\",\"unstructured_image\"]`                          |\n",
    "| `WOS_URL`                                      | string         | No       | URL of the Watson OpenScale instance                                       | `\"https://api.aiopenscale.cloud.ibm.com\"` |\n",
    "| `WML_URL`                                      | string         | No       | URL of Watson Machine Learning instance                                    | `\"https://us-south.ml.cloud.ibm.com\"`     |\n",
    "| `CLOUD_API_KEY`                                | string         | No       | IBM Cloud API Key for IAM authentication                                   | `\"<Your Cloud IAM API Key>\"`             |\n",
    "| `IAM_URL`                                      | string         | No       | IAM authentication URL                                                     | `\"https://iam.ng.bluemix.net/oidc/token\"` |\n",
    "| `SUBSCRIPTION_ID`                              | string         | Yes      | ID of the subscription to be monitored                                     | `\"<Subscription Id>\"`                    |\n",
    "| `CUSTOM_MONITOR_METRICS`                       | list[dict]     | No       | List of metric definitions used in the custom monitor                      |                                           |\n",
    "| └─ `name`                                      | string         | No       | Name of the custom metric (e.g., `sensitivity`)                            |                                           |\n",
    "| └─ `description`                               | string         | No       | Human-readable description of the metric                                   |                                           |\n",
    "| └─ `type`                                      | string         | No       | Data type of the metric value (e.g., `number`)                             |                                           |\n",
    "| `CUSTOM_METRICS_PROVIDER_CREDENTIALS`          | dict           | No       | Dictionary with authentication method for custom metrics provider          |                                           |\n",
    "| └─ `auth_type`                                 | string         | No       | Authentication method (e.g., `bearer`)                                     |                                           |\n",
    "| └─ `token_info`                                | dict           | Yes      | Token generation details (used for bearer tokens)                          |                                           |\n",
    "|     └─ `url`                                   | string         | No       | URL to request IAM token                                                   |                                           |\n",
    "|     └─ `headers`                               | dict           | No       | HTTP headers for token request                                             |                                           |\n",
    "| `SCHEDULE              `                       | list[dict]     | No       | List of metric definitions used in the custom monitor                      |                                           |\n",
    "| └─ `repeat_interval`                           | integer        | No       | Interval between scheduled executions                                      | `1`                                       |\n",
    "| └─ `repeat_type`                               | string         | No       | Unit of repeat interval (`hour`, `day`, etc.)                              | `\"hour\"`                                  |\n",
    "| └─ `delay_unit`                                | string         | No       | Unit of delay duration (`minute`, `second`, etc.)                          |`\"minute\"`                                 |\n",
    "| └─ `delay_time`                                | integer        | No       | Delay duration before execution                                            |`5`                                        |\n",
    "| `CPD_INFO              `                       | list[dict]     | No       | List of metric definitions used in the custom monitor                      |                                           |\n",
    "| └─ `CPD_URL`                                   | string         | No       | CPD instance URL (if using CPD)                                            |                                           |\n",
    "| └─ `USERNAME   `                               | string         | No       | CPD Username                                                               |                                           |\n",
    "| └─ `PASSWORD`                                  | string         | No       | CPD User API Key                                                           |                                           |\n",
    "| └─ `VERSION`                                   | integer        | No       | Version                                                                    |`5.0`                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"CLOUD_API_KEY\": CLOUD_API_KEY,\n",
    "  \"SPACE_ID\": SPACE_ID,\n",
    "  \"DATAMART_ID\": DATAMART_ID,\n",
    "  \"SUBSCRIPTION_ID\": SUBSCRIPTION_ID,\n",
    "  \"CUSTOM_MONITOR_NAME\":\"RAG Quality Monitor\",\n",
    "  \"DEPLOYMENT_TYPE\": \"wml_batch\",\n",
    "  \"CUSTOM_METRICS_WAIT_TIME\": 120,\n",
    "  \"MONITOR_METRICS\": [\n",
    "    {\n",
    "      \"name\": \"answer_completeness\",\n",
    "      \"thresholds\": {\n",
    "        \"lower_limit\": 0.8\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"answer_relevance\",\n",
    "      \"thresholds\": {\n",
    "        \"lower_limit\": 0.6,\n",
    "        \"upper_limit\": 1.0\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"hap\",\n",
    "      \"thresholds\": {\n",
    "        \"lower_limit\": 0.8\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"pii\",\n",
    "      \"thresholds\": {\n",
    "        \"lower_limit\": 0.8\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"TAGS\": [\n",
    "      {\n",
    "          \"name\": \"region\",\n",
    "          \"TAG_DESCRIPTION\": \"Custom metrics tag for monitoring\"\n",
    "      }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51dab6f2e41045f38ead783922814c0a"
   },
   "source": [
    "## 3. Create the custom metrics provider - Python function <a name=\"provider\"></a>\n",
    "\n",
    "The Python function receives the required variables such as the `datamart_id`, `monitor_instance_id`, `monitor_id`, `monitor_instance_parameters` and `subscription_id` from the Watson OpenScale service when it is invoked by the custom monitor.\n",
    "\n",
    "Within the Python function, implement your logic to compute the custom metrics in the `get_metrics` method and the record-level metrics in the `get_record_level_metrics` method, then publish the metrics to the Watson OpenScale service and update the monitor instance run status to finished.\n",
    "\n",
    "Note: Metric names must exactly match the names defined in the configuration otherwise, an error will occur while publishing the metrics.\n",
    "The `record_id` column in the custom dataset is unique (primary key), so you cannot save record-level metrics for the same record more than once. If you need to store duplicate or repeated records, use the `reference_record_id` field instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e7ec6979ce114f528246ba99e8619090"
   },
   "outputs": [],
   "source": [
    "#wml_python_function\n",
    "parms = {\n",
    "        \"url\": OPENSCALE_API_URL,\n",
    "        \"iam_url\": IAM_URL,\n",
    "        \"apikey\": CLOUD_API_KEY\n",
    "    }\n",
    "def custom_metrics_provider(parms = parms):\n",
    "    \n",
    "    import json\n",
    "    import requests\n",
    "    import base64\n",
    "    from requests.auth import HTTPBasicAuth\n",
    "    import time\n",
    "    import uuid\n",
    "    import datetime\n",
    "    import random\n",
    "    import pandas as pd\n",
    "    \n",
    "    headers = {}\n",
    "    headers[\"Content-Type\"] = \"application/json\"\n",
    "    headers[\"Accept\"] = \"application/json\"\n",
    "\n",
    "    def get_access_token():\n",
    "        token_headers={}\n",
    "        token_headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n",
    "        token_headers[\"Accept\"] = \"application/json\"\n",
    "        auth = HTTPBasicAuth(\"bx\", \"bx\")\n",
    "        data = {\n",
    "            \"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\",\n",
    "            \"apikey\": parms[\"apikey\"]\n",
    "        }\n",
    "        response = requests.post(parms[\"iam_url\"], data=data, headers=token_headers, auth=auth)\n",
    "        json_data = response.json()\n",
    "        access_token = json_data['access_token']\n",
    "        return access_token    \n",
    "    \n",
    "    \n",
    "    def get_feedback_data(access_token, data_mart_id, feedback_dataset_id):\n",
    "        json_data = None\n",
    "        if feedback_dataset_id is not None:\n",
    "            headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "            DATASETS_STORE_RECORDS_URL = parms[\"url\"] + \"/openscale/{0}/v2/data_sets/{1}/records?format=list&limit={2}\".format(data_mart_id, feedback_dataset_id, 10)\n",
    "            response = requests.get(DATASETS_STORE_RECORDS_URL, headers=headers, verify=False)\n",
    "            json_data = response.json()\n",
    "        \n",
    "            return json_data\n",
    "\n",
    "    def save_record_level_metrics(base_url, access_token, data_mart_id, custom_dataset_id, run_id, record_level_metrics_df):\n",
    "        \n",
    "        if custom_dataset_id and record_level_metrics_df is not None and not record_level_metrics_df.empty:\n",
    "            payload = [\n",
    "            {\n",
    "                \"fields\": list(record_level_metrics_df.columns),\n",
    "                \"values\": record_level_metrics_df.values.tolist()\n",
    "            }]\n",
    "            headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "            headers[\"Content-Type\"] = \"application/json\"\n",
    "            DATASETS_STORE_RECORDS_URL = base_url + \"/v2/data_sets/{1}/records\".format(data_mart_id, custom_dataset_id)\n",
    "            response = requests.post(DATASETS_STORE_RECORDS_URL, headers=headers, json = payload, verify=False)\n",
    "            record_lev_metrics_resp = response.json()\n",
    "            status_code = response.status_code\n",
    "            if int(status_code) in [200, 201, 202]:\n",
    "                print(f\"Accepted request to save record level metrics to custom dataset {custom_dataset_id}. response {record_lev_metrics_resp}\")\n",
    "            else:\n",
    "                print(f\"Failed while saving record level metrics to custom dataset. Error {record_lev_metrics_resp}\")\n",
    "\n",
    "    \n",
    "    #Update the run status to Finished in the Monitor Run\n",
    "    def update_monitor_run_status(base_url, access_token, custom_monitor_instance_id, run_id, status, error_msg = None):\n",
    "        monitor_run_url = base_url + '/v2/monitor_instances/' + custom_monitor_instance_id + '/runs/'+run_id\n",
    "        completed_timestamp = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        patch_payload  = []\n",
    "        base_path = \"/status\"\n",
    "        \n",
    "        patch_payload.append(get_patch_request_field(base_path, \"state\", status))\n",
    "        patch_payload.append(get_patch_request_field(base_path, \"completed_at\", completed_timestamp))\n",
    "        if error_msg != None:\n",
    "            error_json = get_error_json(error_msg)\n",
    "            patch_payload.append(get_patch_request_field(base_path, \"failure\", error_json))\n",
    "        \n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "        response = requests.patch(monitor_run_url, headers=headers, json = patch_payload, verify=False)\n",
    "        monitor_run_response = response.json()\n",
    "        return response.status_code, monitor_run_response\n",
    "    \n",
    "    def get_error_json(error_message):\n",
    "        trace = str(uuid.uuid4())\n",
    "        error_json = {\n",
    "            'trace': trace,\n",
    "            'errors': [{\n",
    "                'code': \"custom_metrics_error_code\",\n",
    "                'message': str(error_message)\n",
    "            }]\n",
    "        }\n",
    "        return error_json\n",
    "    \n",
    "    def get_patch_request_field(base_path, field_name, field_value, op_name=\"replace\"):\n",
    "        field_json = {\n",
    "            \"op\": op_name,\n",
    "            \"path\": \"{0}/{1}\".format(base_path, field_name),\n",
    "            \"value\": field_value\n",
    "        }\n",
    "        return field_json\n",
    "        \n",
    "    def get_record_level_metrics(feedback_data_df, feedback_dataset_id, custom_monitor_run_id):\n",
    "        # Add the computation logic here to compute the record level metrics\n",
    "        #The record_id column in the custom dataset is unique (primary key), so you cannot save record-level metrics for the same record more than once. \n",
    "        #If you need to store duplicate or repeated records, use the reference_record_id field instead.\n",
    "    \n",
    "        record_level_metrics_df = pd.DataFrame({\n",
    "            #\"record_id\": feedback_data_df[\"record_id\"],\n",
    "            \"reference_record_id\": feedback_data_df[\"record_id\"],\n",
    "            \"record_timestamp\": feedback_data_df[\"record_timestamp\"],\n",
    "            \"run_id\": custom_monitor_run_id,\n",
    "            \"computed_on\": \"feedback\",\n",
    "            \"data_set_id\": feedback_dataset_id,\n",
    "            # generate float values between 0 and 1\n",
    "            \"hap\": [round(random.random(), 2) for _ in range(len(feedback_data_df))],\n",
    "            \"pii\": [round(random.random(), 2) for _ in range(len(feedback_data_df))],\n",
    "            \"answer_completeness\": [round(random.random(), 2) for _ in range(len(feedback_data_df))],\n",
    "            \"answer_relevance\": [round(random.random(), 2) for _ in range(len(feedback_data_df))]\n",
    "            })\n",
    "\n",
    "        return record_level_metrics_df\n",
    "        \n",
    "    #Add your code to compute the custom metrics. \n",
    "    def get_metrics(access_token, data_mart_id, subscription_id, feedback_dataset_id, custom_monitor_run_id, timestamp):\n",
    "        #Add the logic here to compute the metrics. Use the below metric names while creating the custom monitor definition\n",
    "        json_data = get_feedback_data(access_token, data_mart_id, feedback_dataset_id)\n",
    "        metrics = None\n",
    "        record_level_metrics_df = pd.DataFrame()\n",
    "        if json_data is not None and len(json_data['records']) > 0:\n",
    "            fields = json_data['records'][0]['fields']\n",
    "            values = json_data['records'][0]['values']\n",
    "\n",
    "            feedback_data_df = pd.DataFrame(values, columns = fields)\n",
    "            record_level_metrics_df = get_record_level_metrics(feedback_data_df, feedback_dataset_id, custom_monitor_run_id)\n",
    "\n",
    "        #Remove the tag(\"region\": \"us-south\") in below metrics while publishing the metric values to Openscale Datamart \n",
    "        #if the custom monitor definition is not created with tags\n",
    "        \n",
    "        if not record_level_metrics_df.empty:\n",
    "            #Aggregate the record level metrics\n",
    "            metrics = {\"answer_completeness\": record_level_metrics_df[\"answer_completeness\"].mean(), \"answer_relevance\": record_level_metrics_df[\"answer_relevance\"].mean(),\"hap\": record_level_metrics_df[\"hap\"].mean(), \"pii\": record_level_metrics_df[\"pii\"].mean(), \"region\": \"us-south\"}\n",
    "        else:\n",
    "            metrics = {\"answer_completeness\": 0.6, \"answer_relevance\": 0.7, \"hap\": 0.9,\"pii\": 0.95, \"region\": \"us-south\"}\n",
    "        \n",
    "    \n",
    "        return metrics, record_level_metrics_df\n",
    "        \n",
    "        \n",
    "    # Publishes the Custom Metrics to OpenScale\n",
    "    def publish_metrics(base_url, access_token, data_mart_id, subscription_id, custom_monitor_id, custom_monitor_instance_id, custom_monitor_run_id, feedback_dataset_id, custom_dataset_id, timestamp):\n",
    "        # Generate an monitoring run id, where the publishing happens against this run id\n",
    "        custom_metrics, record_level_metrics = get_metrics(access_token, data_mart_id, subscription_id, feedback_dataset_id, custom_monitor_run_id, timestamp)\n",
    "        save_record_level_metrics(base_url, access_token, data_mart_id, custom_dataset_id, custom_monitor_run_id, record_level_metrics)\n",
    "        measurements_payload = [\n",
    "                  {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"run_id\": custom_monitor_run_id,\n",
    "                    \"metrics\": [custom_metrics]\n",
    "                  }\n",
    "                ]\n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "        headers[\"Content-Type\"] = \"application/json\"\n",
    "        measurements_url = base_url + '/v2/monitor_instances/' + custom_monitor_instance_id + '/measurements'\n",
    "        response = requests.post(measurements_url, headers=headers, json = measurements_payload, verify=False)\n",
    "        published_measurement = response.json()\n",
    "        return response.status_code, published_measurement\n",
    "        \n",
    "    \n",
    "    def publish( input_data ):\n",
    "        timestamp = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        payload_array = input_data.get(\"input_data\")[0].get(\"values\")\n",
    "        payload = payload_array[0]\n",
    "        data_mart_id = payload['data_mart_id']\n",
    "        subscription_id = payload['subscription_id']\n",
    "        custom_monitor_id = payload['custom_monitor_id']\n",
    "        custom_monitor_instance_id = payload['custom_monitor_instance_id']\n",
    "        custom_monitor_instance_params  = payload['custom_monitor_instance_params']\n",
    "        custom_monitor_run_id = payload['custom_monitor_run_id']\n",
    "        payload_dataset_id = payload.get('payload_dataset_id')\n",
    "        feedback_dataset_id = payload.get('feedback_dataset_id')\n",
    "        custom_dataset_id = payload.get('custom_dataset_id')\n",
    "\n",
    "        base_url = parms['url'] + '/openscale' + '/' + data_mart_id\n",
    "        access_token = get_access_token()\n",
    "        \n",
    "        published_measurements = []\n",
    "        error_msgs = []\n",
    "        run_status = \"finished\"\n",
    "        error_msg = None\n",
    "        \n",
    "        try:\n",
    "            status_code, published_measurement = publish_metrics(base_url, access_token, data_mart_id, subscription_id, custom_monitor_id, custom_monitor_instance_id, custom_monitor_run_id, feedback_dataset_id, custom_dataset_id, timestamp)\n",
    "            if int(status_code) in [200, 201, 202]:\n",
    "                published_measurements.append(published_measurement)\n",
    "            else:\n",
    "                run_status = \"error\"\n",
    "                error_msg = published_measurement\n",
    "                error_msgs.append(error_msg)\n",
    "                \n",
    "        except Exception as ex:\n",
    "            run_status = \"error\"\n",
    "            error_msg = str(ex)\n",
    "            error_msgs.append(error_msg)\n",
    "            \n",
    "        finally:\n",
    "            status_code, response = update_monitor_run_status(base_url, access_token, custom_monitor_instance_id, custom_monitor_run_id, run_status, error_msg)\n",
    "            if not int(status_code) in [200, 201, 202]:\n",
    "                error_msgs.append(response)\n",
    "    \n",
    "        if len(error_msgs) == 0:\n",
    "            response_payload = {\n",
    "                \"predictions\" : [{ \n",
    "                    \"values\" : published_measurements\n",
    "                }]\n",
    "\n",
    "            }\n",
    "        else:\n",
    "            response_payload = {\n",
    "                \"predictions\":[{\n",
    "                    \"values\":[{\"errors\": error_msgs}]\n",
    "                }]\n",
    "            }\n",
    "        \n",
    "        return response_payload\n",
    "        \n",
    "    return publish\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47683fe263944fafb25f856214b1ec70"
   },
   "source": [
    "## 4. Configure OpenScale. <a name=\"config\"></a>\n",
    "\n",
    "Import the required libraries and set up the Watson OpenScale Python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.2.19'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_watson_openscale import APIClient\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "authenticator = IAMAuthenticator(\n",
    "    apikey=config[\"CLOUD_API_KEY\"]\n",
    ")\n",
    "wos_client = APIClient(service_url=OPENSCALE_API_URL, authenticator=authenticator, service_instance_id = DATAMART_ID)\n",
    "wos_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set up the custom monitor configuration. <a name=\"custom_monitor\"></a>\n",
    "\n",
    "\n",
    "This setup initializes the WML client, sets the default space, deletes existing resources, and recreates the python function deployment, custom metrics provider, custom monitor definition, and monitor instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising  Watson Machine Learning (WML) client.\n",
      "Initilising Cloud WML\n",
      "Default space set to 77981bef-037d-421d-b60d-f5e7c0ee4689\n",
      "Setting up an Integration System for Custom Metrics Provider\n",
      "CUSTOM_METRICS_PROVIDER_NAME: Custom Metrics Provider_0199c390-f7f2-7f54-98cf-289b743c3218\n",
      "delete_integrated_system is True\n",
      "Cleaning up existing deployment Custom Metrics Provider Deployment.\n",
      "Performing Batch deployment Cleanup for: Custom Metrics Provider Deployment_0199c390-f7f2-7f54-98cf-289b743c3218\n",
      "Deleting Batch deployment: 0b1c46e6-2edc-418d-baf5-e63ab8407f99 \n",
      "Deleting associated asset: 4f8b27c0-6064-4c3a-85d0-eecb70e327b4\n",
      "Creating custom function.\n",
      "Deploy function as BATCH : Custom Metrics Provider Deployment\n",
      "\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "Synchronous deployment creation for id: 'cce46763-0f78-4402-bd5e-f7a251e3d313' started\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "\n",
      "ready.\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_id='7779cf78-0714-44c8-839d-37cab060a411'\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "019ab43b-13a6-78de-b045-276cec772386\n",
      "Creating custom monitor.\n",
      "Deleting existing monitor: RAG Quality Monitor\n",
      "Deleting custom dataset: 019aa6b1-259a-723f-8dfb-787825dd892b (table: 3184a853-c900-461d-88ff-baa15c175a0d.rag_quality_monitor_0199c390-f7f2-7f54-98cf-289b743c3218)\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "\n",
      " Waiting for end of deleting data set 019aa6b1-259a-723f-8dfb-787825dd892b \n",
      "\n",
      "===========================================================================\n",
      "\n",
      "\n",
      "\n",
      "finished\n",
      "\n",
      "-----------------------------------------\n",
      " Successfully finished deleting data set \n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "Custom dataset 019aa6b1-259a-723f-8dfb-787825dd892b deleted successfully\n",
      "\n",
      "\n",
      "====================================================================\n",
      "\n",
      " Waiting for end of deleting monitor definition rag_quality_monitor \n",
      "\n",
      "====================================================================\n",
      "\n",
      "\n",
      "\n",
      "active..................................................\n",
      "\n",
      "==================================================================\n",
      "\n",
      " Waiting for end of adding monitor definition rag_quality_monitor \n",
      "\n",
      "==================================================================\n",
      "\n",
      "\n",
      "\n",
      "finished\n",
      "\n",
      "-------------------------------------------------\n",
      " Successfully finished adding monitor definition \n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "Custom monitor created with ID: rag_quality_monitor\n",
      "Creating monitor instance.\n",
      "Creating new monitor instance for monitor definition: rag_quality_monitor\n",
      "\n",
      "\n",
      "===================================================================================\n",
      "\n",
      " Waiting for end of monitor instance creation 019ab43f-fbb8-787c-935a-5e20012c84b6 \n",
      "\n",
      "===================================================================================\n",
      "\n",
      "\n",
      "\n",
      "active\n",
      "\n",
      "---------------------------------------\n",
      " Monitor instance successfully created \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Monitor instance created: 019ab43f-fbb8-787c-935a-5e20012c84b6\n",
      "019ab43f-fbb8-787c-935a-5e20012c84b6\n",
      "Creating custom dataset for record-level metrics.\n",
      "Creating custom dataset with table name: rag_quality_monitor_0199c390-f7f2-7f54-98cf-289b743c3218\n",
      "Custom dataset created successfully with ID: 019ab440-18fa-7217-8dbd-971758164051\n",
      "Custom dataset created with ID: 019ab440-18fa-7217-8dbd-971758164051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'function_id': 'cce46763-0f78-4402-bd5e-f7a251e3d313',\n",
       " 'deployment_id': '7779cf78-0714-44c8-839d-37cab060a411',\n",
       " 'scoring_url': 'https://yp-qa.ml.cloud.ibm.com/ml/v4/deployment_jobs?version=2025-11-24',\n",
       " 'integrated_system_id': '019ab43b-13a6-78de-b045-276cec772386',\n",
       " 'custom_metrics_provider_name': 'Custom Metrics Provider_0199c390-f7f2-7f54-98cf-289b743c3218',\n",
       " 'custom_monitor_id': 'rag_quality_monitor',\n",
       " 'custom_monitor_instance_id': '019ab43f-fbb8-787c-935a-5e20012c84b6',\n",
       " 'custom_dataset_id': '019ab440-18fa-7217-8dbd-971758164051',\n",
       " 'custom_dataset_table_name': 'rag_quality_monitor_0199c390-f7f2-7f54-98cf-289b743c3218'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wos_client.custom_monitor.setup_configuration(config,custom_metrics_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Get custom monitor configuration <a name=\"get_config\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_id': 'cce46763-0f78-4402-bd5e-f7a251e3d313',\n",
       " 'deployment_id': '7779cf78-0714-44c8-839d-37cab060a411',\n",
       " 'scoring_url': 'https://yp-qa.ml.cloud.ibm.com/ml/v4/deployment_jobs?version=2025-11-24',\n",
       " 'integrated_system_id': '019ab43b-13a6-78de-b045-276cec772386',\n",
       " 'custom_metrics_provider_name': 'Custom Metrics Provider_0199c390-f7f2-7f54-98cf-289b743c3218',\n",
       " 'custom_monitor_id': 'rag_quality_monitor',\n",
       " 'custom_monitor_instance_id': '019ab43f-fbb8-787c-935a-5e20012c84b6',\n",
       " 'custom_dataset_id': '019ab440-18fa-7217-8dbd-971758164051',\n",
       " 'custom_dataset_table_name': 'rag_quality_monitor_0199c390-f7f2-7f54-98cf-289b743c3218'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = wos_client.custom_monitor.get_custom_monitor_configuration(config=config)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_monitor_instance_id = result[\"custom_monitor_instance_id\"]\n",
    "deployment_uid = result[\"deployment_id\"]\n",
    "custom_monitor_id = result[\"custom_monitor_id\"]\n",
    "custom_dataset_id = result[\"custom_dataset_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run the custom monitor <a name=\"run\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================================================\n",
      "\n",
      " Waiting for end of monitoring run e2fcb62f-349b-46df-9680-f5cd63393c24 \n",
      "\n",
      "========================================================================\n",
      "\n",
      "\n",
      "\n",
      "running...\n",
      "finished\n",
      "\n",
      "---------------------------\n",
      " Successfully finished run \n",
      "---------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Execute the custom metrics provider deployment\n",
    "monitor_instance_run_info = wos_client.monitor_instances.run(\n",
    "        background_mode=False,\n",
    "        monitor_instance_id=custom_monitor_instance_id\n",
    "     ).result\n",
    "\n",
    "monitor_instance_run_info\n",
    "custom_monitor_run_id = monitor_instance_run_info.metadata.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Risk evaluations for subscription \n",
    "\n",
    "The cell below triggers all configured monitors (OOTB and custom) for the selected subscription. It assesses the test data, computes the metrics, and publishes the results to Watson OpenScale and Facts.\n",
    "\n",
    "For risk assessment of a development-type/pre production subscription, an evaluation dataset must be provided. The risk evaluation function uses the dataset path as an input parameter to evaluate the configured metric dimensions.\n",
    "\n",
    "Note: Disable Step 7 (Run the custom monitor) and uncomment the code in the following cell to run the custom monitor along with other monitors through MRM to evaluate the risk and publish the results to Facts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mrm_monitor_instance():\n",
    "    monitor_instances = wos_client.monitor_instances.list(data_mart_id = DATAMART_ID, monitor_definition_id = \"mrm\", target_target_id = SUBSCRIPTION_ID).result.monitor_instances\n",
    "    if len(monitor_instances) == 1:\n",
    "        return monitor_instances[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mrm_monitor_instance = get_mrm_monitor_instance()\n",
    "#mrm_monitor_instance_id = mrm_monitor_instance.metadata.id\n",
    "\n",
    "###################################################################################\n",
    "#Enable the below code for pre production flow\n",
    "######################################################################################\n",
    "\n",
    "#test_data_set_name = \"test_data\"\n",
    "#body = {}\n",
    "#test_data_path= \"llm_data.csv\"\n",
    "\n",
    "#response = wos_client.monitor_instances.mrm.evaluate_risk(monitor_instance_id=mrm_monitor_instance_id, test_data_set_name=test_data_set_name,\n",
    "#                                                     test_data_path=test_data_path, body=body, project_id=PROJECT_ID,\n",
    "#                                                     includes_model_output=True, background_mode=False)\n",
    "#response.result.to_dict()\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "#Enable the below code for production flow \n",
    "######################################################################################\n",
    "#response  = wos_client.monitor_instances.mrm.evaluate_risk(monitor_instance_id=mrm_monitor_instance_id, \n",
    "#                                                      space_id = SPACE_ID, background_mode = False)\n",
    "#response.result.to_dict()\n",
    "############################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>019ab43f-fbb8-787c-935a-5e20012c84b6 Monitor Runs Metrics from: 2025-11-17 10:35:38.982907  till: 2025-11-24 10:35:38.982913</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>ts</th><th style='border: 1px solid #dddddd'>id</th><th style='border: 1px solid #dddddd'>measurement_id</th><th style='border: 1px solid #dddddd'>value</th><th style='border: 1px solid #dddddd'>lower_limit</th><th style='border: 1px solid #dddddd'>upper_limit</th><th style='border: 1px solid #dddddd'>tags</th><th style='border: 1px solid #dddddd'>monitor_definition_id</th><th style='border: 1px solid #dddddd'>monitor_instance_id</th><th style='border: 1px solid #dddddd'>run_id</th><th style='border: 1px solid #dddddd'>target_type</th><th style='border: 1px solid #dddddd'>target_id</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>2025-11-24 05:05:26.806091+00:00</td><td style='border: 1px solid #dddddd'>answer_relevance</td><td style='border: 1px solid #dddddd'>019ab440-a516-7bab-b72d-2c293916a308</td><td style='border: 1px solid #dddddd'>0.502</td><td style='border: 1px solid #dddddd'>0.6</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>['region:us-south']</td><td style='border: 1px solid #dddddd'>rag_quality_monitor</td><td style='border: 1px solid #dddddd'>019ab43f-fbb8-787c-935a-5e20012c84b6</td><td style='border: 1px solid #dddddd'>e2fcb62f-349b-46df-9680-f5cd63393c24</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>0199c390-f7f2-7f54-98cf-289b743c3218</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-24 05:05:26.806091+00:00</td><td style='border: 1px solid #dddddd'>pii</td><td style='border: 1px solid #dddddd'>019ab440-a516-7bab-b72d-2c293916a308</td><td style='border: 1px solid #dddddd'>0.5</td><td style='border: 1px solid #dddddd'>0.8</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['region:us-south']</td><td style='border: 1px solid #dddddd'>rag_quality_monitor</td><td style='border: 1px solid #dddddd'>019ab43f-fbb8-787c-935a-5e20012c84b6</td><td style='border: 1px solid #dddddd'>e2fcb62f-349b-46df-9680-f5cd63393c24</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>0199c390-f7f2-7f54-98cf-289b743c3218</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-24 05:05:26.806091+00:00</td><td style='border: 1px solid #dddddd'>hap</td><td style='border: 1px solid #dddddd'>019ab440-a516-7bab-b72d-2c293916a308</td><td style='border: 1px solid #dddddd'>0.279</td><td style='border: 1px solid #dddddd'>0.8</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['region:us-south']</td><td style='border: 1px solid #dddddd'>rag_quality_monitor</td><td style='border: 1px solid #dddddd'>019ab43f-fbb8-787c-935a-5e20012c84b6</td><td style='border: 1px solid #dddddd'>e2fcb62f-349b-46df-9680-f5cd63393c24</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>0199c390-f7f2-7f54-98cf-289b743c3218</td></tr><tr><td style='border: 1px solid #dddddd'>2025-11-24 05:05:26.806091+00:00</td><td style='border: 1px solid #dddddd'>answer_completeness</td><td style='border: 1px solid #dddddd'>019ab440-a516-7bab-b72d-2c293916a308</td><td style='border: 1px solid #dddddd'>0.537</td><td style='border: 1px solid #dddddd'>0.8</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['region:us-south']</td><td style='border: 1px solid #dddddd'>rag_quality_monitor</td><td style='border: 1px solid #dddddd'>019ab43f-fbb8-787c-935a-5e20012c84b6</td><td style='border: 1px solid #dddddd'>e2fcb62f-349b-46df-9680-f5cd63393c24</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>0199c390-f7f2-7f54-98cf-289b743c3218</td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=custom_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show record level metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.data_sets.show_records(data_set_id= custom_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e66248c-bbdb-4644-9dd8-b871e9aafaca"
   },
   "source": [
    "# [OPTIONAL STEP] Invoke the custom metrics python function deployment as part of this notebook.\n",
    "\n",
    "Run the cell below to validate the custom metrics provider python function by providing the correct parameters to generate the custom metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_id(data_set_type: str):\n",
    "    data_sets = wos_client.data_sets.list(target_target_id= config[\"SUBSCRIPTION_ID\"], type = data_set_type).result.data_sets\n",
    "    feedback_data_set_id = None\n",
    "    if len(data_sets) > 0:\n",
    "        feedback_data_set_id = data_sets[0].metadata.id\n",
    "    return feedback_data_set_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the custom monitor instance configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor instance details picking for Subscription: 0199c390-f7f2-7f54-98cf-289b743c3218 ,monitor definition: rag_quality_monitor \n"
     ]
    }
   ],
   "source": [
    "res = wos_client.custom_monitor.get_monitor_instance_config(config=config)\n",
    "monitor_instance_parameters = res[\"monitor_instances\"][0][\"entity\"][\"parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted request to save record level metrics to custom dataset 019ab440-18fa-7217-8dbd-971758164051. response {'state': 'preparing'}\n",
      "{'predictions': [{'values': [[{'measurement_id': '019ab441-9176-7b25-9a1a-4cad02e75657', 'metrics': [{'answer_completeness': 0.507, 'answer_relevance': 0.34700000000000003, 'hap': 0.5850000000000001, 'pii': 0.398, 'region': 'us-south'}], 'run_id': 'e2fcb62f-349b-46df-9680-f5cd63393c24', 'timestamp': '2025-11-24T05:06:27.318053Z'}]]}]}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"custom_metrics_provider_id\": result[\"integrated_system_id\"],\n",
    "    \"custom_metrics_wait_time\": monitor_instance_parameters[\"custom_metrics_wait_time\"],\n",
    "    \"custom_metrics_provider_type\": monitor_instance_parameters[\"custom_metrics_provider_type\"],\n",
    "    \"space_id\": monitor_instance_parameters[\"space_id\"],\n",
    "    \"deployment_id\":monitor_instance_parameters[\"deployment_id\"],\n",
    "    \"hardware_spec_id\": monitor_instance_parameters[\"hardware_spec_id\"]\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"data_mart_id\" : config[\"DATAMART_ID\"],\n",
    "    \"subscription_id\" : config[\"SUBSCRIPTION_ID\"],\n",
    "    \"custom_monitor_id\" : result[\"custom_monitor_id\"],\n",
    "    \"custom_monitor_instance_id\" : custom_monitor_instance_id,\n",
    "    \"custom_monitor_run_id\": custom_monitor_run_id,\n",
    "    \"custom_monitor_instance_params\": parameters,\n",
    "    \"feedback_dataset_id\": get_dataset_id(\"feedback\"),\n",
    "    \"custom_dataset_id\": custom_dataset_id\n",
    "    \n",
    "}\n",
    "\n",
    "input_data= { \"input_data\": [ {\"values\": [ payload ] } ]\n",
    "            }\n",
    "func_result = custom_metrics_provider()(input_data)\n",
    "print(func_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "210c3b5835494f67812f0704bad84705"
   },
   "source": [
    "## Congratulations\n",
    "\n",
    "You have finished configuring Custom Monitor Definition and Monitor instance and executing Custom Monitor Run for your Subscription. You can also run the custom monitor from `Watson OpenScale Dashboard`(http://aiopenscale.cloud.ibm.com). Click the tile of your model and select `Evaluate Now` option from `Actions` drop down menu to run the monitor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
