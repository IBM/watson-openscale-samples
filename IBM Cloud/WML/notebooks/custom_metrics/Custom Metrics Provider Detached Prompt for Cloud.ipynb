{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afbf0b",
   "metadata": {},
   "source": [
    "# Working with a custom metrics provider for Detached PTA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0da5be",
   "metadata": {},
   "source": [
    " This notebook should be run in a Watson Studio project, using **IBM Runtime 24.1 on Python 3.11 XS** runtime environment. **If you are viewing this in Watson Studio and do not see the required runtime env in the upper right corner of your screen, please update the runtime now.**. It requires service credentials for the following services:\n",
    "  * Watson OpenScale\n",
    "  * Watson Machine Learning\n",
    "\n",
    "## Overview\n",
    "\n",
    "This sample notebook demonstrates how to create and deploy a PTA in space and configure a custom monitor and compute metrics such as answer completeness, answer relevance, HAP, and PII for LLM subscriptions. Based on the values specified in the configuration cell, it automatically creates the custom monitor definition, WML batch deployment for the Python function, custom metrics provider with the deployment scoring endpoint, and a custom dataset for storing record-level metrics. Users must update the appropriate metric computation logic inside the Python function.\n",
    "\n",
    "During each run, OpenScale invokes the custom metrics provider(python function) and sends inputs like data_mart_id, subscription_id, custom_monitor_id and other parameters. The provider then:\n",
    "\n",
    "- Reads data from feedback, payload logging, or other datasets.\n",
    "- Computes record-level metrics and saves them to the custom dataset.\n",
    "- Computes and publishes aggregated metrics to the Measurements API.\n",
    "- Updates the monitor run status to Finished.\n",
    "  \n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "  1. [Set up your environment](#setup)\n",
    "  2. [Create Prompt template](#prompt)\n",
    "  3. [Prompt Setup](#ptatsetup)\n",
    "  4. [Configure Values for the Custom Monitor](#provider)\n",
    "  5. [Create the custom metrics provider - Python function](#deployment)\n",
    "  6. [Set up the custom monitor configuration](#monitor)\n",
    "  7. [Get custom monitor configuration](#run)\n",
    "  8. [Risk evaluations for PTA subscription](#run)\n",
    "  9. [Display the Custom metrics](#custom_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ea38c",
   "metadata": {},
   "source": [
    "## 1. Set up your environment <a name=\"setup\"></a>\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c4e61",
   "metadata": {},
   "source": [
    "### Install the  `ibm-watson-machine-learning` and `ibm-watson-openscale` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0371652",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-watson-machine-learning   | tail -n 1\n",
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb89807",
   "metadata": {},
   "source": [
    "Note: you may need to restart the kernel to use updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1fee7",
   "metadata": {},
   "source": [
    "### Provision services and configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e02956f",
   "metadata": {},
   "source": [
    "If you have not already, provision an instance of IBM Watson OpenScale using the [OpenScale link in the Cloud catalog](https://cloud.ibm.com/catalog/services/watson-openscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9676c128",
   "metadata": {},
   "source": [
    "Your Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913b738",
   "metadata": {},
   "source": [
    "**NOTE:** You can also get OpenScale `API_KEY` using IBM CLOUD CLI.\n",
    "\n",
    "How to install IBM Cloud (bluemix) console: [instruction](https://console.bluemix.net/docs/cli/reference/ibmcloud/download_cli.html#install_use)\n",
    "\n",
    "How to get api key using console:\n",
    "```\n",
    "bx login --sso\n",
    "bx iam api-key-create 'my_key'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19437386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IAM_URL = \"https://iam.cloud.ibm.com/oidc/token\"\n",
    "DATAPLATFORM_URL = \"https://api.dataplatform.cloud.ibm.com\"\n",
    "SERVICE_URL = \"https://api.aiopenscale.cloud.ibm.com\"\n",
    "CLOUD_API_KEY = \"<Your Cloud IAM API Key>\"\n",
    "DATAMART_ID =  \"<DataMart Id>\"\n",
    "WML_URL = \"<WML URL>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be950f80",
   "metadata": {},
   "source": [
    "### Set the project ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb9ccb",
   "metadata": {},
   "source": [
    "In order to set up a development type subscription, the PTA must be within the project. Please supply the project ID where the PTA needs to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"\" # YOUR_PROJECT_ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c2cc49",
   "metadata": {},
   "source": [
    "### Set the space ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067fbdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_ID = \"\" #YOUR_SPACE_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e3c14",
   "metadata": {},
   "source": [
    "### Function to create the access token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa233200",
   "metadata": {},
   "source": [
    "This function generates an IAM access token using the provided credentials. The API calls for creating and scoring prompt template assets utilize the token generated by this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a636a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "\n",
    "def generate_access_token():\n",
    "    headers = {}\n",
    "    headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n",
    "    headers[\"Accept\"] = \"application/json\"\n",
    "    data = {\n",
    "        \"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\",\n",
    "        \"apikey\": CLOUD_API_KEY,\n",
    "        \"response_type\": \"cloud_iam\"\n",
    "    }\n",
    "    response = requests.post(IAM_URL, data=data, headers=headers)\n",
    "    json_data = response.json()\n",
    "    iam_access_token = json_data[\"access_token\"]\n",
    "\n",
    "    return iam_access_token\n",
    "\n",
    "iam_access_token = generate_access_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a149d",
   "metadata": {},
   "source": [
    "# HuggingFace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4fdf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    tokenizer=\"google/flan-t5-base\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a69e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download summarisation data\n",
    "!rm summarisation.csv\n",
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/summarization/summarisation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data_path = \"summarisation.csv\"\n",
    "llm_data = pd.read_csv(test_data_path)\n",
    "llm_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba7225",
   "metadata": {},
   "source": [
    "## Set the generated_summary with the summary from HF Google Flan model prompt evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt_text):\n",
    "    summary = (summarizer(prompt_text, max_length=len(prompt_text), min_length=1))\n",
    "    summary_text = summary[0][\"summary_text\"]\n",
    "    return summary_text\n",
    "\n",
    "llm_data[\"generated_text\"] = llm_data[\"original_text\"].apply(get_completion)\n",
    "llm_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e9ea64",
   "metadata": {},
   "source": [
    "## 2. Create Prompt template <a name=\"prompt\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1010c42c",
   "metadata": {},
   "source": [
    "Create a prompt template for a summarization task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02a8b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_aigov_facts_client import AIGovFactsClient\n",
    "\n",
    "facts_client = AIGovFactsClient(\n",
    "    api_key=CLOUD_API_KEY,\n",
    "    container_id=PROJECT_ID,\n",
    "    container_type=\"project\",\n",
    "    disable_tracing=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e1b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/04/30 11:53:41 INFO : ------------------------------ Detached Prompt Creation Started ------------------------------\n",
      "2025/04/30 11:53:44 INFO : The detached prompt with ID 40027bbd-9f13-4098-b314-a31e0c8f8700 was created successfully in container_id acf10f1c-58d6-449e-9b38-a996ab1c432d.\n"
     ]
    }
   ],
   "source": [
    "from ibm_aigov_facts_client import DetachedPromptTemplate, PromptTemplate\n",
    "\n",
    "detached_information = DetachedPromptTemplate(\n",
    "    prompt_id=\"detached_prompt\",\n",
    "    model_id=\"google/flan-t5-base\",\n",
    "    model_provider=\"Hugging Face\",\n",
    "    model_name=\"google/flan-t5-base\",\n",
    "    model_url=\"https://huggingface.co/google/flan-t5-base\",\n",
    "    prompt_url=\"prompt_url\",\n",
    "    prompt_additional_info={\"model_owner\": \"huggingface\"}\n",
    ")\n",
    "\n",
    "task_id = \"summarization\"\n",
    "name = \"Summarization-detached notebook\"\n",
    "description = \"My first detached prompt\"\n",
    "model_id = \"google/flan-t5-base\"\n",
    "\n",
    "# define parameters for PromptTemplate\n",
    "prompt_variables = {\"original_text\": \"\"}\n",
    "input = \"{original_text}\"\n",
    "input_prefix = \"Input:\"\n",
    "output_prefix = \"Output:\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input=input,\n",
    "    prompt_variables=prompt_variables,\n",
    "    input_prefix=input_prefix,\n",
    "    output_prefix=output_prefix\n",
    ")\n",
    "\n",
    "pta_details = facts_client.assets.create_detached_prompt(\n",
    "    model_id=model_id,\n",
    "    task_id=task_id,\n",
    "    name=name,\n",
    "    description=description,\n",
    "    prompt_details=prompt_template,\n",
    "    detached_information=detached_information\n",
    ")\n",
    "project_pta_id = pta_details.to_dict()[\"asset_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f461ed5",
   "metadata": {},
   "source": [
    "## 3. Prompt setup <a name=\"ptatsetup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73617c12",
   "metadata": {},
   "source": [
    "### Configure OpenScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aae1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.46'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator, CloudPakForDataAuthenticator\n",
    "from ibm_watson_openscale import APIClient\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "\n",
    "\n",
    "service_instance_id = None  # Update this to refer to a particular service instance\n",
    "authenticator = IAMAuthenticator(\n",
    "    apikey=CLOUD_API_KEY\n",
    ")\n",
    "wos_client = APIClient(\n",
    "    authenticator=authenticator,\n",
    "    service_url=SERVICE_URL,\n",
    "    service_instance_id= DATAMART_ID\n",
    ")\n",
    "data_mart_id =  wos_client.service_instance_id\n",
    "wos_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaaad56",
   "metadata": {},
   "source": [
    "### Promote the asset to Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45499c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Accept\"] = \"*/*\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(iam_access_token)\n",
    "verify = True\n",
    "\n",
    "url = \"{}/v2/assets/{}/promote\".format(DATAPLATFORM_URL ,project_pta_id)\n",
    "\n",
    "params = {\n",
    "    \"project_id\":PROJECT_ID\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"space_id\": SPACE_ID\n",
    "}\n",
    "response = requests.post(url, json=payload, headers=headers, params = params, verify = verify)\n",
    "json_data = response.json()\n",
    "space_pta_id = json_data[\"metadata\"][\"asset_id\"]\n",
    "space_pta_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db826512",
   "metadata": {},
   "source": [
    "### Deployment of asset from space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72b2ab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14598d71-1df4-4687-a583-23f4982841a1\n"
     ]
    }
   ],
   "source": [
    "DEPLOYMENTS_URL = WML_URL + \"/ml/v4/deployments\"\n",
    "\n",
    "headers={}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Accept\"] = \"*/*\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(iam_access_token)\n",
    "verify = True\n",
    "payload = {\n",
    "    \"prompt_template\": {\n",
    "      \"id\": space_pta_id\n",
    "    },\n",
    "    \"detached\": {\n",
    "    },\n",
    "    \"base_model_id\": \"meta-llama/llama-3-70b-instruct\",\n",
    "    \"description\": \"summarization-detached\",\n",
    "    \"name\": \"summarization_detached\",\n",
    "    \"space_id\": SPACE_ID\n",
    "}\n",
    "\n",
    "version = \"2023-07-07\" # The version date for the API of the form YYYY-MM-DD. Example : 2023-07-07\n",
    "params = {\n",
    "    \"version\":version,\n",
    "    \"space_id\":SPACE_ID\n",
    "}\n",
    "\n",
    "response = requests.post(DEPLOYMENTS_URL, json=payload, headers=headers, params = params, verify = verify)\n",
    "json_data = response.json()\n",
    "\n",
    "\n",
    "if \"metadata\" in json_data:\n",
    "    deployment_id = json_data[\"metadata\"][\"id\"]\n",
    "    print(deployment_id)\n",
    "else:\n",
    "    print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd6053",
   "metadata": {},
   "source": [
    "### Setup the prompt template asset in project for evaluation with supported monitor dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543853d0",
   "metadata": {},
   "source": [
    "The prompt template assets from space is supported with `pre_production` or `production` operational space ID. Running the below cell will create a development type subscription from the prompt template asset created within the project.\n",
    "\n",
    "The available parameters that can be passed for `execute_prompt_setup` function are:\n",
    "\n",
    " * `prompt_template_asset_id` : Id of prompt template asset for which subscription needs to be created.\n",
    " * `label_column` :  The name of the column containing the ground truth or actual labels.\n",
    " * `project_id` : The GUID of the project.\n",
    " * `space_id` : The GUID of the space.\n",
    " * `deployment_id` : (optional) The GUID of the deployment.\n",
    " * `operational_space_id` : The rank of the environment in which the monitoring is happening. Accepted values are `development`, `pre_production`, `production`.\n",
    " * `problem_type` : (optional) The task type to monitor for the given prompt template asset.\n",
    " * `classification_type` : The classification type `binary`/`multiclass` applicable only for `classification` problem (task) type.\n",
    " * `input_data_type` : The input data type.\n",
    " * `supporting_monitors` : Monitor configuration for the subscription to be created.\n",
    " * `background_mode` : When `True`, the promt setup operation will be executed in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1810cc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================\n",
      "\n",
      " Waiting for end of adding prompt setup b8601bfe-06a4-4669-b7bd-eda9c6d1ce76 \n",
      "\n",
      "=============================================================================\n",
      "\n",
      "\n",
      "\n",
      "running.\n",
      "finished\n",
      "\n",
      "---------------------------------------------------------------\n",
      " Successfully finished setting up prompt template subscription \n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_column = \"reference_summary\"\n",
    "operational_space_id = \"pre_production\"\n",
    "problem_type = \"summarization\"\n",
    "input_data_type = \"unstructured_text\"\n",
    "\n",
    "monitors = {\n",
    "    \"generative_ai_quality\": {\n",
    "        \"parameters\": {\n",
    "            \"min_sample_size\": 10,\n",
    "            \"metrics_configuration\": {\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = wos_client.wos.execute_prompt_setup(\n",
    "    prompt_template_asset_id=space_pta_id,\n",
    "    space_id=SPACE_ID,\n",
    "    deployment_id=deployment_id,\n",
    "    label_column=label_column,\n",
    "    operational_space_id=operational_space_id,\n",
    "    problem_type=problem_type,\n",
    "    input_data_type=input_data_type,\n",
    "    supporting_monitors=monitors,\n",
    "    background_mode=False\n",
    ")\n",
    "\n",
    "result = response.result\n",
    "res_dict = result.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe07a2",
   "metadata": {},
   "source": [
    "With the below cell, users can  read the  prompt setup task and check its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a942f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01968561-1b2a-7e33-be21-7664c95df22d'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SUBSCRIPTION_ID = result.to_dict()[\"subscription_id\"]\n",
    "SUBSCRIPTION_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65378d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished prompt setup. The response is {'prompt_template_asset_id': 'b8601bfe-06a4-4669-b7bd-eda9c6d1ce76', 'space_id': 'f0941313-c25e-440b-9531-ad0106f8435d', 'deployment_id': '14598d71-1df4-4687-a583-23f4982841a1', 'service_provider_id': '01968561-1761-7274-a799-4a163bbb9d75', 'subscription_id': '01968561-1b2a-7e33-be21-7664c95df22d', 'mrm_monitor_instance_id': '01968561-3a93-7bfc-a331-3e84de3f177f', 'start_time': '2025-04-30T06:27:34.210928Z', 'end_time': '2025-04-30T06:27:50.975981Z', 'status': {'state': 'FINISHED'}}\n"
     ]
    }
   ],
   "source": [
    "response = wos_client.wos.get_prompt_setup(\n",
    "    prompt_template_asset_id=space_pta_id,\n",
    "    space_id=SPACE_ID,\n",
    "    deployment_id=deployment_id\n",
    ")\n",
    "\n",
    "result = response.result\n",
    "result_json = result.to_dict()\n",
    "\n",
    "if result_json[\"status\"][\"state\"] == \"FINISHED\":\n",
    "    print(\"Finished prompt setup. The response is {}\".format(result_json))\n",
    "else:\n",
    "    print(\"Prompt setup failed. The response is {}\".format(result_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb8129b",
   "metadata": {},
   "source": [
    "### Read required IDs from prompt setup response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a458ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSCRIPTION_ID = result_json[\"subscription_id\"]\n",
    "mrm_monitor_instance_id = result_json[\"mrm_monitor_instance_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de52029",
   "metadata": {},
   "source": [
    "## Configure Custom Monitor for Detached PTA subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14fbda",
   "metadata": {},
   "source": [
    "## 4. Default values for the custom monitor <a name=\"setup\"></a>\n",
    "Default values for the following custom monitor parameters are set. You can override them by specifying parameter values in the configuration cell.\n",
    "\n",
    "| Parameter Name                                | Type           | Optional | Description                                                                 | Default Value                              |\n",
    "|----------------------------------------------|----------------|----------|-----------------------------------------------------------------------------|-------------------------------------------|\n",
    "| `DEPLOYMENT_NAME`                             | string         | Yes      | Name of the function deployment                                             | `\"Custom Metrics Provider Deployment\"`   |\n",
    "| `PYTHON_FUNCTION_NAME`                        | string         | Yes      | Name of the Python function to be deployed                                 | `\"Custom Metrics Provider Function\"`      |\n",
    "| `CUSTOM_METRICS_PROVIDER_NAME`                | string         | Yes      | Name for the Custom Metrics Provider                                       | `\"Custom Metrics Provider\"`               |\n",
    "| `CUSTOM_MONITOR_NAME`                         | string         | Yes      | Name of the custom monitor                                                 | `\"Sample Model Performance\"`              |\n",
    "| `DATAMART_ID`                                 | string         | Yes      | Watson OpenScale DataMart GUID                                             | `\"00000000-0000-0000-0000-000000000000\"`  |\n",
    "| `SPACE_ID`                                    | string         | No      | Watson OpenScale Space ID                                                   | `\"<Your Space ID>\"`  |\n",
    "| `RUNTIME_ENV`                                 | string         | Yes      | Runtime environment for the Python function                                | `\"runtime-24.1-py3.11\"`                   |\n",
    "| `ENABLE_SCHEDULE`                             | boolean        | Yes      | Flag to enable scheduled runs of the monitor                               | `True`                                    |\n",
    "| `START_TIME`                                  | string         | Yes      | Scheduled run start time (format: `HH:MM:SS`)                              | `\"10:00:00\"`                              |\n",
    "| `CUSTOM_METRICS_WAIT_TIME`                    | integer        | Yes      | Time in seconds to check the run status                                    | `60`                                     |\n",
    "| `DELETE_CUSTOM_MONITOR`                       | boolean        | Yes      | Flag to delete any existing monitor with the same name                     | `True`                                   |\n",
    "| `DELETE_CUSTOM_MONITOR_INSTANCE`              | boolean        | Yes      | Flag to delete any existing monitor instance                               | `True`                                   |\n",
    "| `ALGORITHM_TYPES`                              | list[string]   | Yes      | Types of algorithms used (`binary`, `regression`, etc.)                    | `[\"binary\",\"multiclass\",\"regression\",\"question_answering\",\"summarization\",\"retrieval_augmented_generation\",\"classification\",\"generation\",\"extraction\"]`                              |\n",
    "| `INPUT_DATA_TYPES`                              | list[string]   | Yes      | Type of input data (`structured`, `unstructured`)                          | `[\"structured\",\"unstructured_text\",\"unstructured_image\"]`                          |\n",
    "| `WOS_URL`                                      | string         | No       | URL of the Watson OpenScale instance                                       | `\"https://api.aiopenscale.cloud.ibm.com\"` |\n",
    "| `WML_URL`                                      | string         | No       | URL of Watson Machine Learning instance                                    | `\"https://us-south.ml.cloud.ibm.com\"`     |\n",
    "| `CLOUD_API_KEY`                                | string         | No       | IBM Cloud API Key for IAM authentication                                   | `\"<Your Cloud IAM API Key>\"`             |\n",
    "| `IAM_URL`                                      | string         | No       | IAM authentication URL                                                     | `\"https://iam.ng.bluemix.net/oidc/token\"` |\n",
    "| `SUBSCRIPTION_ID`                              | string         | Yes      | ID of the subscription to be monitored                                     | `\"<Subscription Id>\"`                    |\n",
    "| `CUSTOM_MONITOR_METRICS`                       | list[dict]     | No       | List of metric definitions used in the custom monitor                      |                                           |\n",
    "| └─ `name`                                      | string         | No       | Name of the custom metric (e.g., `sensitivity`)                            |                                           |\n",
    "| └─ `description`                               | string         | No       | Human-readable description of the metric                                   |                                           |\n",
    "| └─ `type`                                      | string         | No       | Data type of the metric value (e.g., `number`)                             |                                           |\n",
    "| `CUSTOM_METRICS_PROVIDER_CREDENTIALS`          | dict           | No       | Dictionary with authentication method for custom metrics provider          |                                           |\n",
    "| └─ `auth_type`                                 | string         | No       | Authentication method (e.g., `bearer`)                                     |                                           |\n",
    "| └─ `token_info`                                | dict           | Yes      | Token generation details (used for bearer tokens)                          |                                           |\n",
    "|     └─ `url`                                   | string         | No       | URL to request IAM token                                                   |                                           |\n",
    "|     └─ `headers`                               | dict           | No       | HTTP headers for token request                                             |                                           |\n",
    "| `SCHEDULE              `                       | list[dict]     | No       | List of metric definitions used in the custom monitor                      |                                           |\n",
    "| └─ `repeat_interval`                           | integer        | No       | Interval between scheduled executions                                      | `1`                                       |\n",
    "| └─ `repeat_type`                               | string         | No       | Unit of repeat interval (`hour`, `day`, etc.)                              | `\"hour\"`                                  |\n",
    "| └─ `delay_unit`                                | string         | No       | Unit of delay duration (`minute`, `second`, etc.)                          |`\"minute\"`                                 |\n",
    "| └─ `delay_time`                                | integer        | No       | Delay duration before execution                                            |`5`                                        |\n",
    "| `CPD_INFO              `                       | list[dict]     | No       | List of metric definitions used in the custom monitor                      |                                           |\n",
    "| └─ `CPD_URL`                                   | string         | No       | CPD instance URL (if using CPD)                                            |                                           |\n",
    "| └─ `USERNAME   `                               | string         | No       | CPD Username                                                               |                                           |\n",
    "| └─ `PASSWORD`                                  | string         | No       | CPD User API Key                                                           |                                           |\n",
    "| └─ `VERSION`                                   | integer        | No       | Version                                                                    |`5.0`                                      |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a15a5b9",
   "metadata": {},
   "source": [
    "### Configuration cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "   \"CLOUD_API_KEY\": CLOUD_API_KEY,\n",
    "  \"SPACE_ID\": SPACE_ID,\n",
    "  \"DATAMART_ID\": DATAMART_ID,\n",
    "  \"SUBSCRIPTION_ID\": SUBSCRIPTION_ID,\n",
    "  \"CUSTOM_METRICS_WAIT_TIME\": 60,\n",
    "  \"WML_URL\": WML_URL,\n",
    "  \"CUSTOM_MONITOR_NAME\": \"RAG Quality Monitor\",\n",
    "  \"MONITOR_METRICS\": [\n",
    "      {\n",
    "          \"name\": \"answer_completeness\",\n",
    "          \"thresholds\": {\n",
    "              \"lower_limit\": 0.8\n",
    "          }\n",
    "      },\n",
    "      {\n",
    "          \"name\": \"answer_relevance\",\n",
    "          \"thresholds\": {\n",
    "              \"lower_limit\": 0.6,\n",
    "              \"upper_limit\": 1\n",
    "          }\n",
    "      },\n",
    "      {\n",
    "          \"name\": \"hap\",\n",
    "          \"thresholds\": {\n",
    "              \"lower_limit\": 0.8\n",
    "          }\n",
    "      },\n",
    "      {\n",
    "          \"name\": \"pii\",\n",
    "          \"thresholds\": {\n",
    "              \"lower_limit\": 0.8\n",
    "          }\n",
    "      }\n",
    "  ],\n",
    "  \"TAGS\": [\n",
    "      {\n",
    "          \"name\": \"region\",\n",
    "          \"TAG_DESCRIPTION\": \"Custom metrics tag for monitoring\"\n",
    "      }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8809b3",
   "metadata": {},
   "source": [
    "## 5. Create the custom metrics provider - Python function <a name=\"provider\"></a>\n",
    "\n",
    "The Python function receives the required variables, such as the `datamart_id`, `monitor_instance_id`, `monitor_id`, `monitor_instance_parameters` and `subscription_id` from the Watson OpenScale service when it is invoked by the custom monitor. \n",
    "\n",
    "In the Python function, add your own logic to compute the custom metrics in the `get_metrics` method, publish the metrics to the Watson Openscale service and update the status of the run to the `finished` state in the custom monitor instance run.\n",
    "\n",
    "Update the `WOS_CREDENTIALS` in the Python function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wml_python_function\n",
    "parms = {\n",
    "        \"url\": SERVICE_URL,\n",
    "        \"iam_url\": IAM_URL,\n",
    "        \"apikey\": CLOUD_API_KEY\n",
    "    }\n",
    "def custom_metrics_provider(parms = parms):\n",
    "    \n",
    "    import json\n",
    "    import requests\n",
    "    import base64\n",
    "    from requests.auth import HTTPBasicAuth\n",
    "    import time\n",
    "    import uuid\n",
    "    import datetime\n",
    "    import random\n",
    "    import pandas as pd\n",
    "    \n",
    "    headers = {}\n",
    "    headers[\"Content-Type\"] = \"application/json\"\n",
    "    headers[\"Accept\"] = \"application/json\"\n",
    "\n",
    "    def get_access_token():\n",
    "        token_headers={}\n",
    "        token_headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n",
    "        token_headers[\"Accept\"] = \"application/json\"\n",
    "        auth = HTTPBasicAuth(\"bx\", \"bx\")\n",
    "        data = {\n",
    "            \"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\",\n",
    "            \"apikey\": parms[\"apikey\"]\n",
    "        }\n",
    "        response = requests.post(parms[\"iam_url\"], data=data, headers=token_headers, auth=auth)\n",
    "        json_data = response.json()\n",
    "        access_token = json_data['access_token']\n",
    "        return access_token    \n",
    "    \n",
    "    \n",
    "    def get_feedback_data(access_token, data_mart_id, feedback_dataset_id):\n",
    "        json_data = None\n",
    "        if feedback_dataset_id is not None:\n",
    "            headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "            DATASETS_STORE_RECORDS_URL = parms[\"url\"] + \"/openscale/{0}/v2/data_sets/{1}/records?format=list&limit={2}\".format(data_mart_id, feedback_dataset_id, 10)\n",
    "            response = requests.get(DATASETS_STORE_RECORDS_URL, headers=headers, verify=False)\n",
    "            json_data = response.json()\n",
    "        \n",
    "            return json_data\n",
    "\n",
    "    def save_record_level_metrics(base_url, access_token, data_mart_id, custom_dataset_id, run_id, record_level_metrics_df):\n",
    "        \n",
    "        if custom_dataset_id and record_level_metrics_df is not None and not record_level_metrics_df.empty:\n",
    "            payload = [\n",
    "            {\n",
    "                \"fields\": list(record_level_metrics_df.columns),\n",
    "                \"values\": record_level_metrics_df.values.tolist()\n",
    "            }]\n",
    "            headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "            headers[\"Content-Type\"] = \"application/json\"\n",
    "            DATASETS_STORE_RECORDS_URL = base_url + \"/v2/data_sets/{1}/records\".format(data_mart_id, custom_dataset_id)\n",
    "            response = requests.post(DATASETS_STORE_RECORDS_URL, headers=headers, json = payload, verify=False)\n",
    "            record_lev_metrics_resp = response.json()\n",
    "            status_code = response.status_code\n",
    "            if int(status_code) in [200, 201, 202]:\n",
    "                print(f\"Accepted request to save record level metrics to custom dataset {custom_dataset_id}. response {record_lev_metrics_resp}\")\n",
    "            else:\n",
    "                print(f\"Failed while saving record level metrics to custom dataset. Error {record_lev_metrics_resp}\")\n",
    "\n",
    "    \n",
    "    #Update the run status to Finished in the Monitor Run\n",
    "    def update_monitor_run_status(base_url, access_token, custom_monitor_instance_id, run_id, status, error_msg = None):\n",
    "        monitor_run_url = base_url + '/v2/monitor_instances/' + custom_monitor_instance_id + '/runs/'+run_id\n",
    "        completed_timestamp = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        patch_payload  = []\n",
    "        base_path = \"/status\"\n",
    "        \n",
    "        patch_payload.append(get_patch_request_field(base_path, \"state\", status))\n",
    "        patch_payload.append(get_patch_request_field(base_path, \"completed_at\", completed_timestamp))\n",
    "        if error_msg != None:\n",
    "            error_json = get_error_json(error_msg)\n",
    "            patch_payload.append(get_patch_request_field(base_path, \"failure\", error_json))\n",
    "        \n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "        response = requests.patch(monitor_run_url, headers=headers, json = patch_payload, verify=False)\n",
    "        monitor_run_response = response.json()\n",
    "        return response.status_code, monitor_run_response\n",
    "    \n",
    "    def get_error_json(error_message):\n",
    "        trace = str(uuid.uuid4())\n",
    "        error_json = {\n",
    "            'trace': trace,\n",
    "            'errors': [{\n",
    "                'code': \"custom_metrics_error_code\",\n",
    "                'message': str(error_message)\n",
    "            }]\n",
    "        }\n",
    "        return error_json\n",
    "    \n",
    "    def get_patch_request_field(base_path, field_name, field_value, op_name=\"replace\"):\n",
    "        field_json = {\n",
    "            \"op\": op_name,\n",
    "            \"path\": \"{0}/{1}\".format(base_path, field_name),\n",
    "            \"value\": field_value\n",
    "        }\n",
    "        return field_json\n",
    "        \n",
    "    def get_record_level_metrics(feedback_data_df, feedback_dataset_id, custom_monitor_run_id):\n",
    "        # Add the computation logic here to compute the record level metrics\n",
    "        #The record_id column in the custom dataset is unique (primary key), so you cannot save record-level metrics for the same record more than once. \n",
    "        #If you need to store duplicate or repeated records, use the reference_record_id field instead.\n",
    "    \n",
    "        record_level_metrics_df = pd.DataFrame({\n",
    "            #\"record_id\": feedback_data_df[\"record_id\"],\n",
    "            \"reference_record_id\": feedback_data_df[\"record_id\"],\n",
    "            \"record_timestamp\": feedback_data_df[\"record_timestamp\"],\n",
    "            \"run_id\": custom_monitor_run_id,\n",
    "            \"computed_on\": \"feedback\",\n",
    "            \"data_set_id\": feedback_dataset_id,\n",
    "            # generate float values between 0 and 1\n",
    "            \"hap\": [round(random.random(), 2) for _ in range(len(feedback_data_df))],\n",
    "            \"pii\": [round(random.random(), 2) for _ in range(len(feedback_data_df))],\n",
    "            \"answer_completeness\": [round(random.random(), 2) for _ in range(len(feedback_data_df))],\n",
    "            \"answer_relevance\": [round(random.random(), 2) for _ in range(len(feedback_data_df))]\n",
    "            })\n",
    "\n",
    "        return record_level_metrics_df\n",
    "        \n",
    "    #Add your code to compute the custom metrics. \n",
    "    def get_metrics(access_token, data_mart_id, subscription_id, feedback_dataset_id, custom_monitor_run_id, timestamp):\n",
    "        #Add the logic here to compute the metrics. Use the below metric names while creating the custom monitor definition\n",
    "        json_data = get_feedback_data(access_token, data_mart_id, feedback_dataset_id)\n",
    "        metrics = None\n",
    "        record_level_metrics_df = pd.DataFrame()\n",
    "        if json_data is not None and len(json_data['records']) > 0:\n",
    "            fields = json_data['records'][0]['fields']\n",
    "            values = json_data['records'][0]['values']\n",
    "\n",
    "            feedback_data_df = pd.DataFrame(values, columns = fields)\n",
    "            record_level_metrics_df = get_record_level_metrics(feedback_data_df, feedback_dataset_id, custom_monitor_run_id)\n",
    "\n",
    "        #Remove the tag(\"region\": \"us-south\") in below metrics while publishing the metric values to Openscale Datamart \n",
    "        #if the custom monitor definition is not created with tags\n",
    "        \n",
    "        if not record_level_metrics_df.empty:\n",
    "            #Aggregate the record level metrics\n",
    "            metrics = {\"answer_completeness\": record_level_metrics_df[\"answer_completeness\"].mean(), \"answer_relevance\": record_level_metrics_df[\"answer_relevance\"].mean(),\"hap\": record_level_metrics_df[\"hap\"].mean(), \"pii\": record_level_metrics_df[\"pii\"].mean(), \"region\": \"us-south\"}\n",
    "        else:\n",
    "            metrics = {\"answer_completeness\": 0.6, \"answer_relevance\": 0.7, \"hap\": 0.9,\"pii\": 0.95, \"region\": \"us-south\"}\n",
    "        \n",
    "    \n",
    "        return metrics, record_level_metrics_df\n",
    "        \n",
    "        \n",
    "    # Publishes the Custom Metrics to OpenScale\n",
    "    def publish_metrics(base_url, access_token, data_mart_id, subscription_id, custom_monitor_id, custom_monitor_instance_id, custom_monitor_run_id, feedback_dataset_id, custom_dataset_id, timestamp):\n",
    "        # Generate an monitoring run id, where the publishing happens against this run id\n",
    "        custom_metrics, record_level_metrics = get_metrics(access_token, data_mart_id, subscription_id, feedback_dataset_id, custom_monitor_run_id, timestamp)\n",
    "        save_record_level_metrics(base_url, access_token, data_mart_id, custom_dataset_id, custom_monitor_run_id, record_level_metrics)\n",
    "        measurements_payload = [\n",
    "                  {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"run_id\": custom_monitor_run_id,\n",
    "                    \"metrics\": [custom_metrics]\n",
    "                  }\n",
    "                ]\n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "        headers[\"Content-Type\"] = \"application/json\"\n",
    "        measurements_url = base_url + '/v2/monitor_instances/' + custom_monitor_instance_id + '/measurements'\n",
    "        response = requests.post(measurements_url, headers=headers, json = measurements_payload, verify=False)\n",
    "        published_measurement = response.json()\n",
    "        return response.status_code, published_measurement\n",
    "        \n",
    "    \n",
    "    def publish( input_data ):\n",
    "        timestamp = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        payload = input_data.get(\"input_data\")[0].get(\"values\")\n",
    "        data_mart_id = payload['data_mart_id']\n",
    "        subscription_id = payload['subscription_id']\n",
    "        custom_monitor_id = payload['custom_monitor_id']\n",
    "        custom_monitor_instance_id = payload['custom_monitor_instance_id']\n",
    "        custom_monitor_instance_params  = payload['custom_monitor_instance_params']\n",
    "        custom_monitor_run_id = payload['custom_monitor_run_id']\n",
    "        payload_dataset_id = payload.get('payload_dataset_id')\n",
    "        feedback_dataset_id = payload.get('feedback_dataset_id')\n",
    "        custom_dataset_id = payload.get('custom_dataset_id')\n",
    "\n",
    "        base_url = parms['url'] + '/openscale' + '/' + data_mart_id\n",
    "        access_token = get_access_token()\n",
    "        \n",
    "        published_measurements = []\n",
    "        error_msgs = []\n",
    "        run_status = \"finished\"\n",
    "        error_msg = None\n",
    "        \n",
    "        try:\n",
    "            status_code, published_measurement = publish_metrics(base_url, access_token, data_mart_id, subscription_id, custom_monitor_id, custom_monitor_instance_id, custom_monitor_run_id, feedback_dataset_id, custom_dataset_id, timestamp)\n",
    "            if int(status_code) in [200, 201, 202]:\n",
    "                published_measurements.append(published_measurement)\n",
    "            else:\n",
    "                run_status = \"error\"\n",
    "                error_msg = published_measurement\n",
    "                error_msgs.append(error_msg)\n",
    "                \n",
    "        except Exception as ex:\n",
    "            run_status = \"error\"\n",
    "            error_msg = str(ex)\n",
    "            error_msgs.append(error_msg)\n",
    "            \n",
    "        finally:\n",
    "            status_code, response = update_monitor_run_status(base_url, access_token, custom_monitor_instance_id, custom_monitor_run_id, run_status, error_msg)\n",
    "            if not int(status_code) in [200, 201, 202]:\n",
    "                error_msgs.append(response)\n",
    "    \n",
    "        if len(error_msgs) == 0:\n",
    "            response_payload = {\n",
    "                \"predictions\" : [{ \n",
    "                    \"values\" : published_measurements\n",
    "                }]\n",
    "\n",
    "            }\n",
    "        else:\n",
    "            response_payload = {\n",
    "                \"predictions\":[{\n",
    "                    \"values\":[{\"errors\": error_msgs}]\n",
    "                }]\n",
    "            }\n",
    "        \n",
    "        return response_payload\n",
    "        \n",
    "    return publish\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d219027",
   "metadata": {},
   "source": [
    "## 6. Set up the custom monitor configuration. <a name=\"custom_monitor\"></a>\n",
    "\n",
    "\n",
    "This setup initializes the WML client, sets the default space, deletes existing resources, and recreates the python function deployment, custom metrics provider, custom monitor definition, and monitor instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.custom_monitor.setup_configuration(config,custom_metrics_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0749b4d",
   "metadata": {},
   "source": [
    "## 7. Get custom monitor configuration <a name=\"get_config\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d00cf21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_id': '6d10299c-a396-4f05-9a57-98ea57d67b3d',\n",
       " 'deployment_id': '13e3669b-dcd8-43e7-854a-f8843d159fb2',\n",
       " 'scoring_url': 'https://us-south.ml.cloud.ibm.com/ml/v4/deployments/13e3669b-dcd8-43e7-854a-f8843d159fb2/predictions?version=2025-04-30',\n",
       " 'integrated_system_id': '01968562-ca4c-7858-ab05-d92f5d31cb1f',\n",
       " 'custom_monitor_id': 'sample_model_performance',\n",
       " 'custom_monitor_instance_id': '01968562-f7a5-706e-9390-00b1aec736fd'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = wos_client.custom_monitor.get_custom_monitor_configuration(config=config)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8655b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01968562-f7a5-706e-9390-00b1aec736fd'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_monitor_instance_id = result[\"custom_monitor_instance_id\"]\n",
    "custom_monitor_id = result[\"custom_monitor_id\"]\n",
    "custom_dataset_id = result[\"custom_dataset_id\"]\n",
    "custom_monitor_instance_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9505ed4",
   "metadata": {},
   "source": [
    "## Show all the monitor instances of the subscription\n",
    "The following cell lists the monitors present in the development subscription along with their respective statuses and other details. Please wait for all the monitors to be in active state before proceeding further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc915ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>Monitor instances</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>data_mart_id</th><th style='border: 1px solid #dddddd'>status</th><th style='border: 1px solid #dddddd'>target_id</th><th style='border: 1px solid #dddddd'>target_type</th><th style='border: 1px solid #dddddd'>monitor_definition_id</th><th style='border: 1px solid #dddddd'>created_at</th><th style='border: 1px solid #dddddd'>id</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>2e25b9e6-1dc2-4ea2-9c81-53904ab3d931</td><td style='border: 1px solid #dddddd'>active</td><td style='border: 1px solid #dddddd'>01968561-1b2a-7e33-be21-7664c95df22d</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>sample_model_performance</td><td style='border: 1px solid #dddddd'>2025-04-30 06:29:39.002000+00:00</td><td style='border: 1px solid #dddddd'>01968562-f7a5-706e-9390-00b1aec736fd</td></tr><tr><td style='border: 1px solid #dddddd'>2e25b9e6-1dc2-4ea2-9c81-53904ab3d931</td><td style='border: 1px solid #dddddd'>active</td><td style='border: 1px solid #dddddd'>01968561-1b2a-7e33-be21-7664c95df22d</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>generative_ai_quality</td><td style='border: 1px solid #dddddd'>2025-04-30 06:27:42.145000+00:00</td><td style='border: 1px solid #dddddd'>01968561-3180-7a13-bcc8-b69c54b16302</td></tr><tr><td style='border: 1px solid #dddddd'>2e25b9e6-1dc2-4ea2-9c81-53904ab3d931</td><td style='border: 1px solid #dddddd'>active</td><td style='border: 1px solid #dddddd'>01968561-1b2a-7e33-be21-7664c95df22d</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>model_health</td><td style='border: 1px solid #dddddd'>2025-04-30 06:27:43.449000+00:00</td><td style='border: 1px solid #dddddd'>01968561-34df-7d57-a12a-5520f520d403</td></tr><tr><td style='border: 1px solid #dddddd'>2e25b9e6-1dc2-4ea2-9c81-53904ab3d931</td><td style='border: 1px solid #dddddd'>active</td><td style='border: 1px solid #dddddd'>01968561-1b2a-7e33-be21-7664c95df22d</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>mrm</td><td style='border: 1px solid #dddddd'>2025-04-30 06:27:44.083000+00:00</td><td style='border: 1px solid #dddddd'>01968561-3a93-7bfc-a331-3e84de3f177f</td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wos_client.monitor_instances.show(target_target_id=SUBSCRIPTION_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60600246",
   "metadata": {},
   "source": [
    "## 8. Risk evaluations for PTA subscription <a name=\"evaluate\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e9109",
   "metadata": {},
   "source": [
    "### Evaluate the prompt template subscription\n",
    "\n",
    "For the risk assessment of a development type subscription the user needs to have an evaluation dataset. The risk evaluation function takes the evaluation dataset path as a parameter for evaluation of the configured metric dimensions. If there is a discrepancy between the feature columns in the subscription and the column names in the uploading CSV, users has the option to supply a mapping JSON file to associate the CSV column names with the feature column names in the subscription.\n",
    "\n",
    "\n",
    "**Note:* If you are running this notebook from Watson studio, you may first need to upload your test data to studio and run code snippet to download feedback data file from project to local directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8c8fd",
   "metadata": {},
   "source": [
    "The following cell will assess the test data with the subscription of the prompt template asset and produce relevant measurements for the configured monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab96a0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=================================================================================\n",
      "\n",
      " Waiting for risk evaluation of MRM monitor 01968561-3a93-7bfc-a331-3e84de3f177f \n",
      "\n",
      "=================================================================================\n",
      "\n",
      "\n",
      "\n",
      "upload_in_progress.\n",
      "running..\n",
      "finished\n",
      "\n",
      "---------------------------------------\n",
      " Successfully finished evaluating risk \n",
      "---------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_set_name = \"data\"\n",
    "content_type = \"multipart/form-data\"\n",
    "body = {}\n",
    "\n",
    "# Preparing the test data, removing extra columns\n",
    "cols_to_remove = [\"uid\", \"doc\", \"title\", \"id\"]\n",
    "for col in cols_to_remove:\n",
    "    if col in llm_data:\n",
    "        del llm_data[col]\n",
    "llm_data.to_csv(test_data_path, index=False)\n",
    "\n",
    "response = wos_client.monitor_instances.mrm.evaluate_risk(\n",
    "    monitor_instance_id=mrm_monitor_instance_id,\n",
    "    test_data_set_name=test_data_set_name,\n",
    "    test_data_path=test_data_path,\n",
    "    content_type=content_type,\n",
    "    body=body,\n",
    "    space_id=SPACE_ID,\n",
    "    includes_model_output=True,\n",
    "    background_mode=False\n",
    ")\n",
    "\n",
    "#####################################################################################\n",
    "        #For production flow \n",
    "######################################################################################\n",
    "# response  = wos_client.monitor_instances.mrm.evaluate_risk(monitor_instance_id=mrm_monitor_instance_id, \n",
    "#                                                     body = body,\n",
    "#                                                     space_id = SPACE_ID,\n",
    "#                                                     evaluation_tests = [custom_monitor_id, \"model_health\"],\n",
    "#                                                     background_mode = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada89d4",
   "metadata": {},
   "source": [
    "### Read the risk evaluation response\n",
    "\n",
    "After initiating the risk evaluation, the evaluation results are now available for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "940232f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'id': 'ea9f55b7-f7ab-4dc6-b00e-7d9ffa2ed8fb',\n",
       "  'created_at': '2025-04-30T06:30:11.618Z',\n",
       "  'created_by': 'iam-ServiceId-b317a8da-d926-496e-b0ca-6bcc57f556ae'},\n",
       " 'entity': {'triggered_by': 'user',\n",
       "  'parameters': {'deployment_id': '14598d71-1df4-4687-a583-23f4982841a1',\n",
       "   'evaluation_start_time': '2025-04-30T06:29:58.414895Z',\n",
       "   'evaluator_user_key': 'd347a831-fa73-43f1-a1c1-2fd620440e2a',\n",
       "   'facts': {'state': 'finished'},\n",
       "   'is_auto_evaluated': False,\n",
       "   'measurement_id': '01968563-7be5-7522-beeb-a044ef60ce9a',\n",
       "   'monitors_run_status': [{'monitor_id': 'generative_ai_quality',\n",
       "     'status': {'state': 'finished'}},\n",
       "    {'monitor_id': 'model_health', 'status': {'state': 'finished'}},\n",
       "    {'monitor_id': 'sample_model_performance',\n",
       "     'status': {'state': 'finished'}}],\n",
       "   'prompt_template_asset_id': 'b8601bfe-06a4-4669-b7bd-eda9c6d1ce76',\n",
       "   'prompt_template_details': {'pta_resource_key': '70b12f06c5dd777c296b066bccf35bdc535f5989df3171a5e1746d689d5d2079'},\n",
       "   'space_id': 'f0941313-c25e-440b-9531-ad0106f8435d',\n",
       "   'user_iam_id': 'IBMid-666003NI0G',\n",
       "   'publish_metrics': 'false',\n",
       "   'evaluation_tests': ['drift_v2',\n",
       "    'fairness',\n",
       "    'generative_ai_quality',\n",
       "    'model_health',\n",
       "    'quality',\n",
       "    'sample_model_performance']},\n",
       "  'status': {'state': 'finished',\n",
       "   'queued_at': '2025-04-30T06:30:11.614000Z',\n",
       "   'started_at': '2025-04-30T06:30:12.630000Z',\n",
       "   'updated_at': '2025-04-30T06:30:46.027000Z',\n",
       "   'completed_at': '2025-04-30T06:30:40.500000Z',\n",
       "   'message': 'Mrm evaluation complete.',\n",
       "   'operators': []}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = wos_client.monitor_instances.mrm.get_risk_evaluation(mrm_monitor_instance_id, space_id=SPACE_ID)\n",
    "response.result.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7692a2",
   "metadata": {},
   "source": [
    "## 9. Display the custom metrics <a name=\"custom_metrics\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0facadb",
   "metadata": {},
   "source": [
    "Monitor instance ID of custom monitor is required for reading its metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036225d6",
   "metadata": {},
   "source": [
    "Displaying the custom monitor metrics generated through the risk evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "406ef31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>01968562-f7a5-706e-9390-00b1aec736fd Monitor Runs Metrics from: 2025-04-23 12:02:09.136209  till: 2025-04-30 12:02:09.136221</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>ts</th><th style='border: 1px solid #dddddd'>id</th><th style='border: 1px solid #dddddd'>measurement_id</th><th style='border: 1px solid #dddddd'>value</th><th style='border: 1px solid #dddddd'>lower_limit</th><th style='border: 1px solid #dddddd'>upper_limit</th><th style='border: 1px solid #dddddd'>tags</th><th style='border: 1px solid #dddddd'>monitor_definition_id</th><th style='border: 1px solid #dddddd'>monitor_instance_id</th><th style='border: 1px solid #dddddd'>run_id</th><th style='border: 1px solid #dddddd'>target_type</th><th style='border: 1px solid #dddddd'>target_id</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>2025-04-30 06:30:21.749253+00:00</td><td style='border: 1px solid #dddddd'>sensitivity</td><td style='border: 1px solid #dddddd'>01968563-a335-7a9f-91b2-b39b3c382721</td><td style='border: 1px solid #dddddd'>0.85</td><td style='border: 1px solid #dddddd'>0.6</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>['region:us-south']</td><td style='border: 1px solid #dddddd'>sample_model_performance</td><td style='border: 1px solid #dddddd'>01968562-f7a5-706e-9390-00b1aec736fd</td><td style='border: 1px solid #dddddd'>e43e151e-6e1f-46cd-89b7-135a0e4c124b</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>01968561-1b2a-7e33-be21-7664c95df22d</td></tr><tr><td style='border: 1px solid #dddddd'>2025-04-30 06:30:21.749253+00:00</td><td style='border: 1px solid #dddddd'>gender_less40_fav_prediction_ratio</td><td style='border: 1px solid #dddddd'>01968563-a335-7a9f-91b2-b39b3c382721</td><td style='border: 1px solid #dddddd'>0.4</td><td style='border: 1px solid #dddddd'>0.6</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>['region:us-south']</td><td style='border: 1px solid #dddddd'>sample_model_performance</td><td style='border: 1px solid #dddddd'>01968562-f7a5-706e-9390-00b1aec736fd</td><td style='border: 1px solid #dddddd'>e43e151e-6e1f-46cd-89b7-135a0e4c124b</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>01968561-1b2a-7e33-be21-7664c95df22d</td></tr><tr><td style='border: 1px solid #dddddd'>2025-04-30 06:30:21.749253+00:00</td><td style='border: 1px solid #dddddd'>specificity</td><td style='border: 1px solid #dddddd'>01968563-a335-7a9f-91b2-b39b3c382721</td><td style='border: 1px solid #dddddd'>1.2</td><td style='border: 1px solid #dddddd'>0.8</td><td style='border: 1px solid #dddddd'>None</td><td style='border: 1px solid #dddddd'>['region:us-south']</td><td style='border: 1px solid #dddddd'>sample_model_performance</td><td style='border: 1px solid #dddddd'>01968562-f7a5-706e-9390-00b1aec736fd</td><td style='border: 1px solid #dddddd'>e43e151e-6e1f-46cd-89b7-135a0e4c124b</td><td style='border: 1px solid #dddddd'>subscription</td><td style='border: 1px solid #dddddd'>01968561-1b2a-7e33-be21-7664c95df22d</td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=custom_monitor_instance_id, space_id=SPACE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4201178",
   "metadata": {},
   "source": [
    "### Show record level metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21080e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.data_sets.show_records(data_set_id = custom_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b25de17",
   "metadata": {},
   "source": [
    "# [OPTIONAL STEP] Invoke the custom metrics python function deployment as part of this notebook.\n",
    "\n",
    "Validate the custom metrics provider deployment by providing the correct set of paramaters to generate the custom metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92a3d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_id(data_set_type: str):\n",
    "    data_sets = wos_client.data_sets.list(target_target_id= config[\"SUBSCRIPTION_ID\"], type = data_set_type).result.data_sets\n",
    "    feedback_data_set_id = None\n",
    "    if len(data_sets) > 0:\n",
    "        feedback_data_set_id = data_sets[0].metadata.id\n",
    "    return feedback_data_set_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea5d2f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'id': 'e43e151e-6e1f-46cd-89b7-135a0e4c124b', 'crn': 'crn:v1:bluemix:public:aiopenscale:us-south:a/6c26e1f11ef745238913798de41a0653:2e25b9e6-1dc2-4ea2-9c81-53904ab3d931:run:e43e151e-6e1f-46cd-89b7-135a0e4c124b', 'url': '/v2/monitor_instances/01968562-f7a5-706e-9390-00b1aec736fd/runs/e43e151e-6e1f-46cd-89b7-135a0e4c124b', 'created_at': '2025-04-30T06:30:20.532000Z', 'created_by': 'iam-ServiceId-b317a8da-d926-496e-b0ca-6bcc57f556ae'}, 'entity': {'triggered_by': 'user', 'parameters': {'custom_metrics_provider_id': '01968562-ca4c-7858-ab05-d92f5d31cb1f', 'custom_metrics_wait_time': 60, 'enable_custom_metric_runs': True}, 'status': {'state': 'finished', 'queued_at': '2025-04-30T06:30:20.528000Z', 'started_at': '2025-04-30T06:30:20.532000Z', 'updated_at': '2025-04-30T06:30:28.149000Z', 'completed_at': '2025-04-30T06:30:27.721000Z', 'operators': []}}}\n"
     ]
    }
   ],
   "source": [
    "monitor_runs = wos_client.monitor_instances.list_runs(monitor_instance_id=custom_monitor_instance_id).result\n",
    "result_json = monitor_runs._to_dict()\n",
    "latest_run = result_json[\"runs\"][0]\n",
    "print(latest_run)\n",
    "custom_monitor_run_id = latest_run[\"metadata\"][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e345766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "parameters = {\n",
    "    \"custom_metrics_provider_id\": result[\"integrated_system_id\"],\n",
    "    \"custom_metrics_wait_time\":   config[\"CUSTOM_METRICS_WAIT_TIME\"]\n",
    "}\n",
    "\n",
    "payload= {\n",
    "    \"data_mart_id\" : config[\"DATAMART_ID\"],\n",
    "    \"subscription_id\" : config[\"SUBSCRIPTION_ID\"],\n",
    "    \"custom_monitor_id\" : custom_monitor_instance_id,\n",
    "    \"custom_monitor_instance_id\" : custom_monitor_instance_id,\n",
    "    \"custom_monitor_run_id\":custom_monitor_run_id,\n",
    "    \"custom_monitor_instance_params\": parameters,\n",
    "    \"feedback_dataset_id\": get_dataset_id(\"feedback\"),\n",
    "    \"custom_dataset_id\": custom_dataset_id\n",
    "}\n",
    "\n",
    "input_data= { \"input_data\": [ { \"values\": payload } ]\n",
    "            }\n",
    "\n",
    "\n",
    "func_result = custom_metrics_provider()(input_data)\n",
    "func_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c468ba",
   "metadata": {},
   "source": [
    "User can navigate to see the published facts in space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "factsheets_url = \"https://dataplatform.cloud.ibm.com/ml-runtime/deployments/{}/details?space_id={}&context=wx&flush=true\".format(deployment_id, SPACE_ID)\n",
    "print(\"User can navigate to the published facts in space {}\".format(factsheets_url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf66baa",
   "metadata": {},
   "source": [
    "## Congratulations\n",
    "\n",
    "You have finished configuring GenAI Quality monitor, Custom Monitor Definition and Monitor instance and executing Custom Monitor Run for summarization task type. You can now navigate to the prompt template asset in your project / space and click on the Evaluate tab to visualise the results on the UI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
